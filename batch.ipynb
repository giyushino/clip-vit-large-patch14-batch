{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNE7Lf7qp8LEfqT83UtmB/C"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgalmonuwjxG",
        "outputId": "4c25c1be-a822-4037-f083-74a65fb6296e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "datasets = load_dataset(\"cifar10\")\n",
        "\n",
        "labels = datasets[\"train\"].features[\"label\"].names\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = i\n",
        "    id2label[i] = label\n"
      ],
      "metadata": {
        "id": "yESpP8MyN_Rn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")"
      ],
      "metadata": {
        "id": "xm_yJ7UyRj3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def homemade_batch(num_img, batch_size=10, start_img=0):\n",
        "    homemade = []\n",
        "    num_batches = num_img // batch_size\n",
        "    extra = num_img % batch_size\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    t_0 = time.perf_counter()\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        t1 = time.perf_counter()\n",
        "\n",
        "        subset = datasets[\"train\"].select(range((i * batch_size + start_img), (i + 1) * batch_size + start_img))\n",
        "        input = processor(text=labels, images=subset[\"img\"], return_tensors=\"pt\", padding=False).to(device)\n",
        "        output = model(**input)\n",
        "\n",
        "        logits = output.logits_per_image\n",
        "        probs = logits.softmax(dim=1)\n",
        "\n",
        "        max_prob, max_index = probs.max(dim=1)\n",
        "        homemade.append([max_prob.cpu().detach(), max_index.cpu().detach()])\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        t2 = time.perf_counter()\n",
        "        print(f\"Finished batch {i + 1} of {num_batches} in {t2 - t1} seconds\")\n",
        "\n",
        "    t_3 = time.perf_counter()\n",
        "    print(f\"Finished entire dataset in {t_3 - t_0} seconds\")\n",
        "\n",
        "    return homemade\n",
        "\n"
      ],
      "metadata": {
        "id": "PMOz6dV1wzq6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction_reformat(subset):\n",
        "    predicted = []\n",
        "    count = 1\n",
        "    for i in range(len(result)):\n",
        "        for k in range(len(subset[0][0])):\n",
        "            prob = subset[i][0][k].item()\n",
        "            id = subset[i][1][k].item()\n",
        "            label = id2label[id]\n",
        "            predicted.append([i, label, prob, id])\n",
        "\n",
        "            count += 1\n",
        "\n",
        "    return predicted"
      ],
      "metadata": {
        "id": "8YKZceIPLeMP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(result):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = {}\n",
        "    for label in datasets[\"train\"].features[\"label\"].names:\n",
        "        all_labels[label] = 0\n",
        "\n",
        "    incorrect = {}\n",
        "    for label in datasets[\"train\"].features[\"label\"].names:\n",
        "        incorrect[label] = 0\n",
        "\n",
        "\n",
        "    for i in range(len(result)):\n",
        "        all_labels[result[i][1]] += 1\n",
        "        if datasets[\"train\"][i][\"label\"] == result[i][3]:\n",
        "            correct += 1\n",
        "            total += 1\n",
        "            if total % 50 == 0:\n",
        "              print(f\"Model accurately predicted {result[i][1]} with {result[i][2] * 100}% confidence.\")\n",
        "        else:\n",
        "            total += 1\n",
        "            print(f\"Model inaccurately predicted {result[i][1]} with {result[i][2] * 100}% confidence.\")\n",
        "            incorrect[result[i][1]] += 1\n",
        "\n",
        "\n",
        "    print(f\"Acurracy: {(correct/total) * 100}%\")\n",
        "\n",
        "    worst_accuracy = []\n",
        "    for label in all_labels:\n",
        "        correct =  all_labels[label] - incorrect[label]\n",
        "        total = all_labels[label]\n",
        "        print(f\"For {label}: Predicted {correct} out of {total} correct. {(correct) / total * 100}% Accuracy\")\n",
        "        worst_accuracy.append([label, correct/total])\n",
        "\n",
        "    worst_group = min(worst_accuracy, key=lambda x: x[1])\n",
        "    print(f\"The worst performing group is '{worst_group[0]}' with an accuracy of {worst_group[1] * 100}%\")\n",
        ""
      ],
      "metadata": {
        "id": "c5RePiYBLkwH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_analysis(predictions):\n",
        "  cleaned = prediction_reformat(predictions)\n",
        "  final_results = accuracy(cleaned)"
      ],
      "metadata": {
        "id": "JKZpaSgZLpCa"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = homemade_batch(5000)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3WymeC9Oj97",
        "outputId": "baeebef2-baf6-4e92-afd2-55d35d6ed467"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished batch 1 of 500 in 0.596545416999902 seconds\n",
            "Finished batch 2 of 500 in 0.750236530000052 seconds\n",
            "Finished batch 3 of 500 in 0.7110337660000141 seconds\n",
            "Finished batch 4 of 500 in 0.7189878219999173 seconds\n",
            "Finished batch 5 of 500 in 0.7182116180000548 seconds\n",
            "Finished batch 6 of 500 in 0.7201500300000134 seconds\n",
            "Finished batch 7 of 500 in 0.7219336440000461 seconds\n",
            "Finished batch 8 of 500 in 0.7249805410000363 seconds\n",
            "Finished batch 9 of 500 in 0.7266660489999595 seconds\n",
            "Finished batch 10 of 500 in 0.751069083999937 seconds\n",
            "Finished batch 11 of 500 in 0.7515203770000198 seconds\n",
            "Finished batch 12 of 500 in 0.7534011359999795 seconds\n",
            "Finished batch 13 of 500 in 0.7580375059999369 seconds\n",
            "Finished batch 14 of 500 in 0.7328281220000008 seconds\n",
            "Finished batch 15 of 500 in 0.7328600989999359 seconds\n",
            "Finished batch 16 of 500 in 0.7362740460000623 seconds\n",
            "Finished batch 17 of 500 in 0.7411615649999703 seconds\n",
            "Finished batch 18 of 500 in 0.7326110519999247 seconds\n",
            "Finished batch 19 of 500 in 0.7399165959999436 seconds\n",
            "Finished batch 20 of 500 in 0.7351368680000405 seconds\n",
            "Finished batch 21 of 500 in 0.7348571050000601 seconds\n",
            "Finished batch 22 of 500 in 0.7362260280000328 seconds\n",
            "Finished batch 23 of 500 in 0.7275350290000233 seconds\n",
            "Finished batch 24 of 500 in 0.7301484039999195 seconds\n",
            "Finished batch 25 of 500 in 0.7283016869999983 seconds\n",
            "Finished batch 26 of 500 in 0.7277611120000529 seconds\n",
            "Finished batch 27 of 500 in 0.7609821490000286 seconds\n",
            "Finished batch 28 of 500 in 0.7492961340000193 seconds\n",
            "Finished batch 29 of 500 in 0.7528666309999608 seconds\n",
            "Finished batch 30 of 500 in 0.7440212110000175 seconds\n",
            "Finished batch 31 of 500 in 0.7159370180000906 seconds\n",
            "Finished batch 32 of 500 in 0.7185726870000053 seconds\n",
            "Finished batch 33 of 500 in 0.717152877999979 seconds\n",
            "Finished batch 34 of 500 in 0.7178503290000435 seconds\n",
            "Finished batch 35 of 500 in 0.7122608780000519 seconds\n",
            "Finished batch 36 of 500 in 0.7119360570000026 seconds\n",
            "Finished batch 37 of 500 in 0.7132869619999838 seconds\n",
            "Finished batch 38 of 500 in 0.7050587240000823 seconds\n",
            "Finished batch 39 of 500 in 0.7108023079999839 seconds\n",
            "Finished batch 40 of 500 in 0.7058581129999766 seconds\n",
            "Finished batch 41 of 500 in 0.7050395740000113 seconds\n",
            "Finished batch 42 of 500 in 0.703139121999925 seconds\n",
            "Finished batch 43 of 500 in 0.7043810469999698 seconds\n",
            "Finished batch 44 of 500 in 0.7143649849999747 seconds\n",
            "Finished batch 45 of 500 in 0.7261601390000578 seconds\n",
            "Finished batch 46 of 500 in 0.7266848069999696 seconds\n",
            "Finished batch 47 of 500 in 0.7359686690000444 seconds\n",
            "Finished batch 48 of 500 in 0.7075217479999765 seconds\n",
            "Finished batch 49 of 500 in 0.6960767809999879 seconds\n",
            "Finished batch 50 of 500 in 0.6955371799999739 seconds\n",
            "Finished batch 51 of 500 in 0.6937156940000477 seconds\n",
            "Finished batch 52 of 500 in 0.6930573920000143 seconds\n",
            "Finished batch 53 of 500 in 0.6971150150000085 seconds\n",
            "Finished batch 54 of 500 in 0.694604432999995 seconds\n",
            "Finished batch 55 of 500 in 0.687155338000025 seconds\n",
            "Finished batch 56 of 500 in 0.6879921500000137 seconds\n",
            "Finished batch 57 of 500 in 0.7062795960000585 seconds\n",
            "Finished batch 58 of 500 in 0.6875660169999946 seconds\n",
            "Finished batch 59 of 500 in 0.6889822560000312 seconds\n",
            "Finished batch 60 of 500 in 0.6868915070000412 seconds\n",
            "Finished batch 61 of 500 in 0.6873471879999897 seconds\n",
            "Finished batch 62 of 500 in 0.6973889559999407 seconds\n",
            "Finished batch 63 of 500 in 0.7077557940000361 seconds\n",
            "Finished batch 64 of 500 in 0.7025461160000077 seconds\n",
            "Finished batch 65 of 500 in 0.7054369599999291 seconds\n",
            "Finished batch 66 of 500 in 0.6984596620000048 seconds\n",
            "Finished batch 67 of 500 in 0.6839216390000047 seconds\n",
            "Finished batch 68 of 500 in 0.683792328000095 seconds\n",
            "Finished batch 69 of 500 in 0.6758762499999875 seconds\n",
            "Finished batch 70 of 500 in 0.6785371980000718 seconds\n",
            "Finished batch 71 of 500 in 0.677916593999953 seconds\n",
            "Finished batch 72 of 500 in 0.6854349719999391 seconds\n",
            "Finished batch 73 of 500 in 0.679671978999977 seconds\n",
            "Finished batch 74 of 500 in 0.6843873679999888 seconds\n",
            "Finished batch 75 of 500 in 0.6841619860000492 seconds\n",
            "Finished batch 76 of 500 in 0.6826890150000509 seconds\n",
            "Finished batch 77 of 500 in 0.670815356999924 seconds\n",
            "Finished batch 78 of 500 in 0.6846842439999818 seconds\n",
            "Finished batch 79 of 500 in 0.6806187829999999 seconds\n",
            "Finished batch 80 of 500 in 0.6754842469999858 seconds\n",
            "Finished batch 81 of 500 in 0.6940310689999478 seconds\n",
            "Finished batch 82 of 500 in 0.7025998230000141 seconds\n",
            "Finished batch 83 of 500 in 0.694931366999981 seconds\n",
            "Finished batch 84 of 500 in 0.6996491300000116 seconds\n",
            "Finished batch 85 of 500 in 0.6959529150000208 seconds\n",
            "Finished batch 86 of 500 in 0.6664828730000636 seconds\n",
            "Finished batch 87 of 500 in 0.683180741000001 seconds\n",
            "Finished batch 88 of 500 in 0.6719866799999181 seconds\n",
            "Finished batch 89 of 500 in 0.6833627239999487 seconds\n",
            "Finished batch 90 of 500 in 0.6800308609999774 seconds\n",
            "Finished batch 91 of 500 in 0.6736777590000429 seconds\n",
            "Finished batch 92 of 500 in 0.6783207010000751 seconds\n",
            "Finished batch 93 of 500 in 0.6758714480000663 seconds\n",
            "Finished batch 94 of 500 in 0.6792344829999593 seconds\n",
            "Finished batch 95 of 500 in 0.687962964999997 seconds\n",
            "Finished batch 96 of 500 in 0.6854569070000025 seconds\n",
            "Finished batch 97 of 500 in 0.675608683000064 seconds\n",
            "Finished batch 98 of 500 in 0.6828510919999644 seconds\n",
            "Finished batch 99 of 500 in 0.684432787999981 seconds\n",
            "Finished batch 100 of 500 in 0.7035752839999532 seconds\n",
            "Finished batch 101 of 500 in 0.7071169200000895 seconds\n",
            "Finished batch 102 of 500 in 0.7041152890000149 seconds\n",
            "Finished batch 103 of 500 in 0.7048062609999306 seconds\n",
            "Finished batch 104 of 500 in 0.6949296719999438 seconds\n",
            "Finished batch 105 of 500 in 0.6858353569999736 seconds\n",
            "Finished batch 106 of 500 in 0.6853590330000543 seconds\n",
            "Finished batch 107 of 500 in 0.6875001479999128 seconds\n",
            "Finished batch 108 of 500 in 0.6885766660000172 seconds\n",
            "Finished batch 109 of 500 in 0.695386054000096 seconds\n",
            "Finished batch 110 of 500 in 0.6878991859999815 seconds\n",
            "Finished batch 111 of 500 in 0.6879593800000521 seconds\n",
            "Finished batch 112 of 500 in 0.6862150929999871 seconds\n",
            "Finished batch 113 of 500 in 0.6912317569999686 seconds\n",
            "Finished batch 114 of 500 in 0.6963950709999835 seconds\n",
            "Finished batch 115 of 500 in 0.6937030990000039 seconds\n",
            "Finished batch 116 of 500 in 0.6916634029998932 seconds\n",
            "Finished batch 117 of 500 in 0.6931259290000753 seconds\n",
            "Finished batch 118 of 500 in 0.7030749040000046 seconds\n",
            "Finished batch 119 of 500 in 0.7157250479999675 seconds\n",
            "Finished batch 120 of 500 in 0.7195603440000014 seconds\n",
            "Finished batch 121 of 500 in 0.7314617790000284 seconds\n",
            "Finished batch 122 of 500 in 0.7168134340000734 seconds\n",
            "Finished batch 123 of 500 in 0.7093837490000396 seconds\n",
            "Finished batch 124 of 500 in 0.6972774289999961 seconds\n",
            "Finished batch 125 of 500 in 0.694567472000017 seconds\n",
            "Finished batch 126 of 500 in 0.7046348029999763 seconds\n",
            "Finished batch 127 of 500 in 0.7025426599999491 seconds\n",
            "Finished batch 128 of 500 in 0.7027819499999168 seconds\n",
            "Finished batch 129 of 500 in 0.6989619889999403 seconds\n",
            "Finished batch 130 of 500 in 0.7012301009999646 seconds\n",
            "Finished batch 131 of 500 in 0.7026847460000454 seconds\n",
            "Finished batch 132 of 500 in 0.7046478909999223 seconds\n",
            "Finished batch 133 of 500 in 0.7011872400000811 seconds\n",
            "Finished batch 134 of 500 in 0.7026773369999546 seconds\n",
            "Finished batch 135 of 500 in 0.700451768999983 seconds\n",
            "Finished batch 136 of 500 in 0.7181857909999962 seconds\n",
            "Finished batch 137 of 500 in 0.7227299180000273 seconds\n",
            "Finished batch 138 of 500 in 0.7266367759999639 seconds\n",
            "Finished batch 139 of 500 in 0.7431462999999212 seconds\n",
            "Finished batch 140 of 500 in 0.7186193019999791 seconds\n",
            "Finished batch 141 of 500 in 0.7046280440000601 seconds\n",
            "Finished batch 142 of 500 in 0.7066434609999988 seconds\n",
            "Finished batch 143 of 500 in 0.7094927709999865 seconds\n",
            "Finished batch 144 of 500 in 0.7089050450000514 seconds\n",
            "Finished batch 145 of 500 in 0.7017920219999496 seconds\n",
            "Finished batch 146 of 500 in 0.7082965810000132 seconds\n",
            "Finished batch 147 of 500 in 0.707359012999973 seconds\n",
            "Finished batch 148 of 500 in 0.7052975110000261 seconds\n",
            "Finished batch 149 of 500 in 0.7066420799999378 seconds\n",
            "Finished batch 150 of 500 in 0.7030394739999792 seconds\n",
            "Finished batch 151 of 500 in 0.701614319999976 seconds\n",
            "Finished batch 152 of 500 in 0.7042676739999933 seconds\n",
            "Finished batch 153 of 500 in 0.7134912599999552 seconds\n",
            "Finished batch 154 of 500 in 0.7157007700000122 seconds\n",
            "Finished batch 155 of 500 in 0.730637000999991 seconds\n",
            "Finished batch 156 of 500 in 0.723551542999985 seconds\n",
            "Finished batch 157 of 500 in 0.7208328010000287 seconds\n",
            "Finished batch 158 of 500 in 0.7169175900000937 seconds\n",
            "Finished batch 159 of 500 in 0.7054588949999925 seconds\n",
            "Finished batch 160 of 500 in 0.7020367439999973 seconds\n",
            "Finished batch 161 of 500 in 0.7010254890000169 seconds\n",
            "Finished batch 162 of 500 in 0.7024749490000204 seconds\n",
            "Finished batch 163 of 500 in 0.7048388519999662 seconds\n",
            "Finished batch 164 of 500 in 0.6996347650000416 seconds\n",
            "Finished batch 165 of 500 in 0.7012350239999705 seconds\n",
            "Finished batch 166 of 500 in 0.7026481010000225 seconds\n",
            "Finished batch 167 of 500 in 0.698959952999985 seconds\n",
            "Finished batch 168 of 500 in 0.6899950289999879 seconds\n",
            "Finished batch 169 of 500 in 0.7077650300000187 seconds\n",
            "Finished batch 170 of 500 in 0.6955340980000528 seconds\n",
            "Finished batch 171 of 500 in 0.7019132369999852 seconds\n",
            "Finished batch 172 of 500 in 0.7168678210000508 seconds\n",
            "Finished batch 173 of 500 in 0.7179653040000176 seconds\n",
            "Finished batch 174 of 500 in 0.7270154120000143 seconds\n",
            "Finished batch 175 of 500 in 0.7185005189999174 seconds\n",
            "Finished batch 176 of 500 in 0.7025003310000102 seconds\n",
            "Finished batch 177 of 500 in 0.6989750300000424 seconds\n",
            "Finished batch 178 of 500 in 0.6982036040000139 seconds\n",
            "Finished batch 179 of 500 in 0.6943523019999702 seconds\n",
            "Finished batch 180 of 500 in 0.695649708000019 seconds\n",
            "Finished batch 181 of 500 in 0.6982548299999962 seconds\n",
            "Finished batch 182 of 500 in 0.6958444910000026 seconds\n",
            "Finished batch 183 of 500 in 0.6954589989999249 seconds\n",
            "Finished batch 184 of 500 in 0.6938677629999574 seconds\n",
            "Finished batch 185 of 500 in 0.6954269249999925 seconds\n",
            "Finished batch 186 of 500 in 0.6917106969999622 seconds\n",
            "Finished batch 187 of 500 in 0.6881753649998927 seconds\n",
            "Finished batch 188 of 500 in 0.7010289800000464 seconds\n",
            "Finished batch 189 of 500 in 0.692649901999971 seconds\n",
            "Finished batch 190 of 500 in 0.7086245399999598 seconds\n",
            "Finished batch 191 of 500 in 0.7156135190000441 seconds\n",
            "Finished batch 192 of 500 in 0.720634187000087 seconds\n",
            "Finished batch 193 of 500 in 0.724352950000025 seconds\n",
            "Finished batch 194 of 500 in 0.7037214319999521 seconds\n",
            "Finished batch 195 of 500 in 0.6829075010000452 seconds\n",
            "Finished batch 196 of 500 in 0.6880478440000388 seconds\n",
            "Finished batch 197 of 500 in 0.6879058079999822 seconds\n",
            "Finished batch 198 of 500 in 0.6933663099999876 seconds\n",
            "Finished batch 199 of 500 in 0.6908326179999449 seconds\n",
            "Finished batch 200 of 500 in 0.6862211810000645 seconds\n",
            "Finished batch 201 of 500 in 0.689669471000002 seconds\n",
            "Finished batch 202 of 500 in 0.6841515500000241 seconds\n",
            "Finished batch 203 of 500 in 0.7015878290000046 seconds\n",
            "Finished batch 204 of 500 in 0.7055984050000461 seconds\n",
            "Finished batch 205 of 500 in 0.7155373740000641 seconds\n",
            "Finished batch 206 of 500 in 0.7088737199999287 seconds\n",
            "Finished batch 207 of 500 in 0.6965824210000164 seconds\n",
            "Finished batch 208 of 500 in 0.7006404129999737 seconds\n",
            "Finished batch 209 of 500 in 0.7053479510000216 seconds\n",
            "Finished batch 210 of 500 in 0.7112066339999501 seconds\n",
            "Finished batch 211 of 500 in 0.7176229670000112 seconds\n",
            "Finished batch 212 of 500 in 0.6992226879999635 seconds\n",
            "Finished batch 213 of 500 in 0.6872825579999926 seconds\n",
            "Finished batch 214 of 500 in 0.6847757960000536 seconds\n",
            "Finished batch 215 of 500 in 0.6901514269999325 seconds\n",
            "Finished batch 216 of 500 in 0.689017050000075 seconds\n",
            "Finished batch 217 of 500 in 0.6804942349999692 seconds\n",
            "Finished batch 218 of 500 in 0.6878960269999652 seconds\n",
            "Finished batch 219 of 500 in 0.693416520000028 seconds\n",
            "Finished batch 220 of 500 in 0.68501168399996 seconds\n",
            "Finished batch 221 of 500 in 0.6813480170000048 seconds\n",
            "Finished batch 222 of 500 in 0.691300151000064 seconds\n",
            "Finished batch 223 of 500 in 0.6867507509999768 seconds\n",
            "Finished batch 224 of 500 in 0.6816769150000255 seconds\n",
            "Finished batch 225 of 500 in 0.687538482999912 seconds\n",
            "Finished batch 226 of 500 in 0.6890619789999164 seconds\n",
            "Finished batch 227 of 500 in 0.6999308990000372 seconds\n",
            "Finished batch 228 of 500 in 0.7192538210000521 seconds\n",
            "Finished batch 229 of 500 in 0.7113994940000339 seconds\n",
            "Finished batch 230 of 500 in 0.7108694309999919 seconds\n",
            "Finished batch 231 of 500 in 0.7034943040000599 seconds\n",
            "Finished batch 232 of 500 in 0.6951114670000607 seconds\n",
            "Finished batch 233 of 500 in 0.6925011729999824 seconds\n",
            "Finished batch 234 of 500 in 0.6917448489999742 seconds\n",
            "Finished batch 235 of 500 in 0.6934940889999552 seconds\n",
            "Finished batch 236 of 500 in 0.693506020999962 seconds\n",
            "Finished batch 237 of 500 in 0.6927239969999164 seconds\n",
            "Finished batch 238 of 500 in 0.6941630659999873 seconds\n",
            "Finished batch 239 of 500 in 0.6955475109999725 seconds\n",
            "Finished batch 240 of 500 in 0.6935613430000558 seconds\n",
            "Finished batch 241 of 500 in 0.6907364480000524 seconds\n",
            "Finished batch 242 of 500 in 0.6958026040000505 seconds\n",
            "Finished batch 243 of 500 in 0.6943906840000409 seconds\n",
            "Finished batch 244 of 500 in 0.6937874939999347 seconds\n",
            "Finished batch 245 of 500 in 0.7150766360000489 seconds\n",
            "Finished batch 246 of 500 in 0.7142007349999631 seconds\n",
            "Finished batch 247 of 500 in 0.7213543370000934 seconds\n",
            "Finished batch 248 of 500 in 0.7120833789999779 seconds\n",
            "Finished batch 249 of 500 in 0.7077235390000851 seconds\n",
            "Finished batch 250 of 500 in 0.6939823650000108 seconds\n",
            "Finished batch 251 of 500 in 0.6963184180000326 seconds\n",
            "Finished batch 252 of 500 in 0.6981911059999675 seconds\n",
            "Finished batch 253 of 500 in 0.6975097109999524 seconds\n",
            "Finished batch 254 of 500 in 0.6961635530000194 seconds\n",
            "Finished batch 255 of 500 in 0.6985119409999925 seconds\n",
            "Finished batch 256 of 500 in 0.6940353439998717 seconds\n",
            "Finished batch 257 of 500 in 0.694426243999942 seconds\n",
            "Finished batch 258 of 500 in 0.6924594590000197 seconds\n",
            "Finished batch 259 of 500 in 0.6960618309999518 seconds\n",
            "Finished batch 260 of 500 in 0.6947069910002028 seconds\n",
            "Finished batch 261 of 500 in 0.699655876999941 seconds\n",
            "Finished batch 262 of 500 in 0.7000282009998955 seconds\n",
            "Finished batch 263 of 500 in 0.6955163259999608 seconds\n",
            "Finished batch 264 of 500 in 0.7290148949998638 seconds\n",
            "Finished batch 265 of 500 in 0.7262612079998689 seconds\n",
            "Finished batch 266 of 500 in 0.7120305930000086 seconds\n",
            "Finished batch 267 of 500 in 0.7271218149999186 seconds\n",
            "Finished batch 268 of 500 in 0.6930437620001157 seconds\n",
            "Finished batch 269 of 500 in 0.6976810959999966 seconds\n",
            "Finished batch 270 of 500 in 0.6979683019999356 seconds\n",
            "Finished batch 271 of 500 in 0.6976483989999451 seconds\n",
            "Finished batch 272 of 500 in 0.6949540179998621 seconds\n",
            "Finished batch 273 of 500 in 0.6931990600000972 seconds\n",
            "Finished batch 274 of 500 in 0.6992433489999712 seconds\n",
            "Finished batch 275 of 500 in 0.6957289080000919 seconds\n",
            "Finished batch 276 of 500 in 0.6992869410000822 seconds\n",
            "Finished batch 277 of 500 in 0.7012616570000318 seconds\n",
            "Finished batch 278 of 500 in 0.7007154099999298 seconds\n",
            "Finished batch 279 of 500 in 0.7096392530002049 seconds\n",
            "Finished batch 280 of 500 in 0.6978869330000634 seconds\n",
            "Finished batch 281 of 500 in 0.6986407649999364 seconds\n",
            "Finished batch 282 of 500 in 0.7092049180000686 seconds\n",
            "Finished batch 283 of 500 in 0.7197100149999187 seconds\n",
            "Finished batch 284 of 500 in 0.7267112659999384 seconds\n",
            "Finished batch 285 of 500 in 0.7177252609999414 seconds\n",
            "Finished batch 286 of 500 in 0.7141739369999414 seconds\n",
            "Finished batch 287 of 500 in 0.697259572999883 seconds\n",
            "Finished batch 288 of 500 in 0.6932602529998348 seconds\n",
            "Finished batch 289 of 500 in 0.7022248260000197 seconds\n",
            "Finished batch 290 of 500 in 0.6924372639998637 seconds\n",
            "Finished batch 291 of 500 in 0.6989623650001704 seconds\n",
            "Finished batch 292 of 500 in 0.6993499229999998 seconds\n",
            "Finished batch 293 of 500 in 0.6897842569999284 seconds\n",
            "Finished batch 294 of 500 in 0.6950476389999949 seconds\n",
            "Finished batch 295 of 500 in 0.6945661430002019 seconds\n",
            "Finished batch 296 of 500 in 0.6889488520000668 seconds\n",
            "Finished batch 297 of 500 in 0.6910361080001621 seconds\n",
            "Finished batch 298 of 500 in 0.6873288430001594 seconds\n",
            "Finished batch 299 of 500 in 0.692808469000056 seconds\n",
            "Finished batch 300 of 500 in 0.7061684179998338 seconds\n",
            "Finished batch 301 of 500 in 0.7172718570000143 seconds\n",
            "Finished batch 302 of 500 in 0.7217979710001146 seconds\n",
            "Finished batch 303 of 500 in 0.7149330889999419 seconds\n",
            "Finished batch 304 of 500 in 0.7064072759999362 seconds\n",
            "Finished batch 305 of 500 in 0.6921362969999336 seconds\n",
            "Finished batch 306 of 500 in 0.6940483289999975 seconds\n",
            "Finished batch 307 of 500 in 0.6950239789998705 seconds\n",
            "Finished batch 308 of 500 in 0.6917416330002197 seconds\n",
            "Finished batch 309 of 500 in 0.7011164259999987 seconds\n",
            "Finished batch 310 of 500 in 0.6934163610001178 seconds\n",
            "Finished batch 311 of 500 in 0.6968369639998855 seconds\n",
            "Finished batch 312 of 500 in 0.6953194840000378 seconds\n",
            "Finished batch 313 of 500 in 0.6913379700001769 seconds\n",
            "Finished batch 314 of 500 in 0.6934024170000157 seconds\n",
            "Finished batch 315 of 500 in 0.6967646140001307 seconds\n",
            "Finished batch 316 of 500 in 0.6972088160000567 seconds\n",
            "Finished batch 317 of 500 in 0.6962706060000983 seconds\n",
            "Finished batch 318 of 500 in 0.8533644940000613 seconds\n",
            "Finished batch 319 of 500 in 0.9850019309999425 seconds\n",
            "Finished batch 320 of 500 in 0.9159357749999799 seconds\n",
            "Finished batch 321 of 500 in 1.399751654000056 seconds\n",
            "Finished batch 322 of 500 in 1.0198428589999367 seconds\n",
            "Finished batch 323 of 500 in 0.7235848889999943 seconds\n",
            "Finished batch 324 of 500 in 0.7026278830001047 seconds\n",
            "Finished batch 325 of 500 in 0.7805700119999983 seconds\n",
            "Finished batch 326 of 500 in 0.7036395439999978 seconds\n",
            "Finished batch 327 of 500 in 0.7122237879998465 seconds\n",
            "Finished batch 328 of 500 in 0.7118573580000884 seconds\n",
            "Finished batch 329 of 500 in 0.7235834329999307 seconds\n",
            "Finished batch 330 of 500 in 0.749914851000085 seconds\n",
            "Finished batch 331 of 500 in 0.7339199499999722 seconds\n",
            "Finished batch 332 of 500 in 0.952364937000084 seconds\n",
            "Finished batch 333 of 500 in 0.796730972999967 seconds\n",
            "Finished batch 334 of 500 in 0.7923998989999745 seconds\n",
            "Finished batch 335 of 500 in 0.9007374909999726 seconds\n",
            "Finished batch 336 of 500 in 0.902944547000061 seconds\n",
            "Finished batch 337 of 500 in 0.9253320809998513 seconds\n",
            "Finished batch 338 of 500 in 0.8098224589998608 seconds\n",
            "Finished batch 339 of 500 in 0.7319385050000164 seconds\n",
            "Finished batch 340 of 500 in 0.7157856859998901 seconds\n",
            "Finished batch 341 of 500 in 0.7859519179999097 seconds\n",
            "Finished batch 342 of 500 in 0.7491869279999719 seconds\n",
            "Finished batch 343 of 500 in 0.7049135759998535 seconds\n",
            "Finished batch 344 of 500 in 0.6972863200001029 seconds\n",
            "Finished batch 345 of 500 in 0.6957795089999763 seconds\n",
            "Finished batch 346 of 500 in 0.6972320810000383 seconds\n",
            "Finished batch 347 of 500 in 0.6927658659999452 seconds\n",
            "Finished batch 348 of 500 in 0.6952968199998395 seconds\n",
            "Finished batch 349 of 500 in 0.7252306699999735 seconds\n",
            "Finished batch 350 of 500 in 0.7009825820000515 seconds\n",
            "Finished batch 351 of 500 in 0.6982587319998856 seconds\n",
            "Finished batch 352 of 500 in 0.7054259899998669 seconds\n",
            "Finished batch 353 of 500 in 0.7166636859999471 seconds\n",
            "Finished batch 354 of 500 in 0.7228095970001505 seconds\n",
            "Finished batch 355 of 500 in 0.7221267919999264 seconds\n",
            "Finished batch 356 of 500 in 0.7113397309999527 seconds\n",
            "Finished batch 357 of 500 in 0.7018651599998975 seconds\n",
            "Finished batch 358 of 500 in 0.7013300799999342 seconds\n",
            "Finished batch 359 of 500 in 0.7104424760000256 seconds\n",
            "Finished batch 360 of 500 in 0.7018623369999659 seconds\n",
            "Finished batch 361 of 500 in 0.7026124809999601 seconds\n",
            "Finished batch 362 of 500 in 0.6989617250001174 seconds\n",
            "Finished batch 363 of 500 in 0.7027955379999185 seconds\n",
            "Finished batch 364 of 500 in 0.6964827300000707 seconds\n",
            "Finished batch 365 of 500 in 0.6976529029998346 seconds\n",
            "Finished batch 366 of 500 in 0.6992129779998777 seconds\n",
            "Finished batch 367 of 500 in 0.7019772280000325 seconds\n",
            "Finished batch 368 of 500 in 0.698214691999965 seconds\n",
            "Finished batch 369 of 500 in 0.7003980619999766 seconds\n",
            "Finished batch 370 of 500 in 0.7112462340001002 seconds\n",
            "Finished batch 371 of 500 in 0.7210043969998878 seconds\n",
            "Finished batch 372 of 500 in 0.7268922569999177 seconds\n",
            "Finished batch 373 of 500 in 0.7260149789999559 seconds\n",
            "Finished batch 374 of 500 in 0.7213275130000056 seconds\n",
            "Finished batch 375 of 500 in 0.6986936280000009 seconds\n",
            "Finished batch 376 of 500 in 0.6995694770000682 seconds\n",
            "Finished batch 377 of 500 in 0.7948617339998236 seconds\n",
            "Finished batch 378 of 500 in 0.7378251229999933 seconds\n",
            "Finished batch 379 of 500 in 0.738777847999927 seconds\n",
            "Finished batch 380 of 500 in 0.7034630240000297 seconds\n",
            "Finished batch 381 of 500 in 0.7853071740000814 seconds\n",
            "Finished batch 382 of 500 in 0.7340922199998658 seconds\n",
            "Finished batch 383 of 500 in 0.6977081959998941 seconds\n",
            "Finished batch 384 of 500 in 0.7046755100000155 seconds\n",
            "Finished batch 385 of 500 in 0.6990702230000352 seconds\n",
            "Finished batch 386 of 500 in 0.7000384819998544 seconds\n",
            "Finished batch 387 of 500 in 0.7757192779999968 seconds\n",
            "Finished batch 388 of 500 in 0.7136472340000637 seconds\n",
            "Finished batch 389 of 500 in 0.7344723310000063 seconds\n",
            "Finished batch 390 of 500 in 0.8449174980000862 seconds\n",
            "Finished batch 391 of 500 in 0.7977125879999676 seconds\n",
            "Finished batch 392 of 500 in 0.7719254419998833 seconds\n",
            "Finished batch 393 of 500 in 0.7430565879999449 seconds\n",
            "Finished batch 394 of 500 in 0.7533753830000478 seconds\n",
            "Finished batch 395 of 500 in 0.7083626099999947 seconds\n",
            "Finished batch 396 of 500 in 0.695862686000055 seconds\n",
            "Finished batch 397 of 500 in 0.6953206359999058 seconds\n",
            "Finished batch 398 of 500 in 0.6948727230001168 seconds\n",
            "Finished batch 399 of 500 in 0.7086368669999956 seconds\n",
            "Finished batch 400 of 500 in 0.6968583519999356 seconds\n",
            "Finished batch 401 of 500 in 0.6987252119999994 seconds\n",
            "Finished batch 402 of 500 in 0.6931930910000119 seconds\n",
            "Finished batch 403 of 500 in 0.6967870920000223 seconds\n",
            "Finished batch 404 of 500 in 0.6988203160001376 seconds\n",
            "Finished batch 405 of 500 in 0.6975973950000025 seconds\n",
            "Finished batch 406 of 500 in 0.7064551889998256 seconds\n",
            "Finished batch 407 of 500 in 0.7216213429999243 seconds\n",
            "Finished batch 408 of 500 in 0.7172396680000475 seconds\n",
            "Finished batch 409 of 500 in 0.713187550999919 seconds\n",
            "Finished batch 410 of 500 in 0.7079846449998968 seconds\n",
            "Finished batch 411 of 500 in 0.6949459600000409 seconds\n",
            "Finished batch 412 of 500 in 0.6947063980001076 seconds\n",
            "Finished batch 413 of 500 in 0.6972852709998278 seconds\n",
            "Finished batch 414 of 500 in 0.6922436149998248 seconds\n",
            "Finished batch 415 of 500 in 0.6973632340000222 seconds\n",
            "Finished batch 416 of 500 in 0.6949543460000314 seconds\n",
            "Finished batch 417 of 500 in 0.7026348729998517 seconds\n",
            "Finished batch 418 of 500 in 0.6936147249998612 seconds\n",
            "Finished batch 419 of 500 in 0.6957678990002023 seconds\n",
            "Finished batch 420 of 500 in 0.6948516919999292 seconds\n",
            "Finished batch 421 of 500 in 0.6928297089998523 seconds\n",
            "Finished batch 422 of 500 in 0.6995965809999234 seconds\n",
            "Finished batch 423 of 500 in 0.6957063429999835 seconds\n",
            "Finished batch 424 of 500 in 0.7120192429999861 seconds\n",
            "Finished batch 425 of 500 in 0.7130972029999612 seconds\n",
            "Finished batch 426 of 500 in 0.7180627929999446 seconds\n",
            "Finished batch 427 of 500 in 0.718273457000123 seconds\n",
            "Finished batch 428 of 500 in 0.7062172989999453 seconds\n",
            "Finished batch 429 of 500 in 0.6977577580000798 seconds\n",
            "Finished batch 430 of 500 in 0.6962941889999001 seconds\n",
            "Finished batch 431 of 500 in 0.6962928189998365 seconds\n",
            "Finished batch 432 of 500 in 0.6962809809999726 seconds\n",
            "Finished batch 433 of 500 in 0.6911942609999642 seconds\n",
            "Finished batch 434 of 500 in 0.6952776020000329 seconds\n",
            "Finished batch 435 of 500 in 0.6942675729999337 seconds\n",
            "Finished batch 436 of 500 in 0.6940420169999015 seconds\n",
            "Finished batch 437 of 500 in 0.6933082890000151 seconds\n",
            "Finished batch 438 of 500 in 0.698495087999845 seconds\n",
            "Finished batch 439 of 500 in 0.6905780889999278 seconds\n",
            "Finished batch 440 of 500 in 0.6936443950000921 seconds\n",
            "Finished batch 441 of 500 in 0.6958272150000084 seconds\n",
            "Finished batch 442 of 500 in 0.6988503649999984 seconds\n",
            "Finished batch 443 of 500 in 0.7170294869999907 seconds\n",
            "Finished batch 444 of 500 in 0.7165111579997756 seconds\n",
            "Finished batch 445 of 500 in 0.7149941679999756 seconds\n",
            "Finished batch 446 of 500 in 0.7173456380000971 seconds\n",
            "Finished batch 447 of 500 in 0.6936584249999669 seconds\n",
            "Finished batch 448 of 500 in 0.6899564240000018 seconds\n",
            "Finished batch 449 of 500 in 0.9208322539998335 seconds\n",
            "Finished batch 450 of 500 in 0.8769699869999386 seconds\n",
            "Finished batch 451 of 500 in 0.9218905419998009 seconds\n",
            "Finished batch 452 of 500 in 0.7814994169998499 seconds\n",
            "Finished batch 453 of 500 in 0.8052104149999195 seconds\n",
            "Finished batch 454 of 500 in 0.7749892949998411 seconds\n",
            "Finished batch 455 of 500 in 0.6882642790001228 seconds\n",
            "Finished batch 456 of 500 in 0.6916986100000031 seconds\n",
            "Finished batch 457 of 500 in 0.6982167550002032 seconds\n",
            "Finished batch 458 of 500 in 0.6943746499998724 seconds\n",
            "Finished batch 459 of 500 in 0.7069381250000788 seconds\n",
            "Finished batch 460 of 500 in 0.7192019999999957 seconds\n",
            "Finished batch 461 of 500 in 0.7226868770001147 seconds\n",
            "Finished batch 462 of 500 in 0.7110403730000598 seconds\n",
            "Finished batch 463 of 500 in 0.7056233030000385 seconds\n",
            "Finished batch 464 of 500 in 0.6924182040002052 seconds\n",
            "Finished batch 465 of 500 in 0.6920441459999438 seconds\n",
            "Finished batch 466 of 500 in 0.6989756230000239 seconds\n",
            "Finished batch 467 of 500 in 0.7026272230000359 seconds\n",
            "Finished batch 468 of 500 in 0.6955841459998737 seconds\n",
            "Finished batch 469 of 500 in 0.6897552769999038 seconds\n",
            "Finished batch 470 of 500 in 0.6912230320001527 seconds\n",
            "Finished batch 471 of 500 in 0.6923877449999054 seconds\n",
            "Finished batch 472 of 500 in 0.6942828759999884 seconds\n",
            "Finished batch 473 of 500 in 0.6968513490000987 seconds\n",
            "Finished batch 474 of 500 in 0.6976273820000642 seconds\n",
            "Finished batch 475 of 500 in 0.701096065999991 seconds\n",
            "Finished batch 476 of 500 in 0.6975375109998367 seconds\n",
            "Finished batch 477 of 500 in 0.6954298180000933 seconds\n",
            "Finished batch 478 of 500 in 0.7204742460000944 seconds\n",
            "Finished batch 479 of 500 in 0.7249053310001727 seconds\n",
            "Finished batch 480 of 500 in 0.7144121579999592 seconds\n",
            "Finished batch 481 of 500 in 0.7301455369999985 seconds\n",
            "Finished batch 482 of 500 in 0.6985875660000147 seconds\n",
            "Finished batch 483 of 500 in 0.6943046979999963 seconds\n",
            "Finished batch 484 of 500 in 0.6919636740001351 seconds\n",
            "Finished batch 485 of 500 in 0.6959827019998102 seconds\n",
            "Finished batch 486 of 500 in 0.6939179359999343 seconds\n",
            "Finished batch 487 of 500 in 0.6963912530000016 seconds\n",
            "Finished batch 488 of 500 in 0.6917192229998363 seconds\n",
            "Finished batch 489 of 500 in 0.6935433050000483 seconds\n",
            "Finished batch 490 of 500 in 0.6962002029999894 seconds\n",
            "Finished batch 491 of 500 in 0.8729782499999601 seconds\n",
            "Finished batch 492 of 500 in 0.7163703439998699 seconds\n",
            "Finished batch 493 of 500 in 0.6966233350001403 seconds\n",
            "Finished batch 494 of 500 in 0.694532425000034 seconds\n",
            "Finished batch 495 of 500 in 0.6943014869998478 seconds\n",
            "Finished batch 496 of 500 in 0.7084676720000971 seconds\n",
            "Finished batch 497 of 500 in 0.721064522000006 seconds\n",
            "Finished batch 498 of 500 in 0.7218716929999118 seconds\n",
            "Finished batch 499 of 500 in 0.7202940849999777 seconds\n",
            "Finished batch 500 of 500 in 0.7089285029999246 seconds\n",
            "Finished entire dataset in 356.46528551099993 seconds\n",
            "[[tensor([0.8245, 0.9688, 0.3047, 0.2600, 0.9923, 0.7242, 0.4798, 0.8642, 0.9886,\n",
            "        0.6302]), tensor([0, 6, 1, 7, 7, 2, 9, 2, 4, 1])], [tensor([0.9686, 0.9232, 0.9110, 0.4846, 0.9014, 0.5762, 0.9461, 0.7591, 0.8490,\n",
            "        0.5696]), tensor([5, 6, 6, 3, 1, 3, 5, 5, 8, 1])], [tensor([0.9042, 0.9331, 0.7623, 0.9798, 0.8872, 0.8112, 0.9452, 0.9543, 0.5185,\n",
            "        0.8751]), tensor([4, 2, 3, 2, 1, 2, 8, 9, 5, 0])], [tensor([0.9801, 0.5537, 0.9785, 0.9977, 0.7305, 0.9775, 0.9910, 0.9701, 0.9815,\n",
            "        0.6325]), tensor([7, 3, 7, 6, 8, 8, 7, 4, 9, 1])], [tensor([0.7699, 0.9969, 0.9411, 0.9671, 0.5888, 0.9899, 0.9889, 0.6222, 0.4619,\n",
            "        0.3699]), tensor([2, 6, 5, 9, 4, 2, 5, 1, 2, 9])], [tensor([0.9512, 0.7892, 0.8645, 0.9724, 0.9275, 0.5444, 0.9624, 0.9519, 0.8754,\n",
            "        0.6955]), tensor([1, 9, 0, 7, 5, 3, 9, 6, 3, 4])], [tensor([0.8374, 0.8216, 0.7694, 0.9657, 0.9855, 0.9918, 0.9920, 0.8106, 0.6188,\n",
            "        0.6853]), tensor([3, 4, 1, 5, 9, 7, 7, 2, 9, 2])], [tensor([0.9875, 0.8403, 0.9345, 0.9786, 0.7133, 0.9621, 0.7018, 0.9956, 0.4810,\n",
            "        0.9453]), tensor([2, 8, 5, 9, 6, 7, 8, 4, 0, 4])], [tensor([0.9971, 0.9848, 0.9944, 0.8237, 0.8083, 0.8667, 0.6270, 0.9331, 0.6245,\n",
            "        0.9811]), tensor([9, 2, 7, 1, 0, 5, 1, 8, 1, 6])], [tensor([0.8369, 0.9106, 0.9884, 0.7421, 0.9714, 0.8010, 0.8101, 0.8542, 0.9746,\n",
            "        0.8017]), tensor([5, 9, 7, 0, 4, 5, 2, 3, 5, 5])], [tensor([0.9870, 0.5646, 0.6389, 0.8868, 0.6342, 0.9715, 0.9228, 0.9358, 0.9574,\n",
            "        0.9738]), tensor([6, 0, 4, 1, 1, 5, 8, 5, 2, 4])], [tensor([0.6735, 0.9742, 0.9408, 0.8712, 0.8627, 0.8651, 0.3145, 0.8538, 0.9891,\n",
            "        0.7133]), tensor([2, 2, 5, 3, 0, 5, 8, 2, 9, 1])], [tensor([0.6920, 0.9863, 0.8141, 0.9298, 0.9227, 0.9905, 0.9379, 0.9418, 0.5659,\n",
            "        0.9773]), tensor([9, 7, 3, 8, 5, 4, 5, 9, 6, 5])], [tensor([0.9950, 0.4945, 0.9928, 0.9721, 0.8871, 0.8005, 0.6661, 0.9365, 0.9704,\n",
            "        0.9853]), tensor([6, 4, 4, 5, 3, 1, 1, 5, 6, 2])], [tensor([0.8495, 0.3166, 0.5984, 0.4575, 0.7594, 0.8080, 0.9859, 0.9650, 0.9497,\n",
            "        0.9883]), tensor([5, 0, 8, 6, 2, 2, 6, 8, 8, 6])], [tensor([0.9961, 0.9684, 0.7375, 0.8906, 0.7013, 0.6617, 0.9603, 0.9471, 0.7057,\n",
            "        0.8559]), tensor([7, 4, 0, 4, 9, 3, 4, 2, 0, 3])], [tensor([0.9222, 0.9266, 0.9261, 0.9926, 0.9872, 0.5988, 0.6756, 0.9939, 0.8655,\n",
            "        0.9350]), tensor([0, 9, 5, 7, 8, 1, 1, 7, 8, 8])], [tensor([0.9643, 0.3648, 0.7128, 0.9932, 0.9963, 0.9724, 0.8410, 0.6185, 0.8629,\n",
            "        0.9382]), tensor([3, 0, 0, 4, 7, 9, 3, 0, 9, 9])], [tensor([0.9829, 0.9709, 0.6766, 0.8045, 0.9916, 0.9862, 0.8680, 0.9800, 0.6580,\n",
            "        0.9827]), tensor([9, 2, 1, 1, 7, 4, 2, 7, 5, 5])], [tensor([0.9955, 0.8660, 0.5204, 0.9928, 0.7260, 0.9838, 0.9424, 0.9935, 0.5631,\n",
            "        0.9936]), tensor([7, 9, 5, 6, 9, 7, 5, 7, 1, 7])], [tensor([0.5142, 0.9807, 0.9908, 0.9873, 0.7671, 0.4038, 0.9202, 0.9420, 0.7792,\n",
            "        0.7744]), tensor([0, 5, 6, 7, 3, 2, 4, 5, 1, 1])], [tensor([0.9181, 0.9639, 0.3746, 0.8163, 0.9289, 0.9561, 0.9927, 0.8229, 0.7129,\n",
            "        0.8878]), tensor([8, 8, 6, 3, 2, 9, 7, 8, 1, 3])], [tensor([0.9892, 0.9003, 0.9970, 0.6259, 0.9559, 0.9679, 0.9963, 0.4939, 0.9857,\n",
            "        0.8954]), tensor([9, 8, 6, 9, 2, 4, 4, 9, 4, 2])], [tensor([0.6749, 0.8612, 0.5888, 0.7198, 0.8657, 0.9491, 0.9888, 0.7450, 0.8184,\n",
            "        0.6807]), tensor([4, 5, 2, 0, 1, 5, 1, 2, 1, 2])], [tensor([0.6018, 0.9603, 0.5240, 0.9918, 0.7496, 0.8260, 0.9103, 0.9735, 0.9604,\n",
            "        0.9961]), tensor([0, 2, 4, 4, 1, 1, 2, 9, 5, 6])], [tensor([0.9950, 0.6569, 0.8709, 0.9868, 0.9445, 0.9416, 0.8928, 0.8368, 0.9155,\n",
            "        0.9907]), tensor([4, 2, 8, 7, 2, 7, 4, 0, 2, 6])], [tensor([0.9011, 0.9888, 0.6353, 0.9602, 0.9952, 0.4842, 0.6102, 0.8022, 0.9232,\n",
            "        0.8107]), tensor([5, 8, 8, 9, 7, 8, 3, 0, 4, 1])], [tensor([0.7800, 0.7496, 0.4701, 0.9220, 0.9952, 0.7600, 0.9922, 0.9570, 0.9938,\n",
            "        0.9110]), tensor([3, 0, 0, 8, 7, 5, 9, 8, 7, 5])], [tensor([0.9277, 0.9085, 0.9961, 0.9478, 0.9881, 0.6214, 0.9403, 0.9558, 0.8013,\n",
            "        0.9724]), tensor([0, 1, 4, 5, 6, 9, 2, 2, 3, 4])], [tensor([0.8960, 0.9959, 0.4299, 0.6968, 0.9667, 0.6412, 0.8397, 0.3851, 0.9639,\n",
            "        0.9642]), tensor([5, 4, 6, 1, 8, 0, 7, 8, 7, 8])], [tensor([0.9950, 0.7805, 0.6117, 0.9245, 0.6745, 0.7231, 0.9672, 0.9921, 0.8733,\n",
            "        0.9811]), tensor([4, 5, 6, 8, 0, 3, 4, 4, 5, 9])], [tensor([0.8685, 0.9439, 0.7338, 0.5391, 0.5692, 0.6072, 0.7832, 0.9915, 0.7461,\n",
            "        0.9811]), tensor([5, 3, 2, 1, 1, 2, 1, 2, 3, 7])], [tensor([0.7189, 0.9946, 0.3732, 0.9816, 0.4507, 0.9868, 0.9985, 0.9805, 0.9325,\n",
            "        0.9068]), tensor([8, 0, 8, 6, 0, 2, 4, 9, 8, 8])], [tensor([0.9797, 0.4380, 0.6295, 0.6581, 0.9786, 0.5122, 0.9629, 0.9438, 0.6000,\n",
            "        0.8881]), tensor([7, 0, 3, 2, 6, 1, 6, 5, 3, 3])], [tensor([0.9896, 0.9807, 0.8364, 0.8619, 0.4748, 0.9697, 0.8980, 0.9260, 0.9834,\n",
            "        0.9818]), tensor([7, 4, 5, 9, 1, 4, 3, 3, 7, 5])], [tensor([0.9925, 0.9824, 0.9696, 0.9970, 0.9953, 0.2886, 0.9302, 0.9343, 0.7614,\n",
            "        0.8694]), tensor([6, 9, 2, 4, 4, 2, 5, 8, 4, 5])], [tensor([0.9561, 0.9497, 0.5429, 0.9809, 0.8179, 0.9603, 0.9014, 0.9946, 0.9822,\n",
            "        0.5754]), tensor([9, 3, 1, 9, 9, 2, 8, 6, 7, 9])], [tensor([0.9490, 0.9370, 0.9264, 0.8034, 0.8457, 0.9611, 0.4514, 0.4696, 0.5955,\n",
            "        0.6711]), tensor([5, 2, 5, 8, 1, 5, 0, 7, 0, 9])], [tensor([0.9729, 0.8684, 0.9940, 0.3706, 0.9930, 0.9871, 0.8245, 0.9668, 0.8668,\n",
            "        0.4955]), tensor([8, 5, 7, 2, 4, 7, 3, 5, 8, 3])], [tensor([0.9141, 0.9573, 0.9409, 0.8578, 0.9923, 0.9510, 0.2738, 0.9834, 0.9507,\n",
            "        0.8612]), tensor([6, 2, 9, 5, 6, 5, 2, 7, 8, 1])], [tensor([0.9072, 0.9885, 0.9846, 0.9828, 0.8994, 0.9701, 0.5132, 0.6930, 0.4017,\n",
            "        0.9868]), tensor([0, 7, 2, 2, 9, 2, 8, 1, 0, 7])], [tensor([0.9953, 0.9768, 0.9893, 0.9830, 0.9946, 0.4609, 0.9795, 0.9552, 0.8559,\n",
            "        0.9955]), tensor([7, 8, 9, 4, 4, 0, 9, 7, 1, 7])], [tensor([0.8069, 0.9851, 0.5535, 0.9633, 0.8672, 0.9456, 0.7386, 0.8338, 0.5316,\n",
            "        0.8650]), tensor([9, 7, 7, 8, 3, 4, 0, 6, 0, 0])], [tensor([0.9958, 0.9939, 0.6923, 0.9457, 0.9975, 0.9965, 0.9871, 0.9697, 0.9344,\n",
            "        0.5951]), tensor([7, 7, 3, 8, 7, 4, 4, 2, 8, 9])], [tensor([0.3578, 0.8666, 0.9901, 0.9436, 0.5066, 0.6529, 0.4867, 0.9872, 0.7872,\n",
            "        0.9446]), tensor([0, 5, 4, 8, 8, 1, 1, 7, 8, 4])], [tensor([0.9885, 0.9810, 0.9157, 0.9116, 0.9541, 0.9775, 0.7714, 0.6707, 0.4058,\n",
            "        0.8555]), tensor([4, 2, 3, 2, 2, 7, 5, 1, 1, 3])], [tensor([0.9776, 0.8215, 0.9844, 0.7436, 0.9954, 0.9870, 0.7178, 0.7774, 0.9941,\n",
            "        0.9924]), tensor([8, 3, 9, 9, 4, 9, 2, 0, 4, 6])], [tensor([0.9057, 0.5767, 0.9830, 0.7113, 0.9839, 0.9700, 0.7587, 0.8847, 0.4901,\n",
            "        0.6908]), tensor([2, 1, 8, 5, 4, 2, 3, 5, 2, 3])], [tensor([0.9548, 0.9926, 0.8298, 0.5471, 0.9955, 0.9961, 0.6946, 0.8471, 0.7866,\n",
            "        0.7075]), tensor([2, 6, 5, 8, 7, 6, 1, 0, 8, 1])], [tensor([0.9169, 0.8881, 0.5902, 0.9619, 0.9964, 0.9616, 0.9946, 0.3975, 0.9703,\n",
            "        0.7958]), tensor([3, 6, 1, 2, 6, 1, 6, 0, 7, 4])], [tensor([0.9809, 0.9920, 0.9131, 0.7414, 0.5360, 0.5602, 0.9559, 0.4951, 0.4216,\n",
            "        0.9512]), tensor([5, 4, 5, 9, 8, 2, 5, 4, 1, 8])], [tensor([0.8623, 0.2716, 0.9884, 0.9846, 0.9719, 0.8463, 0.9216, 0.7595, 0.5579,\n",
            "        0.9639]), tensor([8, 4, 6, 2, 8, 8, 1, 0, 4, 5])], [tensor([0.7876, 0.4995, 0.7676, 0.6785, 0.9029, 0.9891, 0.6066, 0.9631, 0.8163,\n",
            "        0.5911]), tensor([0, 0, 4, 5, 2, 9, 5, 4, 4, 8])], [tensor([0.5008, 0.9604, 0.9887, 0.2428, 0.7192, 0.6152, 0.9850, 0.4761, 0.9949,\n",
            "        0.5321]), tensor([1, 2, 2, 8, 1, 0, 6, 0, 7, 0])], [tensor([0.7902, 0.8458, 0.9849, 0.9758, 0.9668, 0.9338, 0.9724, 0.9611, 0.9801,\n",
            "        0.9970]), tensor([5, 3, 2, 5, 8, 1, 9, 4, 7, 7])], [tensor([0.7079, 0.9809, 0.9908, 0.5363, 0.9858, 0.9648, 0.9837, 0.8848, 0.9872,\n",
            "        0.9720]), tensor([8, 4, 7, 9, 5, 9, 7, 8, 9, 4])], [tensor([0.6805, 0.9965, 0.9928, 0.9821, 0.8230, 0.9671, 0.9932, 0.9715, 0.9867,\n",
            "        0.6503]), tensor([1, 4, 7, 6, 0, 9, 9, 5, 7, 2])], [tensor([0.5525, 0.7343, 0.8786, 0.5554, 0.6973, 0.7701, 0.9935, 0.9200, 0.9849,\n",
            "        0.9004]), tensor([1, 3, 2, 3, 3, 0, 6, 8, 9, 5])], [tensor([0.9881, 0.9909, 0.4953, 0.9900, 0.9739, 0.5403, 0.6889, 0.9389, 0.9282,\n",
            "        0.9962]), tensor([9, 7, 1, 6, 2, 4, 3, 3, 6, 4])], [tensor([0.9374, 0.9178, 0.9795, 0.7762, 0.9931, 0.6384, 0.9746, 0.6705, 0.9413,\n",
            "        0.9942]), tensor([5, 0, 7, 4, 6, 0, 2, 0, 9, 7])], [tensor([0.9905, 0.9902, 0.9966, 0.9949, 0.8181, 0.3129, 0.8980, 0.9379, 0.9827,\n",
            "        0.9594]), tensor([4, 8, 2, 6, 0, 0, 3, 8, 6, 0])], [tensor([0.6934, 0.8782, 0.9799, 0.8479, 0.9966, 0.3495, 0.9705, 0.9975, 0.9478,\n",
            "        0.9861]), tensor([6, 3, 2, 1, 4, 9, 4, 7, 5, 9])], [tensor([0.7780, 0.9593, 0.8009, 0.9017, 0.9070, 0.5045, 0.3989, 0.9819, 0.9466,\n",
            "        0.8711]), tensor([9, 6, 5, 9, 3, 5, 4, 4, 2, 5])], [tensor([0.9824, 0.9750, 0.7641, 0.8359, 0.8971, 0.4977, 0.6179, 0.9874, 0.7571,\n",
            "        0.8967]), tensor([4, 2, 2, 8, 3, 0, 0, 9, 4, 8])], [tensor([0.8656, 0.6956, 0.9142, 0.9062, 0.9763, 0.3317, 0.9239, 0.8063, 0.9863,\n",
            "        0.6103]), tensor([8, 1, 5, 0, 6, 1, 9, 8, 9, 1])], [tensor([0.8142, 0.9943, 0.6715, 0.7966, 0.7376, 0.9950, 0.8375, 0.8306, 0.9827,\n",
            "        0.9846]), tensor([1, 7, 0, 3, 2, 4, 9, 5, 9, 7])], [tensor([0.8165, 0.6944, 0.9199, 0.6926, 0.5460, 0.7613, 0.9960, 0.8160, 0.7506,\n",
            "        0.9359]), tensor([8, 1, 5, 2, 1, 2, 6, 0, 3, 2])], [tensor([0.9973, 0.9812, 0.7621, 0.9568, 0.8333, 0.6481, 0.6569, 0.9981, 0.9612,\n",
            "        0.9936]), tensor([7, 7, 2, 1, 7, 9, 9, 4, 9, 7])], [tensor([0.9856, 0.9798, 0.9790, 0.3237, 0.8511, 0.9953, 0.9484, 0.5579, 0.9566,\n",
            "        0.7505]), tensor([2, 4, 6, 5, 5, 6, 8, 5, 2, 5])], [tensor([0.9642, 0.7680, 0.9972, 0.4729, 0.4140, 0.5916, 0.6368, 0.9955, 0.9871,\n",
            "        0.6105]), tensor([2, 8, 9, 9, 2, 0, 9, 9, 5, 0])], [tensor([0.9913, 0.9524, 0.9625, 0.7989, 0.2395, 0.8411, 0.9963, 0.9960, 0.7952,\n",
            "        0.8858]), tensor([2, 5, 9, 5, 8, 2, 6, 4, 3, 0])], [tensor([0.4143, 0.8386, 0.5497, 0.9555, 0.5532, 0.9914, 0.8608, 0.9699, 0.9241,\n",
            "        0.9972]), tensor([0, 5, 1, 5, 1, 4, 1, 9, 5, 4])], [tensor([0.9741, 0.7267, 0.8787, 0.9788, 0.9501, 0.9104, 0.9228, 0.6572, 0.9889,\n",
            "        0.9202]), tensor([7, 3, 9, 5, 6, 4, 2, 6, 9, 9])], [tensor([0.3911, 0.9213, 0.9189, 0.9832, 0.9918, 0.9400, 0.9611, 0.9728, 0.7656,\n",
            "        0.9475]), tensor([0, 2, 5, 9, 4, 5, 9, 3, 1, 6])], [tensor([0.8469, 0.6065, 0.9429, 0.1872, 0.7825, 0.8443, 0.9878, 0.9484, 0.9932,\n",
            "        0.6248]), tensor([2, 6, 5, 9, 0, 8, 2, 1, 6, 0])], [tensor([0.5513, 0.9910, 0.9294, 0.6540, 0.7753, 0.9697, 0.8401, 0.9188, 0.9944,\n",
            "        0.9986]), tensor([1, 2, 1, 3, 3, 8, 3, 5, 9, 6])], [tensor([0.9802, 0.9902, 0.7183, 0.9441, 0.9903, 0.9369, 0.9663, 0.8216, 0.5285,\n",
            "        0.8601]), tensor([7, 7, 8, 5, 9, 2, 5, 2, 9, 0])], [tensor([0.6050, 0.6715, 0.8144, 0.9522, 0.9085, 0.9532, 0.9817, 0.7433, 0.7746,\n",
            "        0.7516]), tensor([9, 9, 3, 9, 3, 9, 9, 3, 2, 3])], [tensor([0.9864, 0.9953, 0.8652, 0.7665, 0.6588, 0.8098, 0.9388, 0.9623, 0.7625,\n",
            "        0.5569]), tensor([9, 7, 1, 1, 3, 9, 2, 2, 8, 3])], [tensor([0.9906, 0.8981, 0.7701, 0.9924, 0.9169, 0.9883, 0.9885, 0.9905, 0.9890,\n",
            "        0.9856]), tensor([4, 2, 1, 5, 4, 2, 9, 7, 6, 4])], [tensor([0.9984, 0.9987, 0.9992, 0.9201, 0.6059, 0.9941, 0.9573, 0.9821, 0.8991,\n",
            "        0.9121]), tensor([6, 4, 4, 7, 1, 7, 3, 8, 8, 3])], [tensor([0.4625, 0.5897, 0.9977, 0.3525, 0.4639, 0.9913, 0.4256, 0.8969, 0.9854,\n",
            "        0.9072]), tensor([9, 0, 6, 5, 1, 4, 6, 3, 2, 5])], [tensor([0.7451, 0.8238, 0.9976, 0.9938, 0.9917, 0.9929, 0.9259, 0.6239, 0.9944,\n",
            "        0.6518]), tensor([0, 1, 4, 9, 7, 7, 4, 8, 6, 0])], [tensor([0.5921, 0.8974, 0.9963, 0.9671, 0.9587, 0.9605, 0.9932, 0.2793, 0.8446,\n",
            "        0.8938]), tensor([2, 5, 4, 6, 2, 8, 2, 5, 3, 3])], [tensor([0.5699, 0.4440, 0.9917, 0.8352, 0.9913, 0.9814, 0.9274, 0.9425, 0.6090,\n",
            "        0.8152]), tensor([1, 4, 6, 9, 8, 7, 8, 5, 5, 2])], [tensor([0.9826, 0.7552, 0.9949, 0.9873, 0.9084, 0.8910, 0.8054, 0.9900, 0.6983,\n",
            "        0.7936]), tensor([9, 1, 7, 9, 8, 2, 1, 4, 2, 8])], [tensor([0.9205, 0.9528, 0.6196, 0.5894, 0.7190, 0.7534, 0.8048, 0.7998, 0.6202,\n",
            "        0.9694]), tensor([8, 9, 5, 8, 6, 1, 3, 5, 3, 4])], [tensor([0.9450, 0.9316, 0.4850, 0.7542, 0.4820, 0.9745, 0.9984, 0.9938, 0.9587,\n",
            "        0.4788]), tensor([4, 5, 8, 9, 7, 4, 7, 6, 2, 9])], [tensor([0.8540, 0.9901, 0.9913, 0.9860, 0.9797, 0.9913, 0.8637, 0.9733, 0.6667,\n",
            "        0.7987]), tensor([3, 4, 8, 7, 4, 4, 3, 2, 0, 5])], [tensor([0.2708, 0.9064, 0.9941, 0.9427, 0.9738, 0.3800, 0.8413, 0.9879, 0.8241,\n",
            "        0.9897]), tensor([2, 1, 4, 2, 2, 0, 3, 7, 9, 9])], [tensor([0.9859, 0.9935, 0.8129, 0.9013, 0.7026, 0.9760, 0.6597, 0.9988, 0.9933,\n",
            "        0.3916]), tensor([4, 9, 1, 9, 0, 2, 4, 4, 6, 2])], [tensor([0.9780, 0.9665, 0.8083, 0.3974, 0.8265, 0.9975, 0.4391, 0.9651, 0.4247,\n",
            "        0.9927]), tensor([6, 4, 1, 2, 0, 4, 8, 4, 6, 7])], [tensor([0.9932, 0.9779, 0.9086, 0.7885, 0.8156, 0.9957, 0.8006, 0.9111, 0.9950,\n",
            "        0.5442]), tensor([6, 4, 6, 1, 0, 7, 8, 5, 7, 0])], [tensor([0.8235, 0.9660, 0.9938, 0.9388, 0.9793, 0.9869, 0.9603, 0.9685, 0.9848,\n",
            "        0.9919]), tensor([0, 5, 9, 3, 9, 7, 9, 8, 6, 7])], [tensor([0.8402, 0.8833, 0.9956, 0.8141, 0.9938, 0.7874, 0.9871, 0.9155, 0.8589,\n",
            "        0.8787]), tensor([2, 8, 4, 1, 6, 1, 9, 3, 8, 1])], [tensor([0.9582, 0.4961, 0.9959, 0.9938, 0.9973, 0.9285, 0.9908, 0.7989, 0.9136,\n",
            "        0.7665]), tensor([4, 9, 5, 6, 9, 8, 7, 8, 7, 0])], [tensor([0.6567, 0.9807, 0.9672, 0.6841, 0.4233, 0.8215, 0.8609, 0.9849, 0.3762,\n",
            "        0.9722]), tensor([3, 8, 4, 2, 5, 5, 9, 4, 8, 2])], [tensor([0.9918, 0.6338, 0.9833, 0.9813, 0.9511, 0.5542, 0.5721, 0.3580, 0.9014,\n",
            "        0.5204]), tensor([4, 0, 7, 9, 2, 4, 6, 0, 5, 2])], [tensor([0.6801, 0.9926, 0.9211, 0.3313, 0.9934, 0.7563, 0.8896, 0.9782, 0.8842,\n",
            "        0.9715]), tensor([2, 7, 6, 3, 7, 9, 3, 7, 2, 5])], [tensor([0.7108, 0.9913, 0.6004, 0.9972, 0.9751, 0.9311, 0.9902, 0.7943, 0.9958,\n",
            "        0.7543]), tensor([8, 7, 1, 7, 5, 3, 7, 8, 9, 1])], [tensor([0.5071, 0.8109, 0.9714, 0.9933, 0.7355, 0.9715, 0.5167, 0.9767, 0.9909,\n",
            "        0.6765]), tensor([0, 8, 2, 4, 0, 2, 7, 2, 9, 9])], [tensor([0.9906, 0.5524, 0.6874, 0.7981, 0.9793, 0.8418, 0.7980, 0.9254, 0.9784,\n",
            "        0.6029]), tensor([9, 1, 9, 3, 9, 0, 3, 5, 8, 1])], [tensor([0.9433, 0.8563, 0.8850, 0.4035, 0.9877, 0.9901, 0.9928, 0.9557, 0.6973,\n",
            "        0.9031]), tensor([2, 5, 3, 0, 7, 6, 2, 4, 5, 0])], [tensor([0.9892, 0.8501, 0.9642, 0.9436, 0.9937, 0.9892, 0.9707, 0.8571, 0.9297,\n",
            "        0.9958]), tensor([4, 5, 8, 4, 7, 2, 7, 8, 5, 9])], [tensor([0.9924, 0.9899, 0.6255, 0.9796, 0.8858, 0.9889, 0.9501, 0.8718, 0.4667,\n",
            "        0.9906]), tensor([2, 2, 4, 5, 5, 2, 1, 5, 2, 7])], [tensor([0.6246, 0.7262, 0.9552, 0.9747, 0.9398, 0.5795, 0.9955, 0.9913, 0.9551,\n",
            "        0.9695]), tensor([3, 8, 8, 4, 2, 3, 9, 2, 2, 5])], [tensor([0.9928, 0.9873, 0.8777, 0.9114, 0.9307, 0.4753, 0.9315, 0.9951, 0.9794,\n",
            "        0.8235]), tensor([4, 4, 5, 2, 5, 7, 8, 9, 9, 8])], [tensor([0.7837, 0.9113, 0.6065, 0.9950, 0.7821, 0.9940, 0.9806, 0.9792, 0.9099,\n",
            "        0.5914]), tensor([8, 6, 1, 7, 2, 4, 8, 9, 3, 9])], [tensor([0.9854, 0.9335, 0.9974, 0.9784, 0.9545, 0.8841, 0.9340, 0.9487, 0.9906,\n",
            "        0.7600]), tensor([6, 3, 7, 0, 4, 8, 0, 0, 4, 9])], [tensor([0.7846, 0.9042, 0.9936, 0.9899, 0.6894, 0.9947, 0.9909, 0.7671, 0.7359,\n",
            "        0.9974]), tensor([2, 5, 4, 7, 3, 9, 9, 8, 0, 6])], [tensor([0.8613, 0.8777, 0.6007, 0.8476, 0.8704, 0.7198, 0.9270, 0.5986, 0.9775,\n",
            "        0.8820]), tensor([1, 1, 1, 3, 8, 0, 9, 1, 6, 5])], [tensor([0.8056, 0.9238, 0.9584, 0.9160, 0.9505, 0.9801, 0.7682, 0.9973, 0.9941,\n",
            "        0.3638]), tensor([1, 5, 6, 1, 9, 9, 5, 7, 6, 0])], [tensor([0.8192, 0.8763, 0.7499, 0.9945, 0.9935, 0.9455, 0.5545, 0.7742, 0.9896,\n",
            "        0.8404]), tensor([5, 8, 1, 7, 4, 8, 1, 0, 6, 5])], [tensor([0.9571, 0.8842, 0.9546, 0.9902, 0.6403, 0.9168, 0.8232, 0.8142, 0.8877,\n",
            "        0.9727]), tensor([2, 8, 5, 6, 3, 6, 3, 5, 1, 6])], [tensor([0.9978, 0.5475, 0.3162, 0.7709, 0.9435, 0.9182, 0.8568, 0.6694, 0.9297,\n",
            "        0.9493]), tensor([6, 3, 3, 4, 0, 5, 3, 9, 3, 5])], [tensor([0.7992, 0.9053, 0.5788, 0.9945, 0.9697, 0.9867, 0.9940, 0.8635, 0.8167,\n",
            "        0.9934]), tensor([3, 1, 1, 4, 7, 5, 7, 8, 9, 6])], [tensor([0.9869, 0.7124, 0.9608, 0.8026, 0.8932, 0.4669, 0.8697, 0.9927, 0.9147,\n",
            "        0.9426]), tensor([4, 3, 9, 4, 0, 2, 1, 4, 8, 2])], [tensor([0.3479, 0.9901, 0.9978, 0.9585, 0.9014, 0.9909, 0.6636, 0.9532, 0.8305,\n",
            "        0.9353]), tensor([8, 2, 7, 2, 9, 6, 9, 2, 3, 3])], [tensor([0.9427, 0.4308, 0.9478, 0.9245, 0.9753, 0.9653, 0.9777, 0.9692, 0.9781,\n",
            "        0.8950]), tensor([5, 6, 8, 8, 8, 5, 9, 8, 8, 8])], [tensor([0.9795, 0.9835, 0.9853, 0.7655, 0.7854, 0.4264, 0.9568, 0.9274, 0.5713,\n",
            "        0.8780]), tensor([5, 2, 7, 1, 3, 1, 8, 6, 3, 3])], [tensor([0.6549, 0.6511, 0.8421, 0.5162, 0.7719, 0.9133, 0.9945, 0.7110, 0.9440,\n",
            "        0.9670]), tensor([5, 0, 8, 1, 3, 9, 7, 0, 1, 1])], [tensor([0.8410, 0.9852, 0.9978, 0.7276, 0.8044, 0.9468, 0.9794, 0.9849, 0.9284,\n",
            "        0.9284]), tensor([9, 4, 7, 0, 0, 7, 9, 7, 5, 8])], [tensor([0.9497, 0.8369, 0.8812, 0.7164, 0.9923, 0.8205, 0.6565, 0.9548, 0.9649,\n",
            "        0.9417]), tensor([8, 5, 5, 2, 7, 5, 5, 4, 6, 2])], [tensor([0.9403, 0.9844, 0.4848, 0.9752, 0.9277, 0.9780, 0.9952, 0.9386, 0.9630,\n",
            "        0.9956]), tensor([4, 2, 6, 9, 5, 6, 7, 2, 6, 4])], [tensor([0.7796, 0.8273, 0.8527, 0.9903, 0.9186, 0.8411, 0.4794, 0.9969, 0.9393,\n",
            "        0.5331]), tensor([5, 1, 3, 5, 8, 1, 8, 7, 5, 0])], [tensor([0.9209, 0.6531, 0.9814, 0.6162, 0.7295, 0.4208, 0.4028, 0.9830, 0.8721,\n",
            "        0.9257]), tensor([8, 1, 9, 1, 3, 3, 7, 6, 8, 8])], [tensor([0.6137, 0.7650, 0.9909, 0.9915, 0.9238, 0.9783, 0.9313, 0.9437, 0.5374,\n",
            "        0.8968]), tensor([3, 3, 7, 7, 5, 7, 8, 8, 1, 2])], [tensor([0.4228, 0.9884, 0.6590, 0.9438, 0.9232, 0.9025, 0.9940, 0.9918, 0.9401,\n",
            "        0.9988]), tensor([6, 4, 2, 5, 9, 2, 7, 4, 8, 6])], [tensor([0.8518, 0.9973, 0.9750, 0.9622, 0.7597, 0.9861, 0.4930, 0.9624, 0.7067,\n",
            "        0.9216]), tensor([2, 4, 9, 9, 0, 2, 0, 9, 9, 2])], [tensor([0.9800, 0.9061, 0.5890, 0.9951, 0.9409, 0.8176, 0.3821, 0.9306, 0.9764,\n",
            "        0.9955]), tensor([4, 9, 5, 2, 2, 3, 8, 1, 9, 6])], [tensor([0.5452, 0.9837, 0.9627, 0.9530, 0.9925, 0.9783, 0.9913, 0.9092, 0.9520,\n",
            "        0.9817]), tensor([1, 6, 5, 5, 7, 4, 4, 2, 2, 5])], [tensor([0.9586, 0.7802, 0.9855, 0.7399, 0.8326, 0.9934, 0.9977, 0.8089, 0.9654,\n",
            "        0.8767]), tensor([4, 1, 6, 8, 8, 6, 7, 8, 2, 1])], [tensor([0.9928, 0.9642, 0.8985, 0.7329, 0.9716, 0.9888, 0.9814, 0.9021, 0.9873,\n",
            "        0.8699]), tensor([7, 7, 1, 1, 9, 6, 7, 8, 8, 1])], [tensor([0.8847, 0.9952, 0.9541, 0.9728, 0.4555, 0.9823, 0.9681, 0.8372, 0.8522,\n",
            "        0.4888]), tensor([5, 7, 8, 2, 6, 9, 7, 3, 1, 8])], [tensor([0.7065, 0.9722, 0.9963, 0.6988, 0.6680, 0.8992, 0.9628, 0.8792, 0.8999,\n",
            "        0.9811]), tensor([8, 7, 6, 2, 3, 1, 3, 5, 1, 4])], [tensor([0.9961, 0.8520, 0.6683, 0.9966, 0.9217, 0.9153, 0.8619, 0.9964, 0.9739,\n",
            "        0.9523]), tensor([7, 1, 1, 6, 8, 5, 6, 7, 0, 7])], [tensor([0.9894, 0.9023, 0.9955, 0.3442, 0.9948, 0.9104, 0.8614, 0.8917, 0.9877,\n",
            "        0.8220]), tensor([7, 2, 8, 9, 7, 4, 3, 8, 7, 0])], [tensor([0.9411, 0.9600, 0.8548, 0.9971, 0.9764, 0.9335, 0.9777, 0.9899, 0.7148,\n",
            "        0.9932]), tensor([8, 2, 8, 6, 2, 2, 5, 2, 9, 8])], [tensor([0.8076, 0.8665, 0.9994, 0.7400, 0.6046, 0.9809, 0.8675, 0.9347, 0.9953,\n",
            "        0.9932]), tensor([3, 7, 6, 3, 5, 9, 8, 9, 9, 7])], [tensor([0.9355, 0.7776, 0.9522, 0.9976, 0.9199, 0.5058, 0.7774, 0.6101, 0.9975,\n",
            "        0.8181]), tensor([8, 0, 8, 4, 2, 1, 3, 0, 6, 9])], [tensor([0.8267, 0.9238, 0.6976, 0.9892, 0.7158, 0.9976, 0.8256, 0.7341, 0.9947,\n",
            "        0.9715]), tensor([3, 2, 3, 9, 3, 6, 3, 1, 6, 5])], [tensor([0.9865, 0.9876, 0.7782, 0.8660, 0.7926, 0.8298, 0.9949, 0.3225, 0.8973,\n",
            "        0.9486]), tensor([2, 2, 0, 6, 3, 3, 6, 8, 2, 2])], [tensor([0.8204, 0.8307, 0.9503, 0.9786, 0.9813, 0.9504, 0.9170, 0.9950, 0.9661,\n",
            "        0.9831]), tensor([2, 6, 9, 8, 8, 8, 8, 6, 2, 4])], [tensor([0.9838, 0.9918, 0.9955, 0.9781, 0.9957, 0.4737, 0.9836, 0.9024, 0.9482,\n",
            "        0.9193]), tensor([6, 4, 7, 4, 4, 2, 7, 3, 2, 5])], [tensor([0.3520, 0.9264, 0.8809, 0.9467, 0.9946, 0.7790, 0.9954, 0.9927, 0.9960,\n",
            "        0.8157]), tensor([2, 9, 5, 8, 7, 1, 4, 6, 6, 3])], [tensor([0.4784, 0.9826, 0.9924, 0.8928, 0.8944, 0.3164, 0.9057, 0.9570, 0.9743,\n",
            "        0.8830]), tensor([0, 6, 7, 9, 2, 2, 8, 6, 9, 0])], [tensor([0.9510, 0.9932, 0.8681, 0.9703, 0.9870, 0.9974, 0.9822, 0.5336, 0.9993,\n",
            "        0.9135]), tensor([3, 7, 8, 3, 4, 6, 6, 2, 7, 2])], [tensor([0.9984, 0.6764, 0.9888, 0.8789, 0.9523, 0.7483, 0.9699, 0.9939, 0.8760,\n",
            "        0.8633]), tensor([4, 0, 7, 1, 5, 2, 4, 7, 2, 3])], [tensor([0.8982, 0.6056, 0.9914, 0.9902, 0.9977, 0.7596, 0.9493, 0.9956, 0.6888,\n",
            "        0.9803]), tensor([8, 9, 7, 9, 4, 5, 2, 6, 0, 8])], [tensor([0.9875, 0.9962, 0.9774, 0.9674, 0.7042, 0.3713, 0.4736, 0.9674, 0.9512,\n",
            "        0.8543]), tensor([9, 7, 2, 2, 5, 5, 7, 8, 8, 3])], [tensor([0.7850, 0.9961, 0.9176, 0.8300, 0.9791, 0.9942, 0.9144, 0.7454, 0.9112,\n",
            "        0.9791]), tensor([6, 2, 1, 3, 7, 4, 0, 4, 6, 9])], [tensor([0.6025, 0.7365, 0.6873, 0.9947, 0.9850, 0.9941, 0.5957, 0.8306, 0.9982,\n",
            "        0.6810]), tensor([9, 9, 1, 7, 4, 4, 5, 9, 7, 4])], [tensor([0.9967, 0.8081, 0.6017, 0.7903, 0.9739, 0.8737, 0.8129, 0.7869, 0.9812,\n",
            "        0.9195]), tensor([7, 0, 9, 1, 9, 5, 8, 3, 7, 7])], [tensor([0.9029, 0.9680, 0.9011, 0.9644, 0.9131, 0.8306, 0.9729, 0.4040, 0.9942,\n",
            "        0.6573]), tensor([8, 2, 2, 9, 1, 3, 4, 1, 9, 9])], [tensor([0.9418, 0.9119, 0.9548, 0.9462, 0.9249, 0.9611, 0.9719, 0.9412, 0.9221,\n",
            "        0.9306]), tensor([9, 8, 3, 5, 3, 9, 2, 4, 5, 4])], [tensor([0.9496, 0.8801, 0.4662, 0.8678, 0.9915, 0.9328, 0.8982, 0.8047, 0.9966,\n",
            "        0.9320]), tensor([2, 5, 9, 8, 7, 5, 0, 5, 6, 5])], [tensor([0.9515, 0.8874, 0.9642, 0.7298, 0.5634, 0.9802, 0.6748, 0.8964, 0.7467,\n",
            "        0.9910]), tensor([3, 5, 2, 8, 6, 8, 9, 3, 5, 7])], [tensor([0.9854, 0.9878, 0.9856, 0.9935, 0.9550, 0.9815, 0.7993, 0.9863, 0.7260,\n",
            "        0.9880]), tensor([6, 9, 2, 7, 5, 6, 8, 6, 5, 4])], [tensor([0.8894, 0.9758, 0.5476, 0.5056, 0.9480, 0.8000, 0.5193, 0.5705, 0.9925,\n",
            "        0.9806]), tensor([6, 8, 5, 1, 3, 4, 0, 1, 4, 7])], [tensor([0.9624, 0.5147, 0.8769, 0.8432, 0.9806, 0.9867, 0.9201, 0.9959, 0.5135,\n",
            "        0.7596]), tensor([8, 2, 5, 0, 8, 7, 8, 7, 4, 1])], [tensor([0.6707, 0.8789, 0.6630, 0.6369, 0.9063, 0.8457, 0.7334, 0.8279, 0.9156,\n",
            "        0.9881]), tensor([0, 6, 5, 3, 1, 9, 3, 1, 8, 4])], [tensor([0.7742, 0.5168, 0.9853, 0.9892, 0.9534, 0.9929, 0.9947, 0.9915, 0.9906,\n",
            "        0.5162]), tensor([5, 5, 4, 9, 2, 4, 6, 8, 9, 1])], [tensor([0.9557, 0.9866, 0.9844, 0.8774, 0.9961, 0.7730, 0.8193, 0.8869, 0.5539,\n",
            "        0.9305]), tensor([5, 2, 6, 2, 7, 8, 3, 4, 9, 6])], [tensor([0.7409, 0.8558, 0.9470, 0.9060, 0.6472, 0.8273, 0.9907, 0.9713, 0.5067,\n",
            "        0.9957]), tensor([9, 5, 3, 3, 1, 0, 2, 9, 9, 6])], [tensor([0.8378, 0.9005, 0.3676, 0.9912, 0.9897, 0.8620, 0.6615, 0.8892, 0.7095,\n",
            "        0.5375]), tensor([8, 5, 4, 9, 8, 1, 5, 5, 0, 4])], [tensor([0.8119, 0.2282, 0.8247, 0.9886, 0.8551, 0.7909, 0.6449, 0.7801, 0.6728,\n",
            "        0.9881]), tensor([5, 5, 8, 7, 0, 1, 6, 1, 0, 7])], [tensor([0.9886, 0.9122, 0.9885, 0.6639, 0.8260, 0.5477, 0.9898, 0.9292, 0.8166,\n",
            "        0.4841]), tensor([6, 8, 9, 8, 9, 9, 4, 5, 4, 9])], [tensor([0.9275, 0.9713, 0.9789, 0.8755, 0.7386, 0.9927, 0.8993, 0.9556, 0.5584,\n",
            "        0.9832]), tensor([8, 7, 6, 5, 0, 8, 3, 2, 0, 4])], [tensor([0.9757, 0.9922, 0.8556, 0.9967, 0.9973, 0.9576, 0.9804, 0.9765, 0.8201,\n",
            "        0.9964]), tensor([8, 6, 6, 4, 2, 6, 9, 2, 5, 4])], [tensor([0.9648, 0.9571, 0.7890, 0.8441, 0.9088, 0.9683, 0.9412, 0.8066, 0.8911,\n",
            "        0.9902]), tensor([9, 2, 8, 0, 1, 8, 5, 8, 3, 4])], [tensor([0.5293, 0.9536, 0.9619, 0.5938, 0.9704, 0.9544, 0.8645, 0.9924, 0.9725,\n",
            "        0.4399]), tensor([0, 4, 4, 1, 2, 2, 6, 2, 5, 7])], [tensor([0.9855, 0.6917, 0.3903, 0.8620, 0.9336, 0.7602, 0.8030, 0.5942, 0.9969,\n",
            "        0.9956]), tensor([5, 1, 5, 9, 8, 0, 5, 8, 7, 7])], [tensor([0.5317, 0.6596, 0.9917, 0.9989, 0.9301, 0.9592, 0.5684, 0.9916, 0.4216,\n",
            "        0.8680]), tensor([1, 2, 9, 7, 1, 8, 7, 6, 0, 5])], [tensor([0.9791, 0.8603, 0.4385, 0.9970, 0.6304, 0.9917, 0.9960, 0.7502, 0.9982,\n",
            "        0.9685]), tensor([8, 3, 8, 4, 6, 4, 7, 1, 7, 7])], [tensor([0.3889, 0.8026, 0.9706, 0.8811, 0.9062, 0.9632, 0.9949, 0.7089, 0.9049,\n",
            "        0.6202]), tensor([2, 2, 9, 2, 9, 8, 7, 1, 6, 1])], [tensor([0.9823, 0.8718, 0.9981, 0.9978, 0.5312, 0.9985, 0.8173, 0.8720, 0.8948,\n",
            "        0.9804]), tensor([4, 4, 6, 6, 3, 4, 0, 0, 9, 2])], [tensor([0.8890, 0.9132, 0.9684, 0.8836, 0.9785, 0.4731, 0.9258, 0.9915, 0.9872,\n",
            "        0.9972]), tensor([9, 1, 8, 8, 7, 1, 2, 4, 9, 4])], [tensor([0.9884, 0.9803, 0.8429, 0.9839, 0.7425, 0.9908, 0.5640, 0.9892, 0.9779,\n",
            "        0.9832]), tensor([2, 9, 9, 2, 9, 4, 9, 7, 8, 7])], [tensor([0.9975, 0.6139, 0.9451, 0.7836, 0.9908, 0.9077, 0.5982, 0.9118, 0.3810,\n",
            "        0.9956]), tensor([6, 7, 5, 1, 6, 2, 1, 8, 5, 7])], [tensor([0.7671, 0.9734, 0.9928, 0.9123, 0.9894, 0.9168, 0.9404, 0.9018, 0.5448,\n",
            "        0.9984]), tensor([9, 5, 6, 5, 6, 8, 4, 3, 6, 4])], [tensor([0.9968, 0.9665, 0.9870, 0.8266, 0.9839, 0.9819, 0.2909, 0.9810, 0.7083,\n",
            "        0.9700]), tensor([7, 5, 2, 2, 4, 9, 5, 7, 6, 2])], [tensor([0.6601, 0.9922, 0.9936, 0.9894, 0.8645, 0.9888, 0.8460, 0.9667, 0.9630,\n",
            "        0.5965]), tensor([8, 9, 6, 2, 8, 9, 8, 5, 7, 0])], [tensor([0.9978, 0.7726, 0.9946, 0.9951, 0.9954, 0.6831, 0.9829, 0.9210, 0.9955,\n",
            "        0.9640]), tensor([6, 2, 7, 2, 9, 3, 6, 9, 7, 9])], [tensor([0.8497, 0.5835, 0.9255, 0.9743, 0.9921, 0.9898, 0.9827, 0.5058, 0.9091,\n",
            "        0.9889]), tensor([1, 1, 8, 5, 6, 6, 5, 0, 9, 7])], [tensor([0.9936, 0.5891, 0.9899, 0.9761, 0.3501, 0.9830, 0.9845, 0.9965, 0.9923,\n",
            "        0.9732]), tensor([4, 1, 6, 4, 7, 9, 8, 7, 4, 4])], [tensor([0.9563, 0.9945, 0.9660, 0.6602, 0.8453, 0.7268, 0.8554, 0.9841, 0.9793,\n",
            "        0.9902]), tensor([2, 7, 6, 8, 1, 0, 5, 6, 6, 6])], [tensor([0.9486, 0.5996, 0.9600, 0.8212, 0.9418, 0.4326, 0.9655, 0.9469, 0.8448,\n",
            "        0.9233]), tensor([4, 3, 9, 0, 5, 2, 4, 5, 3, 9])], [tensor([0.9929, 0.9919, 0.9764, 0.9898, 0.9799, 0.7199, 0.9949, 0.8725, 0.5871,\n",
            "        0.8781]), tensor([9, 7, 8, 7, 2, 5, 7, 5, 9, 8])], [tensor([0.9339, 0.9846, 0.9922, 0.7817, 0.9847, 0.9911, 0.7197, 0.9535, 0.8983,\n",
            "        0.6652]), tensor([0, 9, 2, 5, 2, 9, 3, 2, 0, 6])], [tensor([0.9202, 0.9821, 0.9783, 0.9857, 0.9975, 0.9946, 0.4866, 0.9939, 0.9962,\n",
            "        0.8593]), tensor([1, 6, 5, 4, 6, 6, 2, 2, 4, 1])], [tensor([0.5227, 0.8345, 0.9942, 0.4195, 0.6145, 0.9131, 0.6159, 0.9424, 0.9360,\n",
            "        0.7110]), tensor([3, 5, 4, 8, 2, 9, 6, 3, 3, 9])], [tensor([0.8833, 0.9842, 0.3735, 0.6823, 0.9835, 0.8728, 0.9827, 0.9824, 0.9943,\n",
            "        0.9315]), tensor([3, 9, 5, 3, 7, 8, 4, 8, 9, 8])], [tensor([0.7931, 0.9943, 0.5016, 0.6018, 0.9883, 0.7379, 0.3720, 0.5088, 0.9734,\n",
            "        0.9429]), tensor([9, 7, 5, 5, 7, 1, 2, 0, 6, 8])], [tensor([0.9257, 0.8141, 0.9984, 0.9919, 0.7440, 0.8969, 0.8690, 0.6895, 0.7525,\n",
            "        0.8967]), tensor([8, 6, 4, 6, 3, 1, 3, 9, 8, 4])], [tensor([0.2177, 0.9752, 0.9658, 0.9801, 0.9846, 0.5044, 0.9629, 0.4211, 0.9818,\n",
            "        0.9137]), tensor([2, 2, 6, 6, 7, 1, 8, 2, 6, 5])], [tensor([0.7666, 0.7235, 0.9953, 0.9974, 0.2899, 0.7893, 0.8546, 0.6998, 0.8736,\n",
            "        0.9393]), tensor([8, 1, 7, 4, 2, 0, 9, 1, 7, 1])], [tensor([0.8852, 0.4582, 0.8703, 0.9879, 0.9994, 0.9888, 0.8580, 0.9962, 0.6471,\n",
            "        0.6104]), tensor([5, 2, 9, 6, 6, 7, 8, 7, 8, 1])], [tensor([0.4184, 0.8433, 0.9506, 0.9773, 0.8464, 0.8168, 0.8429, 0.9552, 0.7307,\n",
            "        0.9525]), tensor([0, 9, 6, 5, 3, 3, 0, 5, 3, 2])], [tensor([0.9643, 0.9802, 0.9760, 0.9791, 0.9893, 0.5509, 0.9542, 0.4384, 0.8470,\n",
            "        0.9713]), tensor([7, 8, 7, 9, 6, 9, 9, 0, 1, 9])], [tensor([0.9892, 0.5236, 0.9968, 0.7248, 0.4975, 0.9689, 0.9951, 0.7587, 0.9645,\n",
            "        0.3685]), tensor([7, 0, 7, 4, 7, 5, 8, 2, 4, 7])], [tensor([0.9879, 0.9616, 0.6840, 0.8352, 0.9385, 0.9926, 0.9023, 0.9737, 0.9836,\n",
            "        0.8189]), tensor([7, 5, 0, 9, 7, 4, 3, 4, 9, 0])], [tensor([0.9948, 0.7727, 0.9511, 0.9805, 0.9196, 0.8179, 0.4507, 0.9609, 0.9825,\n",
            "        0.9541]), tensor([6, 9, 5, 2, 8, 5, 2, 4, 4, 8])], [tensor([0.9944, 0.8449, 0.3920, 0.8752, 0.9994, 0.6274, 0.9862, 0.9866, 0.8137,\n",
            "        0.9891]), tensor([7, 3, 0, 9, 4, 0, 4, 6, 2, 4])], [tensor([0.8283, 0.6199, 0.9930, 0.7124, 0.7500, 0.7636, 0.9544, 0.9874, 0.8277,\n",
            "        0.9565]), tensor([2, 7, 7, 0, 8, 6, 2, 8, 8, 9])], [tensor([0.9856, 0.9904, 0.8756, 0.8340, 0.9738, 0.9292, 0.7778, 0.9704, 0.9653,\n",
            "        0.8837]), tensor([9, 9, 1, 3, 5, 2, 3, 2, 5, 2])], [tensor([0.9986, 0.7036, 0.7078, 0.9919, 0.8879, 0.7442, 0.3104, 0.9186, 0.7986,\n",
            "        0.9847]), tensor([4, 8, 3, 7, 3, 5, 0, 2, 0, 2])], [tensor([0.9963, 0.9944, 0.6168, 0.9756, 0.9017, 0.9944, 0.9941, 0.9870, 0.9941,\n",
            "        0.9901]), tensor([6, 7, 0, 6, 9, 9, 4, 2, 7, 4])], [tensor([0.7922, 0.8358, 0.9865, 0.9894, 0.9812, 0.8438, 0.9236, 0.9731, 0.2379,\n",
            "        0.9181]), tensor([0, 2, 9, 7, 6, 3, 0, 8, 2, 5])], [tensor([0.9292, 0.7088, 0.9969, 0.6924, 0.9845, 0.3575, 0.9892, 0.5256, 0.9674,\n",
            "        0.8857]), tensor([6, 0, 6, 9, 9, 3, 8, 9, 4, 8])], [tensor([0.9737, 0.5479, 0.9873, 0.9367, 0.9711, 0.8403, 0.9937, 0.9551, 0.8518,\n",
            "        0.9610]), tensor([0, 0, 8, 5, 4, 4, 9, 7, 3, 1])], [tensor([0.9961, 0.9810, 0.9907, 0.9900, 0.9763, 0.9752, 0.7733, 0.8169, 0.7243,\n",
            "        0.9616]), tensor([4, 2, 9, 2, 9, 6, 2, 0, 3, 0])], [tensor([0.9870, 0.8602, 0.9792, 0.7547, 0.9853, 0.9808, 0.9973, 0.9785, 0.8843,\n",
            "        0.9924]), tensor([9, 8, 9, 3, 8, 9, 7, 4, 5, 4])], [tensor([0.9571, 0.6327, 0.9795, 0.9802, 0.8969, 0.6268, 0.9995, 0.9912, 0.9119,\n",
            "        0.9732]), tensor([4, 1, 5, 9, 5, 3, 6, 2, 3, 9])], [tensor([0.5493, 0.4668, 0.9247, 0.9643, 0.7750, 0.3892, 0.9935, 0.8990, 0.8701,\n",
            "        0.4579]), tensor([7, 2, 8, 9, 3, 1, 2, 5, 8, 3])], [tensor([0.5973, 0.9880, 0.9170, 0.8224, 0.8859, 0.8214, 0.9920, 0.6844, 0.9331,\n",
            "        0.2051]), tensor([0, 2, 3, 3, 0, 3, 9, 1, 7, 0])], [tensor([0.9966, 0.8969, 0.9952, 0.9600, 0.9683, 0.7692, 0.9738, 0.9815, 0.9930,\n",
            "        0.9827]), tensor([7, 2, 7, 2, 7, 3, 9, 7, 9, 1])], [tensor([0.7488, 0.5629, 0.9978, 0.9778, 0.9862, 0.8593, 0.6560, 0.9390, 0.6158,\n",
            "        0.9924]), tensor([3, 9, 7, 9, 9, 8, 4, 2, 1, 4])], [tensor([0.9857, 0.8552, 0.5313, 0.8396, 0.9909, 0.9448, 0.9920, 0.9947, 0.4735,\n",
            "        0.9773]), tensor([6, 8, 4, 0, 6, 9, 9, 7, 8, 4])], [tensor([0.9019, 0.6881, 0.9879, 0.9610, 0.8387, 0.9813, 0.9838, 0.9951, 0.4838,\n",
            "        0.6639]), tensor([3, 2, 8, 8, 5, 7, 4, 7, 0, 1])], [tensor([0.3202, 0.9934, 0.5764, 0.9877, 0.5136, 0.8166, 0.9188, 0.9684, 0.9944,\n",
            "        0.9016]), tensor([2, 6, 9, 6, 0, 5, 5, 6, 6, 5])], [tensor([0.8118, 0.9906, 0.7061, 0.8133, 0.5784, 0.9533, 0.6128, 0.4436, 0.9656,\n",
            "        0.9691]), tensor([8, 4, 9, 8, 0, 8, 0, 8, 7, 9])], [tensor([0.5839, 0.9783, 0.9808, 0.5632, 0.9828, 0.8161, 0.6612, 0.9563, 0.7932,\n",
            "        0.5936]), tensor([1, 7, 6, 8, 4, 3, 5, 2, 2, 3])], [tensor([0.6874, 0.9236, 0.8063, 0.9946, 0.9927, 0.9897, 0.4494, 0.8751, 0.2406,\n",
            "        0.8693]), tensor([0, 9, 3, 9, 4, 4, 1, 5, 5, 4])], [tensor([0.8992, 0.9640, 0.3171, 0.8157, 0.7883, 0.7239, 0.9973, 0.8607, 0.7213,\n",
            "        0.3535]), tensor([3, 5, 0, 0, 8, 1, 7, 6, 5, 7])], [tensor([0.3549, 0.9696, 0.9335, 0.9554, 0.9823, 0.6396, 0.7536, 0.3191, 0.9816,\n",
            "        0.9925]), tensor([3, 7, 9, 8, 4, 9, 8, 2, 6, 9])], [tensor([0.9492, 0.7496, 0.8650, 0.9921, 0.7237, 0.9074, 0.7771, 0.9180, 0.8470,\n",
            "        0.9345]), tensor([3, 0, 1, 4, 9, 5, 0, 2, 1, 8])], [tensor([0.9988, 0.8260, 0.6471, 0.3892, 0.6332, 0.9269, 0.9699, 0.9230, 0.9763,\n",
            "        0.9942]), tensor([4, 3, 1, 2, 3, 8, 9, 0, 4, 7])], [tensor([0.9513, 0.9535, 0.9688, 0.9751, 0.8200, 0.9964, 0.9919, 0.9023, 0.8122,\n",
            "        0.8726]), tensor([4, 8, 5, 9, 2, 8, 4, 5, 2, 8])], [tensor([0.9933, 0.7450, 0.9981, 0.5722, 0.8906, 0.9209, 0.9911, 0.8396, 0.8817,\n",
            "        0.9749]), tensor([4, 8, 7, 2, 4, 4, 7, 7, 4, 2])], [tensor([0.9568, 0.9714, 0.9780, 0.8358, 0.6637, 0.6419, 0.9926, 0.9603, 0.9944,\n",
            "        0.9714]), tensor([0, 2, 9, 3, 1, 1, 7, 3, 7, 2])], [tensor([0.9336, 0.7618, 0.8590, 0.9978, 0.8614, 0.5819, 0.6917, 0.9597, 0.9967,\n",
            "        0.7429]), tensor([4, 9, 4, 4, 3, 1, 8, 7, 2, 0])], [tensor([0.4265, 0.5231, 0.8869, 0.9631, 0.9226, 0.9856, 0.8383, 0.9844, 0.5896,\n",
            "        0.6435]), tensor([2, 1, 3, 8, 6, 4, 0, 7, 2, 1])], [tensor([0.8178, 0.6114, 0.5817, 0.5729, 0.9849, 0.5305, 0.9099, 0.9559, 0.9719,\n",
            "        0.9911]), tensor([3, 2, 8, 8, 5, 3, 0, 8, 2, 7])], [tensor([0.9601, 0.8069, 0.9717, 0.9847, 0.9949, 0.9829, 0.9527, 0.9900, 0.9974,\n",
            "        0.9952]), tensor([2, 8, 2, 5, 6, 7, 5, 9, 6, 6])], [tensor([0.9903, 0.3598, 0.9654, 0.9816, 0.9939, 0.9922, 0.8975, 0.9974, 0.9306,\n",
            "        0.9463]), tensor([6, 0, 5, 7, 6, 6, 0, 7, 1, 8])], [tensor([0.6266, 0.9156, 0.7371, 0.9752, 0.9778, 0.7133, 0.9868, 0.9282, 0.6652,\n",
            "        0.9089]), tensor([3, 8, 5, 2, 7, 9, 8, 8, 3, 6])], [tensor([0.8377, 0.9551, 0.9983, 0.8163, 0.9749, 0.6417, 0.7032, 0.5959, 0.6734,\n",
            "        0.2257]), tensor([8, 2, 6, 0, 5, 0, 1, 9, 4, 5])], [tensor([0.9446, 0.8588, 0.8857, 0.9597, 0.9814, 0.8966, 0.6608, 0.9644, 0.6722,\n",
            "        0.8200]), tensor([8, 3, 3, 4, 7, 2, 0, 2, 0, 3])], [tensor([0.8860, 0.9931, 0.9868, 0.9672, 0.9489, 0.9761, 0.7125, 0.9741, 0.9865,\n",
            "        0.8436]), tensor([9, 6, 7, 7, 4, 6, 5, 2, 4, 3])], [tensor([0.9815, 0.6795, 0.7255, 0.9595, 0.9778, 0.9704, 0.9941, 0.9660, 0.3728,\n",
            "        0.9979]), tensor([6, 7, 3, 5, 8, 7, 6, 6, 2, 7])], [tensor([0.9055, 0.6168, 0.9360, 0.7974, 0.5284, 0.9687, 0.8497, 0.9596, 0.9923,\n",
            "        0.8861]), tensor([3, 0, 1, 0, 3, 3, 2, 9, 7, 2])], [tensor([0.9241, 0.5361, 0.9110, 0.9182, 0.9980, 0.9793, 0.8658, 0.9919, 0.9746,\n",
            "        0.9742]), tensor([1, 2, 6, 4, 7, 4, 3, 7, 1, 2])], [tensor([0.4343, 0.9775, 0.9188, 0.9436, 0.6003, 0.9644, 0.7338, 0.9825, 0.9971,\n",
            "        0.8516]), tensor([4, 8, 6, 3, 8, 5, 8, 5, 7, 8])], [tensor([0.7939, 0.9766, 0.6435, 0.7719, 0.3905, 0.9937, 0.3857, 0.8333, 0.5489,\n",
            "        0.6915]), tensor([2, 5, 0, 7, 5, 6, 9, 2, 9, 9])], [tensor([0.9941, 0.8900, 0.9878, 0.7818, 0.5925, 0.9922, 0.9703, 0.9092, 0.9598,\n",
            "        0.6395]), tensor([7, 8, 9, 3, 0, 4, 4, 8, 8, 3])], [tensor([0.9849, 0.8597, 0.9788, 0.7786, 0.9892, 0.8569, 0.7503, 0.9788, 0.8083,\n",
            "        0.7330]), tensor([4, 3, 5, 1, 6, 0, 2, 2, 1, 4])], [tensor([0.5444, 0.9698, 0.9535, 0.7057, 0.6137, 0.7712, 0.8782, 0.9331, 0.9769,\n",
            "        0.9653]), tensor([0, 8, 1, 8, 8, 8, 9, 2, 5, 7])], [tensor([0.7186, 0.4582, 0.6516, 0.9412, 0.6619, 0.9589, 0.4235, 0.9117, 0.9022,\n",
            "        0.6303]), tensor([2, 2, 1, 9, 1, 8, 9, 2, 4, 0])], [tensor([0.8364, 0.9851, 0.9948, 0.6042, 0.3866, 0.9768, 0.8767, 0.8655, 0.7937,\n",
            "        0.9857]), tensor([2, 5, 2, 0, 0, 7, 1, 7, 9, 9])], [tensor([0.9869, 0.9947, 0.5962, 0.9961, 0.9927, 0.9364, 0.8660, 0.6069, 0.9956,\n",
            "        0.7611]), tensor([7, 4, 1, 6, 4, 9, 4, 6, 7, 2])], [tensor([0.9970, 0.9523, 0.4284, 0.9908, 0.6907, 0.4320, 0.8256, 0.9821, 0.5625,\n",
            "        0.7378]), tensor([6, 8, 1, 7, 3, 0, 8, 7, 0, 3])], [tensor([0.8972, 0.8810, 0.9901, 0.6370, 0.9864, 0.9955, 0.8948, 0.7882, 0.9948,\n",
            "        0.9918]), tensor([3, 5, 8, 4, 7, 6, 5, 3, 4, 4])], [tensor([0.9194, 0.4880, 0.8142, 0.9995, 0.8021, 0.8935, 0.8306, 0.6990, 0.9851,\n",
            "        0.9649]), tensor([3, 6, 0, 4, 3, 4, 2, 3, 7, 5])], [tensor([0.9572, 0.8819, 0.9856, 0.9939, 0.5243, 0.9552, 0.9916, 0.9804, 0.6766,\n",
            "        0.8714]), tensor([5, 7, 8, 4, 4, 4, 6, 6, 0, 5])], [tensor([0.9714, 0.8344, 0.9526, 0.4399, 0.9846, 0.5984, 0.9977, 0.7914, 0.8029,\n",
            "        0.8315]), tensor([8, 3, 4, 1, 2, 4, 7, 8, 5, 9])], [tensor([0.5565, 0.8379, 0.9125, 0.9571, 0.9433, 0.9434, 0.8583, 0.9408, 0.8611,\n",
            "        0.9698]), tensor([1, 8, 9, 4, 5, 5, 5, 3, 3, 5])], [tensor([0.9826, 0.9911, 0.9917, 0.9928, 0.8009, 0.9905, 0.8715, 0.8241, 0.9884,\n",
            "        0.4491]), tensor([8, 7, 8, 9, 1, 6, 5, 8, 7, 5])], [tensor([0.9753, 0.8984, 0.2096, 0.5294, 0.2857, 0.9809, 0.7578, 0.5974, 0.9895,\n",
            "        0.9723]), tensor([2, 4, 6, 0, 7, 9, 5, 8, 8, 7])], [tensor([0.8923, 0.9944, 0.9923, 0.8710, 0.5195, 0.9756, 0.9893, 0.6350, 0.9852,\n",
            "        0.9499]), tensor([1, 6, 2, 3, 9, 4, 7, 4, 9, 9])], [tensor([0.9550, 0.9724, 0.4883, 0.9978, 0.9826, 0.9933, 0.5489, 0.9960, 0.9299,\n",
            "        0.9780]), tensor([4, 9, 0, 4, 7, 9, 5, 7, 5, 6])], [tensor([0.8104, 0.7387, 0.9217, 0.6720, 0.9859, 0.5638, 0.9973, 0.2966, 0.9394,\n",
            "        0.8936]), tensor([9, 9, 0, 1, 2, 9, 6, 3, 4, 8])], [tensor([0.9964, 0.6633, 0.8725, 0.3142, 0.9626, 0.9807, 0.9750, 0.7137, 0.9158,\n",
            "        0.8025]), tensor([7, 8, 9, 0, 3, 4, 6, 0, 8, 8])], [tensor([0.6262, 0.2851, 0.7256, 0.8815, 0.6415, 0.9110, 0.5838, 0.7482, 0.9831,\n",
            "        0.9316]), tensor([4, 7, 8, 1, 9, 5, 0, 0, 6, 0])], [tensor([0.7146, 0.6510, 0.9928, 0.9910, 0.9980, 0.9654, 0.9859, 0.9577, 0.9963,\n",
            "        0.3648]), tensor([3, 0, 7, 7, 4, 9, 5, 6, 7, 2])], [tensor([0.9959, 0.9627, 0.9847, 0.9966, 0.3675, 0.9976, 0.9984, 0.5736, 0.9788,\n",
            "        0.9576]), tensor([7, 5, 2, 4, 8, 4, 7, 1, 6, 3])], [tensor([0.9697, 0.8684, 0.7194, 0.9592, 0.9933, 0.9443, 0.9753, 0.9991, 0.9577,\n",
            "        0.4096]), tensor([4, 8, 1, 9, 4, 7, 5, 4, 5, 2])], [tensor([0.9906, 0.8350, 0.2933, 0.3392, 0.9898, 0.7974, 0.9148, 0.9063, 0.9918,\n",
            "        0.5563]), tensor([7, 0, 0, 8, 9, 1, 9, 5, 7, 0])], [tensor([0.8460, 0.9283, 0.6953, 0.9847, 0.8876, 0.9919, 0.9785, 0.9271, 0.9203,\n",
            "        0.5774]), tensor([0, 8, 3, 7, 6, 6, 8, 5, 2, 1])], [tensor([0.9888, 0.7040, 0.8184, 0.7287, 0.7914, 0.5371, 0.9232, 0.9383, 0.9917,\n",
            "        0.9955]), tensor([4, 1, 3, 0, 1, 3, 3, 2, 7, 6])], [tensor([0.9905, 0.9393, 0.9906, 0.9855, 0.9298, 0.6974, 0.9958, 0.8604, 0.4351,\n",
            "        0.9944]), tensor([6, 8, 4, 2, 6, 3, 7, 2, 1, 6])], [tensor([0.9886, 0.9021, 0.1857, 0.7169, 0.9863, 0.9629, 0.9924, 0.9627, 0.2795,\n",
            "        0.9862]), tensor([7, 9, 4, 0, 7, 2, 2, 6, 5, 6])], [tensor([0.9978, 0.9804, 0.9568, 0.7565, 0.9442, 0.9233, 0.9501, 0.9835, 0.8296,\n",
            "        0.5660]), tensor([6, 2, 9, 0, 8, 3, 8, 9, 0, 5])], [tensor([0.5334, 0.2478, 0.3059, 0.9547, 0.9260, 0.7642, 0.9783, 0.7929, 0.5198,\n",
            "        0.9883]), tensor([9, 0, 4, 2, 9, 3, 8, 8, 8, 9])], [tensor([0.8058, 0.9185, 0.5642, 0.9954, 0.5924, 0.9798, 0.4895, 0.5925, 0.8939,\n",
            "        0.6168]), tensor([2, 4, 3, 7, 0, 9, 1, 1, 8, 3])], [tensor([0.9908, 0.5269, 0.9761, 0.6244, 0.2937, 0.7703, 0.7870, 0.8006, 0.9338,\n",
            "        0.8926]), tensor([7, 2, 9, 1, 9, 9, 6, 5, 8, 1])], [tensor([0.9922, 0.7456, 0.9924, 0.7533, 0.9871, 0.8490, 0.9621, 0.9920, 0.9405,\n",
            "        0.4610]), tensor([7, 5, 6, 5, 4, 9, 4, 4, 5, 3])], [tensor([0.9367, 0.6370, 0.9856, 0.8186, 0.8791, 0.9323, 0.9847, 0.9441, 0.9936,\n",
            "        0.9682]), tensor([8, 0, 6, 2, 5, 8, 9, 8, 6, 5])], [tensor([0.8699, 0.7326, 0.5823, 0.9810, 0.7451, 0.6121, 0.9677, 0.9730, 0.7869,\n",
            "        0.8777]), tensor([5, 1, 6, 5, 3, 5, 4, 8, 9, 7])], [tensor([0.9347, 0.9949, 0.8653, 0.9337, 0.4057, 0.8747, 0.9624, 0.8434, 0.9709,\n",
            "        0.4742]), tensor([5, 6, 5, 8, 4, 5, 4, 1, 5, 4])], [tensor([0.7771, 0.9630, 0.9046, 0.9453, 0.9369, 0.9049, 0.9767, 0.9971, 0.9649,\n",
            "        0.9995]), tensor([0, 2, 2, 6, 3, 5, 5, 4, 5, 4])], [tensor([0.7106, 0.9898, 0.9887, 0.9430, 0.9640, 0.7799, 0.6684, 0.9473, 0.9368,\n",
            "        0.5705]), tensor([8, 5, 6, 4, 5, 5, 1, 2, 3, 2])], [tensor([0.9657, 0.6793, 0.9966, 0.9288, 0.7853, 0.9948, 0.9581, 0.8719, 0.9958,\n",
            "        0.6982]), tensor([9, 1, 6, 3, 8, 7, 2, 5, 4, 8])], [tensor([0.9909, 0.9333, 0.9965, 0.8855, 0.8236, 0.7996, 0.4962, 0.5985, 0.9975,\n",
            "        0.9822]), tensor([9, 5, 4, 8, 5, 3, 2, 1, 6, 2])], [tensor([0.4124, 0.7511, 0.9406, 0.8915, 0.9469, 0.9311, 0.8612, 0.5563, 0.8106,\n",
            "        0.8115]), tensor([8, 0, 8, 5, 8, 5, 8, 1, 9, 0])], [tensor([0.9757, 0.9925, 0.8244, 0.5829, 0.9567, 0.9480, 0.8900, 0.6742, 0.9878,\n",
            "        0.9715]), tensor([8, 9, 2, 3, 3, 5, 3, 1, 9, 5])], [tensor([0.8263, 0.9951, 0.9328, 0.9047, 0.9958, 0.9915, 0.8990, 0.6508, 0.9922,\n",
            "        0.4961]), tensor([2, 9, 8, 6, 4, 6, 6, 0, 2, 5])], [tensor([0.9313, 0.8101, 0.9765, 0.7824, 0.8357, 0.7202, 0.9897, 0.9962, 0.3230,\n",
            "        0.9735]), tensor([1, 8, 5, 5, 5, 8, 6, 4, 9, 6])], [tensor([0.7380, 0.9642, 0.9889, 0.9242, 0.3481, 0.9790, 0.9604, 0.8346, 0.9890,\n",
            "        0.9673]), tensor([0, 6, 8, 0, 2, 7, 8, 5, 9, 9])], [tensor([0.9159, 0.5865, 0.4992, 0.8702, 0.6820, 0.7080, 0.8697, 0.9751, 0.9959,\n",
            "        0.7081]), tensor([6, 3, 4, 1, 0, 0, 9, 8, 7, 7])], [tensor([0.4824, 0.8384, 0.9529, 0.5949, 0.9730, 0.8651, 0.9782, 0.4992, 0.9811,\n",
            "        0.9804]), tensor([4, 5, 4, 4, 6, 5, 8, 8, 7, 2])], [tensor([0.9012, 0.9300, 0.9797, 0.7347, 0.8674, 0.8627, 0.7734, 0.9811, 0.9816,\n",
            "        0.9838]), tensor([5, 4, 9, 0, 6, 9, 5, 6, 2, 4])], [tensor([0.9470, 0.9922, 0.9405, 0.5715, 0.7576, 0.8008, 0.9779, 0.8529, 0.9965,\n",
            "        0.9250]), tensor([5, 7, 5, 1, 3, 8, 2, 4, 6, 5])], [tensor([0.9956, 0.9664, 0.9951, 0.7070, 0.8652, 0.7898, 0.9385, 0.9463, 0.9659,\n",
            "        0.9936]), tensor([7, 9, 6, 3, 5, 9, 5, 8, 4, 4])], [tensor([0.9620, 0.9760, 0.9954, 0.9843, 0.8814, 0.8547, 0.1882, 0.9181, 0.8699,\n",
            "        0.2828]), tensor([4, 0, 7, 8, 0, 3, 9, 1, 3, 5])], [tensor([0.9848, 0.6080, 0.8451, 0.9864, 0.9558, 0.9722, 0.9416, 0.9924, 0.9952,\n",
            "        0.9593]), tensor([9, 1, 5, 2, 5, 9, 5, 4, 7, 6])], [tensor([0.5875, 0.6545, 0.9871, 0.9970, 0.6352, 0.9125, 0.8189, 0.9864, 0.9961,\n",
            "        0.6342]), tensor([5, 2, 9, 6, 0, 8, 2, 5, 6, 1])], [tensor([0.9619, 0.9891, 0.9724, 0.8926, 0.9982, 0.7727, 0.7771, 0.4085, 0.4998,\n",
            "        0.9997]), tensor([4, 4, 9, 3, 9, 9, 6, 0, 0, 4])], [tensor([0.9816, 0.9441, 0.8927, 0.9991, 0.7069, 0.9973, 0.9694, 0.6868, 0.9643,\n",
            "        0.8704]), tensor([6, 0, 2, 7, 8, 6, 5, 8, 5, 1])], [tensor([0.9782, 0.9574, 0.9321, 0.8806, 0.9717, 0.8396, 0.6429, 0.8889, 0.8399,\n",
            "        0.9805]), tensor([3, 2, 3, 1, 9, 6, 3, 8, 9, 4])], [tensor([0.4902, 0.9615, 0.9873, 0.9883, 0.6185, 0.9789, 0.7573, 0.9929, 0.6649,\n",
            "        0.9295]), tensor([0, 2, 7, 6, 9, 7, 2, 4, 3, 5])], [tensor([0.8131, 0.7544, 0.4978, 0.4213, 0.9915, 0.7703, 0.9328, 0.8893, 0.5464,\n",
            "        0.9918]), tensor([0, 5, 3, 0, 4, 8, 5, 3, 3, 7])], [tensor([0.9953, 0.8874, 0.9693, 0.9760, 0.8592, 0.9319, 0.8902, 0.7287, 0.7897,\n",
            "        0.7919]), tensor([9, 0, 6, 4, 8, 4, 4, 5, 6, 7])], [tensor([0.9680, 0.9326, 0.9612, 0.9911, 0.9882, 0.9830, 0.9976, 0.8750, 0.9616,\n",
            "        0.9760]), tensor([4, 2, 8, 2, 9, 9, 7, 7, 9, 8])], [tensor([0.6118, 0.9122, 0.9692, 0.9465, 0.9337, 0.9792, 0.9734, 0.8540, 0.9951,\n",
            "        0.9538]), tensor([4, 3, 2, 3, 1, 5, 7, 4, 4, 5])], [tensor([0.9825, 0.9478, 0.9845, 0.9362, 0.9583, 0.9910, 0.9473, 0.9586, 0.9395,\n",
            "        0.5361]), tensor([7, 3, 2, 3, 6, 7, 7, 2, 7, 5])], [tensor([0.9575, 0.4018, 0.6811, 0.9734, 0.6979, 0.8773, 0.9565, 0.9892, 0.9815,\n",
            "        0.8736]), tensor([1, 2, 0, 9, 2, 8, 5, 4, 0, 1])], [tensor([0.9934, 0.9502, 0.6792, 0.7115, 0.9473, 0.9903, 0.7653, 0.9865, 0.9588,\n",
            "        0.9931]), tensor([6, 8, 0, 1, 5, 6, 4, 5, 4, 6])], [tensor([0.9907, 0.9804, 0.3474, 0.9965, 0.9923, 0.9947, 0.4406, 0.9737, 0.9887,\n",
            "        0.9969]), tensor([4, 7, 1, 4, 7, 9, 2, 9, 8, 7])], [tensor([0.9715, 0.6715, 0.9975, 0.9943, 0.9606, 0.5088, 0.5658, 0.3862, 0.9621,\n",
            "        0.7720]), tensor([4, 2, 7, 2, 2, 1, 6, 2, 9, 9])], [tensor([0.9882, 0.9967, 0.7726, 0.8258, 0.8341, 0.9778, 0.8714, 0.7940, 0.4856,\n",
            "        0.6912]), tensor([2, 6, 3, 8, 4, 4, 3, 1, 4, 4])], [tensor([0.6754, 0.5913, 0.9965, 0.7743, 0.9772, 0.7279, 0.9968, 0.9703, 0.6579,\n",
            "        0.9481]), tensor([3, 3, 7, 2, 8, 1, 7, 2, 2, 8])], [tensor([0.9297, 0.9585, 0.7590, 0.9040, 0.6940, 0.9882, 0.9454, 0.6977, 0.9132,\n",
            "        0.9136]), tensor([9, 8, 1, 3, 1, 4, 5, 0, 1, 8])], [tensor([0.9980, 0.9557, 0.7695, 0.9839, 0.8815, 0.7938, 0.6121, 0.8693, 0.6833,\n",
            "        0.8672]), tensor([7, 2, 1, 6, 8, 5, 9, 0, 2, 4])], [tensor([0.5420, 0.5314, 0.6955, 0.2456, 0.9926, 0.8816, 0.9639, 0.9853, 0.9519,\n",
            "        0.9922]), tensor([2, 3, 3, 4, 2, 2, 5, 2, 5, 7])], [tensor([0.9804, 0.9121, 0.7544, 0.8913, 0.9841, 0.9777, 0.5049, 0.9853, 0.8598,\n",
            "        0.9727]), tensor([4, 6, 5, 8, 9, 8, 2, 9, 0, 9])], [tensor([0.9881, 0.9891, 0.9784, 0.5043, 0.9582, 0.9942, 0.6464, 0.9767, 0.7270,\n",
            "        0.5124]), tensor([7, 7, 2, 2, 5, 7, 8, 9, 8, 3])], [tensor([0.6801, 0.9007, 0.9121, 0.8745, 0.5056, 0.9411, 0.9797, 0.9841, 0.6561,\n",
            "        0.8182]), tensor([2, 5, 0, 5, 1, 8, 5, 4, 5, 3])], [tensor([0.9601, 0.9848, 0.9405, 0.9906, 0.9854, 0.9847, 0.9891, 0.6528, 0.8595,\n",
            "        0.6343]), tensor([2, 4, 5, 6, 7, 2, 7, 3, 5, 0])], [tensor([0.8695, 0.7522, 0.9935, 0.7308, 0.9550, 0.9828, 0.4071, 0.9879, 0.8275,\n",
            "        0.9932]), tensor([4, 1, 9, 2, 8, 4, 8, 4, 1, 7])], [tensor([0.9832, 0.9912, 0.5543, 0.9369, 0.5929, 0.4082, 0.6332, 0.9875, 0.8081,\n",
            "        0.9146]), tensor([8, 7, 5, 5, 9, 8, 9, 4, 1, 5])], [tensor([0.9246, 0.9877, 0.3014, 0.9981, 0.9628, 0.9899, 0.7833, 0.7990, 0.9914,\n",
            "        0.9972]), tensor([9, 6, 0, 7, 2, 2, 1, 1, 9, 4])], [tensor([0.7010, 0.7420, 0.6115, 0.9932, 0.5494, 0.9911, 0.9961, 0.8944, 0.9037,\n",
            "        0.9953]), tensor([3, 5, 6, 6, 0, 4, 6, 1, 2, 9])], [tensor([0.9925, 0.9890, 0.9911, 0.9942, 0.9723, 0.9908, 0.9920, 0.8525, 0.6365,\n",
            "        0.6198]), tensor([7, 4, 4, 4, 9, 8, 4, 8, 1, 0])], [tensor([0.7819, 0.8307, 0.9618, 0.9831, 0.5495, 0.7797, 0.8307, 0.7821, 0.9329,\n",
            "        0.9888]), tensor([1, 8, 4, 2, 4, 0, 3, 1, 3, 4])], [tensor([0.9689, 0.9805, 0.6147, 0.8601, 0.7879, 0.9990, 0.9441, 0.9727, 0.9973,\n",
            "        0.9376]), tensor([8, 1, 2, 0, 6, 4, 5, 6, 9, 0])], [tensor([0.8183, 0.2631, 0.8336, 0.9959, 0.9931, 0.5306, 0.6819, 0.6769, 0.4284,\n",
            "        0.7778]), tensor([9, 5, 1, 4, 7, 8, 6, 1, 2, 3])], [tensor([0.9984, 0.7163, 0.9374, 0.9843, 0.8764, 0.9816, 0.9360, 0.8274, 0.7586,\n",
            "        0.9398]), tensor([6, 1, 3, 2, 8, 7, 4, 3, 0, 5])], [tensor([0.9729, 0.7015, 0.9960, 0.9903, 0.2850, 0.7048, 0.6922, 0.9767, 0.9722,\n",
            "        0.9854]), tensor([2, 9, 4, 4, 6, 3, 2, 2, 6, 4])], [tensor([0.5838, 0.9906, 0.9885, 0.8033, 0.8175, 0.5920, 0.9680, 0.9629, 0.9984,\n",
            "        0.9168]), tensor([3, 9, 2, 5, 9, 1, 2, 8, 4, 5])], [tensor([0.9829, 0.9880, 0.8643, 0.9921, 0.9748, 0.9372, 0.8876, 0.8619, 0.9849,\n",
            "        0.9746]), tensor([4, 2, 1, 2, 5, 5, 4, 5, 6, 7])], [tensor([0.8890, 0.8641, 0.7499, 0.9961, 0.9849, 0.8644, 0.9787, 0.7741, 0.9973,\n",
            "        0.9906]), tensor([2, 3, 4, 2, 5, 1, 5, 1, 7, 6])], [tensor([0.9894, 0.9524, 0.9812, 0.9007, 0.7252, 0.1912, 0.8016, 0.9745, 0.7745,\n",
            "        0.9368]), tensor([2, 5, 4, 5, 1, 5, 9, 8, 3, 5])], [tensor([0.9812, 0.7421, 0.9608, 0.9446, 0.9943, 0.4343, 0.9114, 0.9669, 0.4931,\n",
            "        0.8590]), tensor([5, 1, 8, 2, 7, 8, 9, 1, 2, 3])], [tensor([0.9833, 0.9479, 0.9968, 0.6851, 0.9887, 0.9239, 0.8072, 0.8971, 0.8015,\n",
            "        0.5301]), tensor([7, 5, 6, 5, 4, 8, 0, 3, 5, 2])], [tensor([0.9857, 0.9852, 0.9916, 0.9983, 0.9502, 0.9442, 0.8906, 0.4071, 0.9933,\n",
            "        0.9686]), tensor([7, 7, 4, 7, 9, 3, 3, 2, 7, 7])], [tensor([0.8739, 0.6844, 0.6640, 0.7588, 0.9827, 0.9671, 0.8814, 0.9847, 0.9365,\n",
            "        0.9825]), tensor([2, 1, 4, 3, 5, 3, 8, 4, 3, 4])], [tensor([0.6021, 0.9455, 0.9973, 0.8946, 0.7569, 0.6876, 0.9835, 0.9827, 0.4472,\n",
            "        0.5717]), tensor([0, 2, 9, 0, 6, 4, 6, 6, 0, 4])], [tensor([0.7365, 0.7449, 0.8743, 0.9857, 0.9906, 0.7410, 0.9405, 0.9027, 0.8789,\n",
            "        0.9853]), tensor([4, 3, 8, 4, 7, 3, 9, 2, 4, 2])], [tensor([0.8587, 0.9961, 0.9942, 0.5187, 0.9963, 0.8222, 0.3093, 0.4642, 0.9965,\n",
            "        0.9945]), tensor([0, 6, 7, 7, 8, 8, 2, 5, 7, 7])], [tensor([0.9122, 0.9878, 0.7794, 0.8671, 0.4271, 0.8001, 0.8197, 0.9955, 0.6653,\n",
            "        0.9683]), tensor([9, 9, 1, 3, 5, 2, 2, 7, 8, 1])], [tensor([0.9954, 0.9963, 0.9947, 0.9894, 0.9867, 0.9936, 0.9670, 0.7255, 0.9580,\n",
            "        0.7361]), tensor([6, 4, 6, 2, 9, 6, 8, 8, 4, 3])], [tensor([0.9183, 0.4744, 0.9760, 0.9946, 0.3831, 0.8579, 0.4239, 0.7615, 0.9451,\n",
            "        0.6905]), tensor([8, 5, 2, 9, 0, 1, 2, 9, 8, 0])], [tensor([0.3729, 0.4580, 0.8672, 0.7032, 0.9585, 0.9857, 0.5827, 0.7971, 0.5002,\n",
            "        0.9225]), tensor([3, 0, 3, 5, 5, 6, 9, 3, 3, 5])], [tensor([0.9328, 0.9813, 0.9827, 0.9882, 0.9963, 0.7712, 0.9935, 0.9814, 0.4640,\n",
            "        0.9949]), tensor([5, 9, 9, 9, 4, 5, 6, 9, 2, 7])], [tensor([0.6312, 0.2731, 0.9684, 0.9013, 0.9844, 0.9561, 0.8131, 0.6434, 0.7666,\n",
            "        0.9787]), tensor([1, 9, 2, 3, 9, 2, 8, 0, 2, 2])], [tensor([0.9861, 0.8993, 0.6889, 0.5073, 0.9404, 0.8755, 0.3543, 0.9878, 0.9911,\n",
            "        0.6132]), tensor([7, 0, 1, 2, 5, 5, 8, 2, 4, 8])], [tensor([0.5740, 0.9024, 0.4427, 0.8725, 0.9677, 0.9848, 0.9849, 0.8853, 0.9929,\n",
            "        0.9893]), tensor([9, 0, 5, 3, 5, 4, 6, 5, 6, 7])], [tensor([0.9903, 0.6215, 0.9841, 0.9948, 0.8370, 0.9967, 0.9403, 0.8414, 0.3825,\n",
            "        0.9715]), tensor([6, 2, 9, 4, 2, 7, 5, 5, 2, 4])], [tensor([0.9968, 0.9735, 0.9883, 0.9742, 0.8143, 0.9885, 0.9715, 0.9795, 0.9982,\n",
            "        0.4089]), tensor([4, 2, 4, 9, 3, 7, 9, 9, 6, 0])], [tensor([0.9976, 0.9289, 0.9895, 0.9591, 0.9300, 0.9906, 0.9923, 0.5345, 0.9217,\n",
            "        0.9953]), tensor([2, 6, 6, 2, 5, 7, 7, 6, 2, 4])], [tensor([0.7170, 0.9912, 0.3606, 0.8792, 0.8459, 0.9129, 0.9939, 0.9460, 0.9763,\n",
            "        0.9081]), tensor([8, 4, 8, 2, 5, 9, 6, 4, 2, 0])], [tensor([0.5070, 0.7660, 0.9915, 0.9434, 0.7431, 0.5307, 0.5407, 0.8588, 0.9052,\n",
            "        0.9898]), tensor([0, 3, 4, 2, 0, 4, 2, 6, 2, 2])], [tensor([0.9846, 0.9825, 0.9947, 0.9943, 0.9926, 0.7771, 0.6571, 0.9900, 0.4735,\n",
            "        0.9991]), tensor([9, 8, 7, 4, 7, 3, 3, 7, 7, 4])], [tensor([0.8356, 0.8774, 0.7781, 0.2450, 0.8574, 0.9274, 0.3013, 0.6137, 0.8858,\n",
            "        0.7935]), tensor([0, 2, 1, 8, 5, 2, 6, 8, 9, 1])], [tensor([0.8813, 0.9964, 0.3813, 0.9163, 0.9217, 0.5762, 0.5757, 0.9692, 0.2329,\n",
            "        0.9112]), tensor([1, 6, 2, 6, 2, 1, 3, 9, 8, 8])], [tensor([0.5501, 0.9960, 0.9169, 0.9940, 0.3724, 0.9606, 0.9950, 0.9955, 0.9607,\n",
            "        0.9989]), tensor([2, 6, 5, 7, 1, 5, 7, 6, 0, 7])], [tensor([0.7723, 0.7086, 0.9793, 0.9913, 0.9631, 0.9778, 0.9898, 0.9135, 0.9847,\n",
            "        0.9535]), tensor([3, 1, 8, 9, 2, 6, 6, 5, 9, 1])], [tensor([0.6186, 0.9699, 0.2529, 0.7541, 0.9986, 0.9932, 0.8470, 0.9299, 0.8356,\n",
            "        0.9714]), tensor([1, 8, 0, 0, 4, 2, 5, 8, 5, 5])], [tensor([0.8657, 0.8378, 0.9359, 0.9943, 0.5758, 0.9877, 0.9139, 0.9687, 0.9749,\n",
            "        0.7364]), tensor([2, 4, 3, 7, 0, 7, 4, 2, 9, 0])], [tensor([0.9973, 0.9776, 0.9788, 0.9889, 0.9707, 0.9920, 0.8919, 0.9900, 0.8973,\n",
            "        0.4780]), tensor([4, 7, 7, 9, 6, 6, 0, 4, 1, 9])], [tensor([0.9300, 0.8743, 0.9856, 0.9201, 0.9740, 0.9954, 0.8813, 0.8066, 0.4032,\n",
            "        0.8793]), tensor([3, 3, 2, 0, 6, 7, 5, 3, 6, 5])], [tensor([0.9985, 0.4884, 0.4857, 0.9670, 0.9981, 0.8275, 0.9915, 0.6634, 0.9966,\n",
            "        0.8657]), tensor([4, 1, 3, 8, 4, 1, 2, 0, 7, 6])], [tensor([0.9795, 0.9962, 0.9571, 0.9926, 0.6327, 0.9038, 0.5914, 0.8733, 0.9574,\n",
            "        0.9816]), tensor([9, 2, 5, 6, 1, 1, 9, 6, 5, 5])], [tensor([0.4556, 0.9187, 0.9864, 0.4141, 0.9724, 0.7741, 0.9786, 0.5036, 0.3524,\n",
            "        0.7301]), tensor([6, 5, 2, 5, 5, 3, 7, 9, 0, 9])], [tensor([0.6197, 0.8670, 0.8506, 0.8857, 0.9877, 0.9836, 0.8479, 0.4758, 0.9964,\n",
            "        0.8070]), tensor([1, 8, 3, 1, 2, 5, 9, 0, 7, 2])], [tensor([0.6608, 0.9206, 0.9494, 0.8925, 0.7328, 0.8433, 0.9621, 0.7378, 0.7508,\n",
            "        0.9844]), tensor([1, 8, 7, 3, 1, 8, 9, 7, 1, 7])], [tensor([0.9889, 0.2745, 0.5019, 0.9968, 0.9928, 0.9676, 0.7686, 0.9626, 0.8523,\n",
            "        0.9559]), tensor([7, 0, 2, 6, 4, 9, 4, 4, 9, 4])], [tensor([0.4840, 0.9825, 0.9442, 0.9856, 0.9592, 0.9862, 0.9075, 0.5420, 0.9847,\n",
            "        0.9591]), tensor([8, 9, 9, 4, 4, 4, 9, 2, 7, 9])], [tensor([0.9581, 0.9935, 0.9800, 0.8411, 0.9910, 0.9653, 0.6472, 0.9933, 0.9791,\n",
            "        0.9782]), tensor([2, 7, 5, 0, 7, 4, 9, 6, 4, 7])], [tensor([0.8153, 0.9138, 0.9711, 0.5859, 0.6980, 0.8520, 0.9470, 0.7542, 0.9855,\n",
            "        0.8858]), tensor([6, 3, 4, 1, 0, 8, 6, 4, 7, 2])], [tensor([0.8733, 0.3245, 0.9038, 0.9830, 0.8849, 0.3487, 0.8830, 0.9133, 0.7137,\n",
            "        0.9503]), tensor([0, 5, 5, 4, 6, 1, 5, 5, 2, 3])], [tensor([0.7167, 0.4388, 0.9904, 0.8444, 0.7897, 0.9991, 0.9652, 0.5731, 0.6655,\n",
            "        0.9984]), tensor([3, 1, 7, 8, 3, 6, 8, 3, 9, 4])], [tensor([0.9471, 0.9122, 0.9932, 0.9423, 0.9204, 0.8116, 0.1967, 0.9921, 0.8778,\n",
            "        0.9479]), tensor([5, 5, 7, 5, 1, 4, 4, 7, 0, 9])], [tensor([0.9845, 0.5665, 0.3459, 0.9535, 0.9379, 0.7480, 0.9971, 0.9747, 0.8523,\n",
            "        0.9686]), tensor([2, 6, 0, 6, 1, 7, 9, 5, 6, 9])], [tensor([0.9946, 0.9797, 0.8796, 0.8452, 0.6014, 0.8483, 0.9954, 0.8422, 0.8546,\n",
            "        0.9687]), tensor([4, 2, 1, 4, 4, 1, 9, 5, 1, 4])], [tensor([0.3240, 0.7786, 0.9940, 0.9962, 0.9013, 0.9767, 0.7339, 0.7454, 0.6294,\n",
            "        0.9926]), tensor([0, 1, 8, 4, 1, 7, 8, 3, 6, 6])], [tensor([0.9929, 0.9666, 0.9066, 0.9915, 0.8379, 0.4980, 0.8234, 0.7791, 0.9579,\n",
            "        0.9976]), tensor([8, 8, 9, 7, 0, 2, 9, 0, 5, 6])], [tensor([0.7546, 0.9877, 0.8075, 0.9924, 0.9882, 0.9961, 0.9501, 0.9688, 0.9808,\n",
            "        0.6316]), tensor([0, 2, 9, 7, 9, 7, 2, 2, 9, 2])], [tensor([0.7875, 0.8859, 0.8168, 0.9838, 0.9488, 0.9408, 0.9718, 0.9552, 0.9266,\n",
            "        0.9689]), tensor([0, 0, 9, 8, 9, 6, 9, 6, 3, 3])], [tensor([0.9876, 0.9973, 0.9563, 0.9370, 0.8813, 0.6893, 0.4949, 0.7045, 0.9798,\n",
            "        0.7082]), tensor([9, 6, 2, 2, 9, 7, 4, 0, 4, 6])], [tensor([0.9511, 0.7834, 0.9570, 0.9886, 0.9785, 0.9844, 0.9949, 0.8611, 0.7810,\n",
            "        0.9013]), tensor([5, 3, 8, 4, 7, 7, 9, 4, 1, 9])], [tensor([0.9044, 0.7913, 0.5071, 0.9671, 0.6415, 0.9621, 0.9961, 0.9401, 0.9924,\n",
            "        0.9368]), tensor([3, 2, 4, 9, 3, 8, 4, 8, 5, 0])], [tensor([0.9547, 0.9695, 0.4608, 0.9698, 0.5138, 0.9971, 0.9871, 0.9891, 0.7505,\n",
            "        0.9737]), tensor([5, 7, 4, 4, 6, 7, 4, 4, 3, 2])], [tensor([0.9794, 0.6777, 0.9897, 0.8762, 0.9658, 0.9617, 0.9187, 0.9656, 0.6685,\n",
            "        0.9453]), tensor([9, 0, 1, 3, 2, 5, 2, 5, 1, 9])], [tensor([0.9654, 0.8419, 0.9155, 0.9875, 0.9695, 0.8656, 0.2530, 0.8293, 0.7403,\n",
            "        0.9762]), tensor([8, 3, 2, 7, 7, 1, 7, 1, 5, 2])], [tensor([0.9905, 0.8009, 0.8889, 0.5179, 0.4338, 0.9868, 0.9857, 0.4627, 0.9965,\n",
            "        0.8773]), tensor([7, 2, 8, 5, 2, 7, 9, 0, 9, 1])], [tensor([0.9975, 0.6698, 0.9983, 0.9725, 0.6775, 0.9917, 0.2912, 0.7831, 0.8784,\n",
            "        0.7367]), tensor([7, 8, 4, 4, 9, 9, 1, 0, 9, 8])], [tensor([0.7860, 0.9661, 0.9984, 0.9031, 0.8423, 0.7587, 0.7814, 0.9909, 0.8834,\n",
            "        0.9302]), tensor([9, 2, 4, 5, 3, 5, 3, 7, 5, 3])], [tensor([0.7434, 0.7750, 0.9578, 0.9976, 0.9776, 0.8019, 0.9599, 0.8980, 0.6615,\n",
            "        0.7982]), tensor([3, 2, 3, 6, 7, 6, 9, 9, 8, 5])], [tensor([0.8154, 0.8497, 0.8840, 0.9654, 0.9372, 0.8377, 0.9884, 0.6642, 0.9934,\n",
            "        0.2397]), tensor([2, 5, 8, 9, 3, 0, 9, 1, 9, 7])], [tensor([0.9768, 0.9632, 0.9958, 0.8997, 0.9958, 0.3577, 0.9932, 0.8638, 0.9660,\n",
            "        0.9839]), tensor([9, 2, 7, 3, 7, 7, 4, 1, 7, 9])], [tensor([0.7288, 0.8918, 0.8367, 0.9374, 0.7592, 0.8459, 0.7468, 0.8773, 0.6377,\n",
            "        0.4339]), tensor([1, 2, 5, 9, 3, 3, 3, 3, 3, 2])], [tensor([0.9984, 0.9497, 0.4348, 0.4516, 0.8987, 0.4589, 0.4750, 0.9734, 0.9415,\n",
            "        0.4857]), tensor([4, 7, 0, 0, 6, 7, 0, 5, 9, 2])], [tensor([0.9762, 0.9271, 0.8163, 0.7201, 0.9510, 0.9951, 0.9926, 0.9932, 0.2782,\n",
            "        0.9243]), tensor([9, 5, 2, 0, 0, 7, 7, 9, 6, 1])], [tensor([0.7688, 0.7679, 0.9609, 0.5747, 0.7111, 0.9930, 0.9951, 0.9526, 0.9832,\n",
            "        0.9905]), tensor([3, 1, 8, 2, 1, 7, 8, 4, 6, 7])], [tensor([0.8669, 0.9245, 0.8932, 0.9260, 0.5942, 0.7375, 0.7099, 0.8838, 0.9103,\n",
            "        0.9842]), tensor([0, 1, 3, 6, 8, 3, 3, 5, 9, 4])], [tensor([0.6354, 0.8888, 0.9510, 0.6138, 0.8289, 0.9800, 0.9655, 0.9949, 0.9896,\n",
            "        0.9378]), tensor([0, 4, 5, 1, 3, 5, 9, 6, 7, 8])], [tensor([0.8188, 0.8015, 0.8201, 0.6137, 0.4189, 0.2917, 0.5025, 0.9557, 0.9546,\n",
            "        0.9377]), tensor([1, 4, 3, 3, 1, 8, 3, 2, 3, 4])], [tensor([0.8035, 0.9956, 0.9477, 0.8352, 0.9765, 0.8366, 0.9726, 0.9030, 0.9948,\n",
            "        0.9413]), tensor([3, 7, 9, 0, 2, 1, 5, 2, 6, 5])], [tensor([0.6322, 0.9953, 0.8536, 0.9421, 0.7061, 0.9864, 0.5361, 0.8851, 0.8475,\n",
            "        0.5016]), tensor([6, 9, 8, 4, 9, 7, 0, 5, 7, 0])], [tensor([0.5843, 0.9264, 0.7050, 0.9640, 0.8978, 0.8595, 0.7524, 0.9504, 0.9338,\n",
            "        0.6180]), tensor([5, 8, 0, 5, 8, 3, 9, 5, 5, 0])], [tensor([0.9979, 0.7675, 0.8707, 0.9494, 0.8491, 0.9533, 0.9058, 0.4150, 0.4667,\n",
            "        0.4754]), tensor([7, 3, 0, 6, 3, 7, 3, 0, 0, 2])], [tensor([0.9927, 0.4960, 0.6404, 0.9613, 0.9619, 0.9894, 0.7449, 0.9081, 0.9931,\n",
            "        0.7391]), tensor([6, 8, 0, 2, 9, 7, 0, 5, 6, 3])], [tensor([0.9308, 0.9776, 0.4984, 0.9769, 0.9687, 0.9911, 0.6330, 0.4271, 0.9793,\n",
            "        0.9772]), tensor([8, 6, 2, 6, 9, 6, 0, 0, 4, 6])], [tensor([0.9381, 0.7960, 0.8710, 0.4705, 0.9964, 0.9952, 0.9910, 0.9310, 0.9706,\n",
            "        0.9655]), tensor([0, 8, 3, 1, 7, 6, 7, 3, 5, 9])], [tensor([0.9432, 0.9635, 0.5028, 0.9580, 0.9588, 0.9620, 0.9918, 0.9177, 0.9870,\n",
            "        0.8329]), tensor([2, 4, 1, 2, 5, 3, 6, 5, 6, 5])], [tensor([0.9365, 0.8400, 0.3139, 0.8305, 0.7078, 0.6727, 0.3953, 0.9720, 0.9634,\n",
            "        0.7467]), tensor([4, 3, 2, 1, 9, 1, 1, 7, 1, 1])], [tensor([0.3902, 0.9671, 0.9740, 0.9819, 0.8278, 0.9934, 0.9987, 0.8523, 0.9964,\n",
            "        0.7828]), tensor([2, 2, 9, 9, 5, 6, 6, 9, 9, 2])], [tensor([0.5620, 0.5264, 0.9398, 0.5408, 0.9500, 0.9535, 0.9712, 0.9886, 0.8915,\n",
            "        0.8163]), tensor([1, 1, 4, 0, 5, 9, 2, 4, 2, 8])], [tensor([0.9293, 0.9964, 0.9952, 0.9447, 0.9649, 0.9229, 0.9340, 0.7023, 0.7995,\n",
            "        0.5132]), tensor([1, 6, 6, 8, 8, 5, 8, 1, 8, 3])], [tensor([0.9103, 0.3574, 0.9774, 0.9838, 0.9720, 0.9858, 0.9678, 0.9954, 0.6331,\n",
            "        0.8341]), tensor([8, 2, 2, 4, 8, 5, 0, 7, 1, 0])], [tensor([0.9774, 0.9633, 0.9691, 0.9874, 0.9781, 0.9874, 0.8808, 0.9180, 0.9272,\n",
            "        0.9856]), tensor([9, 5, 5, 7, 4, 2, 3, 5, 1, 4])], [tensor([0.7992, 0.4587, 0.8559, 0.6542, 0.2614, 0.3563, 0.9762, 0.9244, 0.7512,\n",
            "        0.8265]), tensor([8, 0, 5, 0, 2, 0, 7, 4, 1, 9])], [tensor([0.9751, 0.8522, 0.9869, 0.9444, 0.9849, 0.9743, 0.9043, 0.9609, 0.8608,\n",
            "        0.9925]), tensor([2, 0, 5, 5, 9, 8, 3, 8, 1, 6])], [tensor([0.7625, 0.9929, 0.9778, 0.9501, 0.9954, 0.5219, 0.8701, 0.8127, 0.9442,\n",
            "        0.2899]), tensor([8, 6, 6, 6, 4, 1, 3, 9, 6, 2])], [tensor([0.9040, 0.9715, 0.9495, 0.7515, 0.9714, 0.8426, 0.9885, 0.9870, 0.9612,\n",
            "        0.6847]), tensor([0, 7, 8, 1, 9, 3, 6, 6, 9, 3])], [tensor([0.7211, 0.9981, 0.6679, 0.5481, 0.8457, 0.9967, 0.9869, 0.9950, 0.5592,\n",
            "        0.8902]), tensor([3, 7, 1, 9, 1, 7, 2, 4, 0, 4])], [tensor([0.5298, 0.7722, 0.9307, 0.3691, 0.9725, 0.9099, 0.9006, 0.9889, 0.9857,\n",
            "        0.7175]), tensor([3, 8, 3, 2, 4, 9, 1, 9, 2, 1])], [tensor([0.9771, 0.6965, 0.9331, 0.9100, 0.7904, 0.8799, 0.4794, 0.8820, 0.8474,\n",
            "        0.2157]), tensor([5, 2, 4, 5, 3, 3, 5, 2, 5, 0])], [tensor([0.4553, 0.9913, 0.9607, 0.9945, 0.8950, 0.8872, 0.9267, 0.6836, 0.9291,\n",
            "        0.8384]), tensor([0, 7, 5, 4, 1, 6, 2, 3, 8, 3])], [tensor([0.9811, 0.4822, 0.7467, 0.9785, 0.8937, 0.9893, 0.8513, 0.8172, 0.7578,\n",
            "        0.9355]), tensor([2, 0, 9, 2, 3, 9, 1, 5, 8, 6])], [tensor([0.9459, 0.7225, 0.8246, 0.9950, 0.9605, 0.9229, 0.9542, 0.9951, 0.8776,\n",
            "        0.9809]), tensor([8, 5, 8, 4, 9, 4, 5, 4, 2, 2])], [tensor([0.9284, 0.9697, 0.9454, 0.7934, 0.8127, 0.8200, 0.4392, 0.9324, 0.9961,\n",
            "        0.9963]), tensor([5, 5, 2, 9, 8, 3, 7, 4, 7, 4])], [tensor([0.9939, 0.6339, 0.9650, 0.8541, 0.8338, 0.4115, 0.6973, 0.3561, 0.7153,\n",
            "        0.9756]), tensor([6, 0, 9, 1, 0, 2, 5, 4, 9, 7])], [tensor([0.9890, 0.9978, 0.9911, 0.5627, 0.7629, 0.9945, 0.9096, 0.9829, 0.4061,\n",
            "        0.6044]), tensor([7, 7, 6, 5, 3, 6, 1, 4, 1, 1])], [tensor([0.2749, 0.9821, 0.7886, 0.9910, 0.5549, 0.9622, 0.9551, 0.9972, 0.8362,\n",
            "        0.8239]), tensor([2, 9, 5, 7, 2, 4, 2, 7, 1, 0])], [tensor([0.9968, 0.9984, 0.8980, 0.5648, 0.9074, 0.7545, 0.9820, 0.9942, 0.9864,\n",
            "        0.4339]), tensor([7, 4, 2, 9, 6, 6, 2, 4, 2, 1])], [tensor([0.8828, 0.9928, 0.9798, 0.9981, 0.9264, 0.9957, 0.9672, 0.9822, 0.9637,\n",
            "        0.3935]), tensor([0, 9, 6, 7, 8, 7, 8, 7, 1, 0])], [tensor([0.8590, 0.8516, 0.9935, 0.4528, 0.9242, 0.9939, 0.7801, 0.7928, 0.9698,\n",
            "        0.3640]), tensor([0, 3, 7, 9, 8, 9, 6, 1, 6, 2])], [tensor([0.9362, 0.9946, 0.9624, 0.9684, 0.8779, 0.9814, 0.9800, 0.8052, 0.9879,\n",
            "        0.9767]), tensor([9, 7, 8, 2, 3, 8, 8, 3, 4, 5])], [tensor([0.7457, 0.6877, 0.9504, 0.9256, 0.6316, 0.5412, 0.9640, 0.2682, 0.9802,\n",
            "        0.6738]), tensor([1, 1, 5, 5, 6, 4, 4, 4, 7, 9])], [tensor([0.7024, 0.9938, 0.9343, 0.2453, 0.9665, 0.7965, 0.9643, 0.8739, 0.4271,\n",
            "        0.8530]), tensor([8, 6, 5, 2, 9, 8, 4, 3, 0, 8])], [tensor([0.9612, 0.7069, 0.8370, 0.9775, 0.9795, 0.8478, 0.9950, 0.5524, 0.9966,\n",
            "        0.9987]), tensor([2, 0, 6, 5, 6, 2, 6, 1, 4, 7])], [tensor([0.7517, 0.5115, 0.9932, 0.6541, 0.8301, 0.9819, 0.5355, 0.3115, 0.9971,\n",
            "        0.8959]), tensor([5, 4, 7, 8, 3, 7, 1, 7, 6, 7])], [tensor([0.9685, 0.7219, 0.9539, 0.8369, 0.9822, 0.6702, 0.9882, 0.9771, 0.9753,\n",
            "        0.6098]), tensor([2, 0, 8, 4, 4, 3, 2, 1, 9, 1])], [tensor([0.9013, 0.9300, 0.9807, 0.9285, 0.8831, 0.9874, 0.9812, 0.9948, 0.7567,\n",
            "        0.9605]), tensor([4, 8, 4, 5, 3, 9, 7, 7, 1, 8])], [tensor([0.7949, 0.8182, 0.9983, 0.9619, 0.4074, 0.9820, 0.9932, 0.9946, 0.9279,\n",
            "        0.9554]), tensor([3, 3, 6, 2, 1, 4, 9, 7, 6, 8])], [tensor([0.7822, 0.5038, 0.9940, 0.9879, 0.9462, 0.7955, 0.5740, 0.8737, 0.9664,\n",
            "        0.7528]), tensor([9, 8, 7, 2, 5, 1, 9, 2, 7, 3])], [tensor([0.9903, 0.8354, 0.9336, 0.8588, 0.9898, 0.8482, 0.9893, 0.9637, 0.9241,\n",
            "        0.8613]), tensor([7, 0, 5, 5, 4, 1, 9, 8, 6, 5])], [tensor([0.9776, 0.8626, 0.9964, 0.6390, 0.9304, 0.9919, 0.9813, 0.5977, 0.8319,\n",
            "        0.9870]), tensor([9, 5, 7, 2, 6, 9, 2, 3, 2, 9])], [tensor([0.8046, 0.9956, 0.8785, 0.9693, 0.7906, 0.9889, 0.9878, 0.7589, 0.4797,\n",
            "        0.7719]), tensor([1, 7, 9, 5, 8, 8, 4, 3, 3, 9])], [tensor([0.9842, 0.9630, 0.9873, 0.9586, 0.9918, 0.9970, 0.6175, 0.8181, 0.9994,\n",
            "        0.9214]), tensor([4, 5, 7, 2, 2, 6, 1, 0, 4, 8])], [tensor([0.5386, 0.9031, 0.9943, 0.9926, 0.9144, 0.9964, 0.8142, 0.9857, 0.9651,\n",
            "        0.4020]), tensor([1, 0, 6, 9, 5, 4, 1, 9, 4, 1])], [tensor([0.8924, 0.9852, 0.9938, 0.7573, 0.7163, 0.8548, 0.8584, 0.9735, 0.9993,\n",
            "        0.2954]), tensor([6, 4, 6, 2, 0, 9, 5, 3, 7, 5])], [tensor([0.9486, 0.8858, 0.6683, 0.9931, 0.9588, 0.7870, 0.9977, 0.3086, 0.7135,\n",
            "        0.9408]), tensor([7, 8, 1, 6, 5, 1, 7, 6, 0, 2])], [tensor([0.9317, 0.9438, 0.8336, 0.4528, 0.2852, 0.8012, 0.9930, 0.8803, 0.9322,\n",
            "        0.2401]), tensor([4, 5, 5, 1, 0, 8, 9, 2, 5, 1])], [tensor([0.8995, 0.4452, 0.9732, 0.9841, 0.9851, 0.5996, 0.9783, 0.9978, 0.9358,\n",
            "        0.9893]), tensor([0, 3, 8, 2, 4, 3, 2, 6, 8, 7])], [tensor([0.9751, 0.5927, 0.9771, 0.9714, 0.9255, 0.9361, 0.8522, 0.9944, 0.9797,\n",
            "        0.6238]), tensor([7, 8, 5, 8, 9, 9, 5, 4, 5, 3])], [tensor([0.9818, 0.9919, 0.9694, 0.8682, 0.8914, 0.9041, 0.8243, 0.9865, 0.6607,\n",
            "        0.6868]), tensor([9, 9, 2, 9, 9, 9, 3, 7, 2, 9])], [tensor([0.9608, 0.9521, 0.6463, 0.6303, 0.9725, 0.9924, 0.9076, 0.9771, 0.9287,\n",
            "        0.7856]), tensor([3, 8, 3, 1, 5, 2, 3, 2, 5, 2])], [tensor([0.7033, 0.9510, 0.9604, 0.9855, 0.9952, 0.9731, 0.9921, 0.7689, 0.9504,\n",
            "        0.9794]), tensor([0, 3, 9, 2, 4, 6, 7, 9, 2, 7])], [tensor([0.9415, 0.9877, 0.8910, 0.6513, 0.5747, 0.9971, 0.6017, 0.7140, 0.9926,\n",
            "        0.5110]), tensor([3, 7, 5, 2, 9, 9, 7, 3, 7, 9])], [tensor([0.9961, 0.7814, 0.8851, 0.7760, 0.8771, 0.9853, 0.9846, 0.9915, 0.9718,\n",
            "        0.9614]), tensor([7, 8, 8, 8, 5, 9, 9, 8, 7, 2])], [tensor([0.6225, 0.9834, 0.9933, 0.7235, 0.9821, 0.9901, 0.9249, 0.4271, 0.3868,\n",
            "        0.9691]), tensor([1, 5, 9, 1, 5, 9, 3, 8, 9, 6])], [tensor([0.9179, 0.9915, 0.9930, 0.8331, 0.9901, 0.8955, 0.9749, 0.4220, 0.8632,\n",
            "        0.9901]), tensor([1, 5, 6, 6, 7, 3, 8, 2, 1, 9])], [tensor([0.9956, 0.9076, 0.4423, 0.9957, 0.3614, 0.9770, 0.9990, 0.9499, 0.4716,\n",
            "        0.9935]), tensor([6, 5, 5, 2, 9, 2, 4, 9, 0, 7])], [tensor([0.7205, 0.8947, 0.9989, 0.9893, 0.9934, 0.9445, 0.3695, 0.6939, 0.7896,\n",
            "        0.9282]), tensor([8, 4, 4, 6, 6, 5, 2, 0, 0, 7])], [tensor([0.5297, 0.6221, 0.9736, 0.8948, 0.9599, 0.9984, 0.9855, 0.8790, 0.8758,\n",
            "        0.8736]), tensor([4, 1, 9, 9, 4, 4, 8, 8, 2, 3])], [tensor([0.9574, 0.7115, 0.8527, 0.9968, 0.9954, 0.4025, 0.9715, 0.8692, 0.4353,\n",
            "        0.9656]), tensor([2, 3, 8, 7, 7, 4, 9, 9, 9, 4])], [tensor([0.8221, 0.9973, 0.9946, 0.8567, 0.9541, 0.5633, 0.6038, 0.8875, 0.8175,\n",
            "        0.9963]), tensor([3, 7, 7, 6, 6, 1, 1, 2, 1, 7])], [tensor([0.9831, 0.5435, 0.9984, 0.9956, 0.3135, 0.9921, 0.8606, 0.6919, 0.6282,\n",
            "        0.8544]), tensor([2, 0, 6, 6, 7, 7, 3, 0, 2, 2])], [tensor([0.7862, 0.9732, 0.9916, 0.9636, 0.9316, 0.9835, 0.3535, 0.5897, 0.7860,\n",
            "        0.7059]), tensor([8, 2, 6, 7, 2, 8, 1, 7, 1, 8])], [tensor([0.9815, 0.9918, 0.9882, 0.8470, 0.9884, 0.9387, 0.6460, 0.4265, 0.9846,\n",
            "        0.5563]), tensor([2, 6, 9, 3, 2, 9, 5, 0, 9, 1])], [tensor([0.9779, 0.9867, 0.9817, 0.9651, 0.9333, 0.9840, 0.9361, 0.8284, 0.9958,\n",
            "        0.4926]), tensor([2, 7, 6, 9, 5, 5, 8, 1, 4, 2])], [tensor([0.7584, 0.8963, 0.9844, 0.3080, 0.9883, 0.6429, 0.6903, 0.8340, 0.9957,\n",
            "        0.7567]), tensor([9, 8, 4, 5, 6, 9, 0, 3, 7, 3])], [tensor([0.7414, 0.6418, 0.1920, 0.4548, 0.7479, 0.4652, 0.9302, 0.9592, 0.8731,\n",
            "        0.8568]), tensor([3, 2, 5, 6, 2, 8, 8, 8, 3, 5])], [tensor([0.8117, 0.8936, 0.9972, 0.9575, 0.8013, 0.9937, 0.9950, 0.9931, 0.9671,\n",
            "        0.9929]), tensor([5, 3, 6, 2, 0, 9, 9, 9, 4, 2])], [tensor([0.9906, 0.9583, 0.9902, 0.6996, 0.4846, 0.8599, 0.8535, 0.9047, 0.9803,\n",
            "        0.4322]), tensor([4, 4, 7, 1, 6, 1, 8, 8, 6, 6])], [tensor([0.9922, 0.9839, 0.9136, 0.9427, 0.3643, 0.9285, 0.5617, 0.8842, 0.9945,\n",
            "        0.7326]), tensor([4, 8, 3, 8, 6, 2, 6, 5, 7, 3])], [tensor([0.5691, 0.9847, 0.9877, 0.2143, 0.9872, 0.9506, 0.9818, 0.7917, 0.8460,\n",
            "        0.9980]), tensor([9, 8, 4, 2, 6, 8, 6, 1, 2, 4])], [tensor([0.5987, 0.5342, 0.8404, 0.8914, 0.9941, 0.8179, 0.9709, 0.9891, 0.9955,\n",
            "        0.9968]), tensor([1, 1, 5, 3, 5, 0, 6, 7, 7, 7])], [tensor([0.5255, 0.7336, 0.9897, 0.6696, 0.7900, 0.8234, 0.8974, 0.9886, 0.8620,\n",
            "        0.9899]), tensor([3, 0, 8, 9, 3, 0, 6, 7, 8, 7])], [tensor([0.6137, 0.7269, 0.3950, 0.6526, 0.4235, 0.7302, 0.8789, 0.9820, 0.9347,\n",
            "        0.9075]), tensor([1, 9, 2, 1, 2, 5, 9, 4, 5, 2])], [tensor([0.9677, 0.9864, 0.7335, 0.9845, 0.9755, 0.9787, 0.8958, 0.5683, 0.9784,\n",
            "        0.9136]), tensor([9, 9, 5, 7, 2, 2, 5, 4, 5, 5])], [tensor([0.2295, 0.7099, 0.7731, 0.9206, 0.9917, 0.5135, 0.5229, 0.9380, 0.7211,\n",
            "        0.9720]), tensor([1, 3, 3, 8, 4, 0, 0, 2, 0, 8])], [tensor([0.3934, 0.9893, 0.9879, 0.9643, 0.9920, 0.8540, 0.9671, 0.9853, 0.8396,\n",
            "        0.9795]), tensor([2, 4, 4, 9, 6, 5, 3, 5, 0, 8])], [tensor([0.9961, 0.6072, 0.9861, 0.8467, 0.9983, 0.4943, 0.5377, 0.4694, 0.7886,\n",
            "        0.9446]), tensor([4, 0, 6, 5, 6, 2, 2, 9, 3, 2])], [tensor([0.9889, 0.7773, 0.8247, 0.9887, 0.8666, 0.5834, 0.9968, 0.9943, 0.8826,\n",
            "        0.7693]), tensor([4, 3, 9, 9, 9, 6, 4, 4, 1, 3])], [tensor([0.3634, 0.4832, 0.9918, 0.8729, 0.9569, 0.4025, 0.9964, 0.8707, 0.9945,\n",
            "        0.9903]), tensor([8, 2, 7, 0, 4, 9, 6, 0, 7, 2])], [tensor([0.9698, 0.7125, 0.9721, 0.8684, 0.8673, 0.9957, 0.9935, 0.9870, 0.4722,\n",
            "        0.5028]), tensor([5, 1, 8, 7, 1, 6, 9, 5, 6, 0])], [tensor([0.9959, 0.9138, 0.4376, 0.9883, 0.9990, 0.9921, 0.8958, 0.9631, 0.9869,\n",
            "        0.6555]), tensor([9, 3, 9, 5, 6, 6, 3, 7, 4, 1])], [tensor([0.6169, 0.8596, 0.9836, 0.8313, 0.9145, 0.8677, 0.9988, 0.9859, 0.5499,\n",
            "        0.9806]), tensor([1, 9, 5, 9, 8, 8, 4, 6, 3, 4])], [tensor([0.9863, 0.8050, 0.9745, 0.9933, 0.9932, 0.9648, 0.9978, 0.9750, 0.1918,\n",
            "        0.5341]), tensor([6, 1, 3, 6, 4, 8, 7, 2, 2, 2])], [tensor([0.8412, 0.7580, 0.8599, 0.6838, 0.8927, 0.8713, 0.9338, 0.9840, 0.8906,\n",
            "        0.9676]), tensor([1, 0, 1, 5, 8, 3, 2, 5, 5, 5])], [tensor([0.9867, 0.8808, 0.9735, 0.8737, 0.9934, 0.5714, 0.9925, 0.9914, 0.9968,\n",
            "        0.9782]), tensor([4, 5, 9, 9, 7, 1, 5, 7, 7, 6])], [tensor([0.8504, 0.8228, 0.9784, 0.8459, 0.8912, 0.8517, 0.8039, 0.9746, 0.8743,\n",
            "        0.9777]), tensor([9, 3, 4, 3, 5, 0, 0, 6, 3, 5])], [tensor([0.8908, 0.9975, 0.6871, 0.9575, 0.9938, 0.8743, 0.9616, 0.9206, 0.9935,\n",
            "        0.9828]), tensor([9, 6, 1, 9, 7, 3, 2, 9, 7, 8])], [tensor([0.5857, 0.6087, 0.9663, 0.9796, 0.9850, 0.9951, 0.9872, 0.8021, 0.8257,\n",
            "        0.8272]), tensor([8, 9, 9, 2, 6, 6, 7, 5, 9, 5])], [tensor([0.8883, 0.9911, 0.9946, 0.9957, 0.6730, 0.9781, 0.9496, 0.9207, 0.9687,\n",
            "        0.9433]), tensor([5, 4, 4, 9, 5, 2, 3, 5, 5, 3])], [tensor([0.8628, 0.9308, 0.7629, 0.4530, 0.8240, 0.6569, 0.9426, 0.9389, 0.5534,\n",
            "        0.9953]), tensor([1, 5, 8, 8, 8, 4, 2, 8, 6, 7])], [tensor([0.9893, 0.8662, 0.8485, 0.9840, 0.6696, 0.6971, 0.4518, 0.9677, 0.9804,\n",
            "        0.3097]), tensor([7, 3, 1, 9, 5, 1, 1, 2, 9, 1])], [tensor([0.7551, 0.7757, 0.9825, 0.7577, 0.5021, 0.9939, 0.9771, 0.6873, 0.9829,\n",
            "        0.6778]), tensor([8, 1, 6, 1, 3, 7, 9, 0, 7, 0])], [tensor([0.9655, 0.9921, 0.4181, 0.5585, 0.9293, 0.6396, 0.8995, 0.7794, 0.9162,\n",
            "        0.9867]), tensor([6, 6, 6, 1, 5, 4, 6, 1, 2, 7])], [tensor([0.9302, 0.8812, 0.3426, 0.8692, 0.7857, 0.4731, 0.9896, 0.9929, 0.4343,\n",
            "        0.9967]), tensor([2, 5, 5, 3, 3, 5, 4, 7, 2, 4])], [tensor([0.6478, 0.9269, 0.9708, 0.8895, 0.2767, 0.9904, 0.9328, 0.9765, 0.4639,\n",
            "        0.7934]), tensor([1, 5, 6, 9, 0, 5, 3, 4, 0, 0])], [tensor([0.9900, 0.9946, 0.4477, 0.9133, 0.8890, 0.9965, 0.4713, 0.9107, 0.9832,\n",
            "        0.9636]), tensor([4, 6, 3, 6, 5, 7, 4, 9, 9, 2])], [tensor([0.8474, 0.9974, 0.8191, 0.2446, 0.5546, 0.9970, 0.9554, 0.9504, 0.9916,\n",
            "        0.6963]), tensor([2, 6, 1, 9, 0, 6, 9, 3, 2, 4])], [tensor([0.5405, 0.3781, 0.7611, 0.7618, 0.9928, 0.9930, 0.9988, 0.8499, 0.9044,\n",
            "        0.9676]), tensor([1, 7, 5, 9, 2, 9, 6, 8, 3, 8])], [tensor([0.7911, 0.7973, 0.6870, 0.7337, 0.7536, 0.9625, 0.4909, 0.7732, 0.8253,\n",
            "        0.8526]), tensor([3, 2, 1, 8, 3, 2, 6, 3, 5, 0])], [tensor([0.9881, 0.9708, 0.8872, 0.9050, 0.9834, 0.9167, 0.9108, 0.8152, 0.5506,\n",
            "        0.9181]), tensor([7, 9, 6, 1, 4, 9, 2, 3, 0, 3])]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_analysis(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEglqhsIOnKK",
        "outputId": "e3062fa0-ec33-4adf-b42f-7814a224385b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model inaccurately predicted automobile with 30.468297004699707% confidence.\n",
            "Model inaccurately predicted horse with 26.002177596092224% confidence.\n",
            "Model inaccurately predicted truck with 47.97724783420563% confidence.\n",
            "Model inaccurately predicted cat with 55.37012219429016% confidence.\n",
            "Model inaccurately predicted bird with 46.18670046329498% confidence.\n",
            "Model inaccurately predicted truck with 36.99069321155548% confidence.\n",
            "Model inaccurately predicted deer with 69.54557299613953% confidence.\n",
            "Model inaccurately predicted bird with 68.53422522544861% confidence.\n",
            "Model accurately predicted dog with 80.16961216926575% confidence.\n",
            "Model inaccurately predicted deer with 63.88816237449646% confidence.\n",
            "Model inaccurately predicted dog with 86.51031255722046% confidence.\n",
            "Model inaccurately predicted ship with 31.448206305503845% confidence.\n",
            "Model inaccurately predicted truck with 69.19840574264526% confidence.\n",
            "Model inaccurately predicted cat with 88.7103259563446% confidence.\n",
            "Model accurately predicted frog with 98.82681965827942% confidence.\n",
            "Model inaccurately predicted truck with 70.13311386108398% confidence.\n",
            "Model inaccurately predicted cat with 66.17206335067749% confidence.\n",
            "Model inaccurately predicted cat with 84.09743309020996% confidence.\n",
            "Model inaccurately predicted bird with 86.79799437522888% confidence.\n",
            "Model inaccurately predicted dog with 52.0396888256073% confidence.\n",
            "Model accurately predicted horse with 99.35798645019531% confidence.\n",
            "Model inaccurately predicted bird with 40.382394194602966% confidence.\n",
            "Model inaccurately predicted truck with 49.38937723636627% confidence.\n",
            "Model accurately predicted frog with 99.60929751396179% confidence.\n",
            "Model inaccurately predicted ship with 48.41931760311127% confidence.\n",
            "Model inaccurately predicted ship with 38.51282298564911% confidence.\n",
            "Model accurately predicted ship with 96.4232325553894% confidence.\n",
            "Model inaccurately predicted automobile with 51.220703125% confidence.\n",
            "Model accurately predicted dog with 98.17729592323303% confidence.\n",
            "Model inaccurately predicted bird with 28.85544002056122% confidence.\n",
            "Model inaccurately predicted horse with 46.964430809020996% confidence.\n",
            "Model inaccurately predicted bird with 37.06227242946625% confidence.\n",
            "Model accurately predicted automobile with 86.11834645271301% confidence.\n",
            "Model inaccurately predicted truck with 59.50525999069214% confidence.\n",
            "Model accurately predicted deer with 94.45899724960327% confidence.\n",
            "Model inaccurately predicted truck with 74.35654997825623% confidence.\n",
            "Model accurately predicted deer with 79.57754731178284% confidence.\n",
            "Model inaccurately predicted automobile with 42.1556830406189% confidence.\n",
            "Model inaccurately predicted deer with 27.15896964073181% confidence.\n",
            "Model inaccurately predicted dog with 60.66264510154724% confidence.\n",
            "Model accurately predicted horse with 99.70210194587708% confidence.\n",
            "Model inaccurately predicted truck with 53.62909436225891% confidence.\n",
            "Model inaccurately predicted bird with 65.0325357913971% confidence.\n",
            "Model accurately predicted horse with 99.42485094070435% confidence.\n",
            "Model inaccurately predicted dog with 50.446027517318726% confidence.\n",
            "Model inaccurately predicted deer with 39.89304006099701% confidence.\n",
            "Model inaccurately predicted automobile with 33.17248225212097% confidence.\n",
            "Model inaccurately predicted truck with 92.38580465316772% confidence.\n",
            "Model inaccurately predicted automobile with 61.03358864784241% confidence.\n",
            "Model inaccurately predicted automobile with 54.60067391395569% confidence.\n",
            "Model inaccurately predicted horse with 83.33482146263123% confidence.\n",
            "Model inaccurately predicted truck with 65.68684577941895% confidence.\n",
            "Model inaccurately predicted dog with 32.37026035785675% confidence.\n",
            "Model inaccurately predicted dog with 55.78917860984802% confidence.\n",
            "Model inaccurately predicted truck with 47.28972911834717% confidence.\n",
            "Model inaccurately predicted truck with 63.67969512939453% confidence.\n",
            "Model accurately predicted airplane with 61.0478401184082% confidence.\n",
            "Model inaccurately predicted ship with 23.94760102033615% confidence.\n",
            "Model inaccurately predicted truck with 18.7240868806839% confidence.\n",
            "Model accurately predicted airplane with 62.4763548374176% confidence.\n",
            "Model inaccurately predicted truck with 52.850425243377686% confidence.\n",
            "Model inaccurately predicted truck with 60.50105094909668% confidence.\n",
            "Model accurately predicted deer with 98.5622227191925% confidence.\n",
            "Model inaccurately predicted truck with 46.248817443847656% confidence.\n",
            "Model inaccurately predicted dog with 35.24586856365204% confidence.\n",
            "Model inaccurately predicted ship with 62.38921284675598% confidence.\n",
            "Model inaccurately predicted bird with 59.206950664520264% confidence.\n",
            "Model inaccurately predicted dog with 27.926817536354065% confidence.\n",
            "Model inaccurately predicted dog with 60.90376377105713% confidence.\n",
            "Model accurately predicted bird with 81.51576519012451% confidence.\n",
            "Model inaccurately predicted dog with 61.95932626724243% confidence.\n",
            "Model inaccurately predicted horse with 48.19802641868591% confidence.\n",
            "Model inaccurately predicted truck with 47.88409173488617% confidence.\n",
            "Model inaccurately predicted bird with 27.07570791244507% confidence.\n",
            "Model accurately predicted truck with 98.97176027297974% confidence.\n",
            "Model inaccurately predicted deer with 65.97152352333069% confidence.\n",
            "Model inaccurately predicted bird with 39.15955424308777% confidence.\n",
            "Model inaccurately predicted bird with 39.74436819553375% confidence.\n",
            "Model accurately predicted automobile with 87.86535263061523% confidence.\n",
            "Model inaccurately predicted truck with 49.606090784072876% confidence.\n",
            "Model inaccurately predicted horse with 91.36123061180115% confidence.\n",
            "Model inaccurately predicted bird with 68.40692162513733% confidence.\n",
            "Model inaccurately predicted dog with 42.327749729156494% confidence.\n",
            "Model inaccurately predicted ship with 37.62362003326416% confidence.\n",
            "Model inaccurately predicted deer with 55.41670322418213% confidence.\n",
            "Model inaccurately predicted bird with 52.0377516746521% confidence.\n",
            "Model accurately predicted automobile with 75.43070316314697% confidence.\n",
            "Model inaccurately predicted horse with 51.66935920715332% confidence.\n",
            "Model inaccurately predicted deer with 62.546348571777344% confidence.\n",
            "Model inaccurately predicted bird with 46.671995520591736% confidence.\n",
            "Model accurately predicted horse with 99.06284213066101% confidence.\n",
            "Model inaccurately predicted cat with 57.95101523399353% confidence.\n",
            "Model inaccurately predicted horse with 47.533175349235535% confidence.\n",
            "Model inaccurately predicted truck with 59.13964509963989% confidence.\n",
            "Model accurately predicted frog with 99.74310994148254% confidence.\n",
            "Model inaccurately predicted cat with 31.61904215812683% confidence.\n",
            "Model inaccurately predicted truck with 66.93748831748962% confidence.\n",
            "Model accurately predicted dog with 94.92974281311035% confidence.\n",
            "Model inaccurately predicted truck with 81.67056441307068% confidence.\n",
            "Model inaccurately predicted bird with 46.69222831726074% confidence.\n",
            "Model accurately predicted cat with 87.79842257499695% confidence.\n",
            "Model inaccurately predicted deer with 94.03247833251953% confidence.\n",
            "Model inaccurately predicted ship with 47.938552498817444% confidence.\n",
            "Model accurately predicted airplane with 53.30667495727539% confidence.\n",
            "Model inaccurately predicted cat with 42.08293259143829% confidence.\n",
            "Model inaccurately predicted horse with 40.27639925479889% confidence.\n",
            "Model inaccurately predicted truck with 92.31513738632202% confidence.\n",
            "Model inaccurately predicted truck with 97.49879240989685% confidence.\n",
            "Model inaccurately predicted truck with 70.67044973373413% confidence.\n",
            "Model inaccurately predicted ship with 38.207271695137024% confidence.\n",
            "Model accurately predicted frog with 99.54597353935242% confidence.\n",
            "Model inaccurately predicted ship with 48.8764762878418% confidence.\n",
            "Model accurately predicted deer with 98.11310768127441% confidence.\n",
            "Model inaccurately predicted truck with 34.42353308200836% confidence.\n",
            "Model inaccurately predicted dog with 60.46488285064697% confidence.\n",
            "Model inaccurately predicted cat with 77.73800492286682% confidence.\n",
            "Model accurately predicted truck with 81.80912733078003% confidence.\n",
            "Model inaccurately predicted bird with 47.36579954624176% confidence.\n",
            "Model inaccurately predicted bird with 35.201478004455566% confidence.\n",
            "Model accurately predicted cat with 81.5716028213501% confidence.\n",
            "Model inaccurately predicted bird with 31.638869643211365% confidence.\n",
            "Model inaccurately predicted truck with 60.559117794036865% confidence.\n",
            "Model inaccurately predicted dog with 37.130481004714966% confidence.\n",
            "Model inaccurately predicted horse with 47.364071011543274% confidence.\n",
            "Model accurately predicted cat with 85.43117046356201% confidence.\n",
            "Model inaccurately predicted truck with 60.24581789970398% confidence.\n",
            "Model inaccurately predicted truck with 73.65318536758423% confidence.\n",
            "Model inaccurately predicted deer with 68.10135841369629% confidence.\n",
            "Model inaccurately predicted truck with 60.17138957977295% confidence.\n",
            "Model inaccurately predicted automobile with 40.400320291519165% confidence.\n",
            "Model inaccurately predicted truck with 65.73086380958557% confidence.\n",
            "Model accurately predicted deer with 93.05758476257324% confidence.\n",
            "Model inaccurately predicted truck with 46.615830063819885% confidence.\n",
            "Model inaccurately predicted bird with 51.46656036376953% confidence.\n",
            "Model inaccurately predicted deer with 51.34592652320862% confidence.\n",
            "Model accurately predicted automobile with 75.95946192741394% confidence.\n",
            "Model inaccurately predicted dog with 66.30499362945557% confidence.\n",
            "Model inaccurately predicted dog with 77.42106318473816% confidence.\n",
            "Model inaccurately predicted truck with 55.39296269416809% confidence.\n",
            "Model inaccurately predicted deer with 53.75175476074219% confidence.\n",
            "Model inaccurately predicted dog with 22.8183314204216% confidence.\n",
            "Model inaccurately predicted truck with 54.76832389831543% confidence.\n",
            "Model inaccurately predicted truck with 48.41315746307373% confidence.\n",
            "Model accurately predicted deer with 99.02432560920715% confidence.\n",
            "Model inaccurately predicted horse with 43.99363696575165% confidence.\n",
            "Model inaccurately predicted dog with 39.025864005088806% confidence.\n",
            "Model inaccurately predicted horse with 56.84199333190918% confidence.\n",
            "Model inaccurately predicted bird with 38.89254331588745% confidence.\n",
            "Model accurately predicted automobile with 62.01938986778259% confidence.\n",
            "Model inaccurately predicted truck with 56.39500617980957% confidence.\n",
            "Model inaccurately predicted horse with 61.39334440231323% confidence.\n",
            "Model inaccurately predicted dog with 38.09758424758911% confidence.\n",
            "Model accurately predicted deer with 99.83991980552673% confidence.\n",
            "Model inaccurately predicted dog with 29.092499613761902% confidence.\n",
            "Model inaccurately predicted automobile with 58.91183018684387% confidence.\n",
            "Model inaccurately predicted horse with 35.01439690589905% confidence.\n",
            "Model accurately predicted deer with 97.3235547542572% confidence.\n",
            "Model inaccurately predicted bird with 43.26196312904358% confidence.\n",
            "Model inaccurately predicted bird with 48.6630916595459% confidence.\n",
            "Model accurately predicted automobile with 85.92726588249207% confidence.\n",
            "Model inaccurately predicted bird with 61.45404577255249% confidence.\n",
            "Model inaccurately predicted dog with 37.347063422203064% confidence.\n",
            "Model inaccurately predicted dog with 60.18492579460144% confidence.\n",
            "Model inaccurately predicted bird with 21.767814457416534% confidence.\n",
            "Model inaccurately predicted bird with 42.11271107196808% confidence.\n",
            "Model accurately predicted dog with 91.37044548988342% confidence.\n",
            "Model inaccurately predicted bird with 28.99152636528015% confidence.\n",
            "Model inaccurately predicted bird with 45.8181768655777% confidence.\n",
            "Model inaccurately predicted truck with 55.09463548660278% confidence.\n",
            "Model inaccurately predicted horse with 49.75478947162628% confidence.\n",
            "Model inaccurately predicted horse with 36.84569001197815% confidence.\n",
            "Model inaccurately predicted truck with 83.51522088050842% confidence.\n",
            "Model inaccurately predicted truck with 77.26550698280334% confidence.\n",
            "Model inaccurately predicted bird with 45.068979263305664% confidence.\n",
            "Model inaccurately predicted truck with 87.52478361129761% confidence.\n",
            "Model inaccurately predicted horse with 61.99411153793335% confidence.\n",
            "Model accurately predicted bird with 88.36976885795593% confidence.\n",
            "Model inaccurately predicted bird with 23.79215657711029% confidence.\n",
            "Model inaccurately predicted truck with 69.23599243164062% confidence.\n",
            "Model inaccurately predicted truck with 52.56344676017761% confidence.\n",
            "Model accurately predicted automobile with 96.10434174537659% confidence.\n",
            "Model inaccurately predicted cat with 62.681615352630615% confidence.\n",
            "Model inaccurately predicted horse with 54.927849769592285% confidence.\n",
            "Model inaccurately predicted bird with 46.68477475643158% confidence.\n",
            "Model accurately predicted airplane with 20.507369935512543% confidence.\n",
            "Model inaccurately predicted truck with 56.28848671913147% confidence.\n",
            "Model inaccurately predicted deer with 65.59900641441345% confidence.\n",
            "Model inaccurately predicted deer with 53.126633167266846% confidence.\n",
            "Model inaccurately predicted bird with 32.02052116394043% confidence.\n",
            "Model accurately predicted dog with 90.16088843345642% confidence.\n",
            "Model inaccurately predicted truck with 70.60649394989014% confidence.\n",
            "Model inaccurately predicted bird with 95.6303358078003% confidence.\n",
            "Model inaccurately predicted bird with 79.32189702987671% confidence.\n",
            "Model inaccurately predicted dog with 24.060039222240448% confidence.\n",
            "Model inaccurately predicted cat with 35.4916512966156% confidence.\n",
            "Model inaccurately predicted bird with 31.91203474998474% confidence.\n",
            "Model accurately predicted truck with 99.25422668457031% confidence.\n",
            "Model inaccurately predicted bird with 38.91974985599518% confidence.\n",
            "Model inaccurately predicted bird with 57.22206234931946% confidence.\n",
            "Model accurately predicted bird with 97.13894128799438% confidence.\n",
            "Model inaccurately predicted bird with 58.9563250541687% confidence.\n",
            "Model accurately predicted ship with 94.62974667549133% confidence.\n",
            "Model inaccurately predicted truck with 59.591859579086304% confidence.\n",
            "Model inaccurately predicted dog with 22.567492723464966% confidence.\n",
            "Model inaccurately predicted horse with 67.95145869255066% confidence.\n",
            "Model inaccurately predicted bird with 37.28112876415253% confidence.\n",
            "Model accurately predicted horse with 99.78947043418884% confidence.\n",
            "Model inaccurately predicted bird with 53.609007596969604% confidence.\n",
            "Model inaccurately predicted deer with 43.425336480140686% confidence.\n",
            "Model inaccurately predicted dog with 39.054250717163086% confidence.\n",
            "Model inaccurately predicted truck with 38.5694682598114% confidence.\n",
            "Model inaccurately predicted truck with 54.88882064819336% confidence.\n",
            "Model accurately predicted cat with 63.94967436790466% confidence.\n",
            "Model inaccurately predicted bird with 45.82294821739197% confidence.\n",
            "Model inaccurately predicted truck with 79.36934232711792% confidence.\n",
            "Model accurately predicted bird with 76.10695362091064% confidence.\n",
            "Model inaccurately predicted deer with 63.69901895523071% confidence.\n",
            "Model inaccurately predicted deer with 52.4314820766449% confidence.\n",
            "Model inaccurately predicted dog with 87.13987469673157% confidence.\n",
            "Model inaccurately predicted automobile with 43.988847732543945% confidence.\n",
            "Model inaccurately predicted deer with 59.835875034332275% confidence.\n",
            "Model accurately predicted truck with 83.1483781337738% confidence.\n",
            "Model inaccurately predicted automobile with 55.65118193626404% confidence.\n",
            "Model inaccurately predicted dog with 94.33712363243103% confidence.\n",
            "Model inaccurately predicted dog with 44.90600526332855% confidence.\n",
            "Model inaccurately predicted horse with 28.572499752044678% confidence.\n",
            "Model inaccurately predicted truck with 51.94714665412903% confidence.\n",
            "Model inaccurately predicted deer with 63.495051860809326% confidence.\n",
            "Model inaccurately predicted dog with 54.88636493682861% confidence.\n",
            "Model accurately predicted frog with 97.79528975486755% confidence.\n",
            "Model inaccurately predicted truck with 73.87245297431946% confidence.\n",
            "Model inaccurately predicted horse with 28.50964665412903% confidence.\n",
            "Model inaccurately predicted truck with 64.15094137191772% confidence.\n",
            "Model accurately predicted cat with 95.76034545898438% confidence.\n",
            "Model inaccurately predicted horse with 94.43439245223999% confidence.\n",
            "Model inaccurately predicted bird with 40.95844030380249% confidence.\n",
            "Model inaccurately predicted automobile with 43.50516200065613% confidence.\n",
            "Model accurately predicted frog with 99.44309592247009% confidence.\n",
            "Model inaccurately predicted deer with 18.56827586889267% confidence.\n",
            "Model inaccurately predicted dog with 27.954024076461792% confidence.\n",
            "Model inaccurately predicted truck with 53.3439576625824% confidence.\n",
            "Model inaccurately predicted cat with 61.678701639175415% confidence.\n",
            "Model inaccurately predicted truck with 29.3656587600708% confidence.\n",
            "Model accurately predicted automobile with 89.25995826721191% confidence.\n",
            "Model inaccurately predicted cat with 46.10294699668884% confidence.\n",
            "Model inaccurately predicted dog with 61.20502948760986% confidence.\n",
            "Model accurately predicted deer with 99.9521255493164% confidence.\n",
            "Model inaccurately predicted bird with 49.61654543876648% confidence.\n",
            "Model inaccurately predicted ship with 41.24225080013275% confidence.\n",
            "Model inaccurately predicted bird with 82.44372010231018% confidence.\n",
            "Model accurately predicted dog with 97.14996218681335% confidence.\n",
            "Model inaccurately predicted dog with 49.611592292785645% confidence.\n",
            "Model inaccurately predicted truck with 32.30259418487549% confidence.\n",
            "Model inaccurately predicted bird with 34.81419086456299% confidence.\n",
            "Model inaccurately predicted truck with 86.96855902671814% confidence.\n",
            "Model inaccurately predicted horse with 70.8110511302948% confidence.\n",
            "Model accurately predicted bird with 98.04469347000122% confidence.\n",
            "Model inaccurately predicted truck with 86.26947402954102% confidence.\n",
            "Model inaccurately predicted deer with 85.28955578804016% confidence.\n",
            "Model inaccurately predicted cat with 85.4651689529419% confidence.\n",
            "Model inaccurately predicted truck with 18.8155397772789% confidence.\n",
            "Model inaccurately predicted dog with 28.281015157699585% confidence.\n",
            "Model accurately predicted frog with 95.93088626861572% confidence.\n",
            "Model inaccurately predicted truck with 83.99466276168823% confidence.\n",
            "Model inaccurately predicted truck with 61.85221076011658% confidence.\n",
            "Model accurately predicted dog with 92.95443296432495% confidence.\n",
            "Model inaccurately predicted cat with 49.77776110172272% confidence.\n",
            "Model inaccurately predicted horse with 87.50175833702087% confidence.\n",
            "Model inaccurately predicted deer with 61.17751598358154% confidence.\n",
            "Model inaccurately predicted dog with 53.61058712005615% confidence.\n",
            "Model inaccurately predicted automobile with 34.74401831626892% confidence.\n",
            "Model inaccurately predicted bird with 44.06393766403198% confidence.\n",
            "Model inaccurately predicted horse with 99.68746900558472% confidence.\n",
            "Model inaccurately predicted bird with 38.619568943977356% confidence.\n",
            "Model inaccurately predicted cat with 87.1441662311554% confidence.\n",
            "Model inaccurately predicted deer with 48.56390357017517% confidence.\n",
            "Model accurately predicted deer with 69.11996603012085% confidence.\n",
            "Model inaccurately predicted truck with 61.206018924713135% confidence.\n",
            "Model inaccurately predicted bird with 68.32682490348816% confidence.\n",
            "Model inaccurately predicted bird with 54.19884920120239% confidence.\n",
            "Model inaccurately predicted deer with 24.564045667648315% confidence.\n",
            "Model inaccurately predicted bird with 50.48514008522034% confidence.\n",
            "Model accurately predicted truck with 97.26696014404297% confidence.\n",
            "Model inaccurately predicted bird with 50.42644739151001% confidence.\n",
            "Model inaccurately predicted bird with 68.01347136497498% confidence.\n",
            "Model inaccurately predicted dog with 65.61402082443237% confidence.\n",
            "Model inaccurately predicted dog with 85.94520688056946% confidence.\n",
            "Model inaccurately predicted ship with 40.70959985256195% confidence.\n",
            "Model inaccurately predicted dog with 55.42704463005066% confidence.\n",
            "Model inaccurately predicted truck with 59.292733669281006% confidence.\n",
            "Model inaccurately predicted truck with 63.32138180732727% confidence.\n",
            "Model accurately predicted dog with 91.46171808242798% confidence.\n",
            "Model inaccurately predicted dog with 74.20305013656616% confidence.\n",
            "Model inaccurately predicted deer with 54.94617223739624% confidence.\n",
            "Model inaccurately predicted bird with 61.468011140823364% confidence.\n",
            "Model accurately predicted airplane with 93.75806450843811% confidence.\n",
            "Model inaccurately predicted truck with 81.83251023292542% confidence.\n",
            "Model inaccurately predicted dog with 26.310434937477112% confidence.\n",
            "Model inaccurately predicted ship with 53.05657386779785% confidence.\n",
            "Model inaccurately predicted bird with 42.8416907787323% confidence.\n",
            "Model inaccurately predicted cat with 77.78304815292358% confidence.\n",
            "Model inaccurately predicted truck with 70.14857530593872% confidence.\n",
            "Model accurately predicted horse with 97.46277928352356% confidence.\n",
            "Model inaccurately predicted dog with 19.119180738925934% confidence.\n",
            "Model inaccurately predicted ship with 43.430501222610474% confidence.\n",
            "Model inaccurately predicted bird with 49.30877387523651% confidence.\n",
            "Model inaccurately predicted bird with 53.005266189575195% confidence.\n",
            "Model inaccurately predicted bird with 40.70935547351837% confidence.\n",
            "Model accurately predicted horse with 96.85744047164917% confidence.\n",
            "Model inaccurately predicted horse with 51.86925530433655% confidence.\n",
            "Model inaccurately predicted bird with 30.925369262695312% confidence.\n",
            "Model inaccurately predicted dog with 46.415975689888% confidence.\n",
            "Model inaccurately predicted truck with 91.21795296669006% confidence.\n",
            "Model accurately predicted automobile with 96.83056473731995% confidence.\n",
            "Model inaccurately predicted dog with 47.44035303592682% confidence.\n",
            "Model inaccurately predicted bird with 42.39271283149719% confidence.\n",
            "Model inaccurately predicted cat with 37.29192316532135% confidence.\n",
            "Model inaccurately predicted truck with 58.265888690948486% confidence.\n",
            "Model inaccurately predicted bird with 46.40170633792877% confidence.\n",
            "Model inaccurately predicted truck with 27.310463786125183% confidence.\n",
            "Model accurately predicted bird with 97.86737561225891% confidence.\n",
            "Model inaccurately predicted bird with 50.72789192199707% confidence.\n",
            "Model inaccurately predicted dog with 44.27073299884796% confidence.\n",
            "Model inaccurately predicted bird with 62.154603004455566% confidence.\n",
            "Model inaccurately predicted bird with 38.25079798698425% confidence.\n",
            "Model accurately predicted deer with 99.52695965766907% confidence.\n",
            "Model inaccurately predicted ship with 36.059004068374634% confidence.\n",
            "Model inaccurately predicted truck with 91.28834009170532% confidence.\n",
            "Model inaccurately predicted bird with 54.072195291519165% confidence.\n",
            "Model inaccurately predicted horse with 47.34927713871002% confidence.\n",
            "Model inaccurately predicted bird with 38.12669813632965% confidence.\n",
            "Model inaccurately predicted ship with 23.287305235862732% confidence.\n",
            "Model accurately predicted ship with 91.12383723258972% confidence.\n",
            "Model inaccurately predicted automobile with 37.24350035190582% confidence.\n",
            "Model inaccurately predicted automobile with 61.86269521713257% confidence.\n",
            "Model inaccurately predicted truck with 47.80188202857971% confidence.\n",
            "Model inaccurately predicted truck with 59.14092659950256% confidence.\n",
            "Model inaccurately predicted dog with 41.407597064971924% confidence.\n",
            "Model inaccurately predicted truck with 84.78591442108154% confidence.\n",
            "Model accurately predicted bird with 80.70448040962219% confidence.\n",
            "Model inaccurately predicted automobile with 73.2849657535553% confidence.\n",
            "Model inaccurately predicted horse with 73.7794816493988% confidence.\n",
            "Model inaccurately predicted airplane with 27.45027244091034% confidence.\n",
            "Model inaccurately predicted bird with 50.18627643585205% confidence.\n",
            "Model inaccurately predicted ship with 48.397842049598694% confidence.\n",
            "Model inaccurately predicted truck with 64.71970677375793% confidence.\n",
            "Model accurately predicted bird with 88.58489990234375% confidence.\n",
            "Model inaccurately predicted dog with 32.45279788970947% confidence.\n",
            "Model inaccurately predicted cat with 71.66982889175415% confidence.\n",
            "Model inaccurately predicted automobile with 43.87730956077576% confidence.\n",
            "Model inaccurately predicted truck with 66.5539562702179% confidence.\n",
            "Model inaccurately predicted dog with 91.2178099155426% confidence.\n",
            "Model inaccurately predicted deer with 19.674961268901825% confidence.\n",
            "Model inaccurately predicted horse with 74.80244636535645% confidence.\n",
            "Model accurately predicted deer with 96.866375207901% confidence.\n",
            "Model inaccurately predicted cat with 74.54202771186829% confidence.\n",
            "Model inaccurately predicted truck with 90.66373705863953% confidence.\n",
            "Model inaccurately predicted bird with 49.80449676513672% confidence.\n",
            "Model inaccurately predicted truck with 80.74665069580078% confidence.\n",
            "Model inaccurately predicted bird with 63.160574436187744% confidence.\n",
            "Model inaccurately predicted horse with 68.92901062965393% confidence.\n",
            "Model accurately predicted frog with 70.81642150878906% confidence.\n",
            "Model inaccurately predicted deer with 50.71369409561157% confidence.\n",
            "Model inaccurately predicted deer with 46.07871472835541% confidence.\n",
            "Model inaccurately predicted horse with 25.302743911743164% confidence.\n",
            "Model inaccurately predicted dog with 74.02834296226501% confidence.\n",
            "Model accurately predicted bird with 97.62315154075623% confidence.\n",
            "Model inaccurately predicted truck with 67.75472164154053% confidence.\n",
            "Model inaccurately predicted truck with 78.60437035560608% confidence.\n",
            "Model inaccurately predicted horse with 23.969534039497375% confidence.\n",
            "Model inaccurately predicted horse with 35.76763868331909% confidence.\n",
            "Model inaccurately predicted cat with 63.76864314079285% confidence.\n",
            "Model inaccurately predicted bird with 43.38525831699371% confidence.\n",
            "Model inaccurately predicted horse with 45.893603563308716% confidence.\n",
            "Model inaccurately predicted bird with 57.46851563453674% confidence.\n",
            "Model inaccurately predicted automobile with 71.1061954498291% confidence.\n",
            "Model accurately predicted horse with 99.05397891998291% confidence.\n",
            "Model inaccurately predicted cat with 61.367809772491455% confidence.\n",
            "Model inaccurately predicted ship with 29.173871874809265% confidence.\n",
            "Model inaccurately predicted horse with 84.7474217414856% confidence.\n",
            "Model accurately predicted airplane with 50.159817934036255% confidence.\n",
            "Model inaccurately predicted dog with 58.431726694107056% confidence.\n",
            "Model inaccurately predicted bird with 47.542545199394226% confidence.\n",
            "Model inaccurately predicted bird with 49.837565422058105% confidence.\n",
            "Model accurately predicted truck with 96.55299186706543% confidence.\n",
            "Model inaccurately predicted truck with 70.77783942222595% confidence.\n",
            "Model inaccurately predicted bird with 39.02353346347809% confidence.\n",
            "Model accurately predicted cat with 51.3220489025116% confidence.\n",
            "Model inaccurately predicted bird with 35.73929965496063% confidence.\n",
            "Model accurately predicted bird with 28.991761803627014% confidence.\n",
            "Model inaccurately predicted truck with 54.80753183364868% confidence.\n",
            "Model inaccurately predicted bird with 36.90982460975647% confidence.\n",
            "Model accurately predicted cat with 83.8360607624054% confidence.\n",
            "Model inaccurately predicted truck with 74.6690034866333% confidence.\n",
            "Model inaccurately predicted dog with 72.24515676498413% confidence.\n",
            "Model inaccurately predicted bird with 41.15011692047119% confidence.\n",
            "Model inaccurately predicted dog with 69.72942352294922% confidence.\n",
            "Model inaccurately predicted deer with 35.613054037094116% confidence.\n",
            "Model inaccurately predicted truck with 71.53099179267883% confidence.\n",
            "Model inaccurately predicted dog with 56.270575523376465% confidence.\n",
            "Model inaccurately predicted automobile with 40.607813000679016% confidence.\n",
            "Model accurately predicted automobile with 60.444194078445435% confidence.\n",
            "Model inaccurately predicted bird with 27.48520076274872% confidence.\n",
            "Model inaccurately predicted truck with 56.480979919433594% confidence.\n",
            "Model inaccurately predicted truck with 45.28244733810425% confidence.\n",
            "Model inaccurately predicted bird with 36.39529347419739% confidence.\n",
            "Model accurately predicted dog with 97.67153859138489% confidence.\n",
            "Model inaccurately predicted deer with 54.11851406097412% confidence.\n",
            "Model inaccurately predicted deer with 26.815924048423767% confidence.\n",
            "Model inaccurately predicted bird with 24.525947868824005% confidence.\n",
            "Model inaccurately predicted dog with 75.17351508140564% confidence.\n",
            "Model inaccurately predicted horse with 31.14720582962036% confidence.\n",
            "Model accurately predicted automobile with 60.977011919021606% confidence.\n",
            "Model inaccurately predicted truck with 57.40142464637756% confidence.\n",
            "Model accurately predicted truck with 98.69549870491028% confidence.\n",
            "Model inaccurately predicted cat with 47.973012924194336% confidence.\n",
            "Model inaccurately predicted deer with 96.50951623916626% confidence.\n",
            "Model inaccurately predicted dog with 29.535582661628723% confidence.\n",
            "Model accurately predicted bird with 94.07777786254883% confidence.\n",
            "Model inaccurately predicted dog with 83.35704803466797% confidence.\n",
            "Model inaccurately predicted automobile with 24.011872708797455% confidence.\n",
            "Model inaccurately predicted truck with 89.14034962654114% confidence.\n",
            "Model inaccurately predicted truck with 68.67623329162598% confidence.\n",
            "Model inaccurately predicted dog with 92.86524653434753% confidence.\n",
            "Model accurately predicted bird with 78.5563588142395% confidence.\n",
            "Model inaccurately predicted truck with 57.46883749961853% confidence.\n",
            "Model inaccurately predicted horse with 60.16887426376343% confidence.\n",
            "Model inaccurately predicted truck with 51.10466480255127% confidence.\n",
            "Model inaccurately predicted ship with 42.71166920661926% confidence.\n",
            "Model inaccurately predicted bird with 42.19556748867035% confidence.\n",
            "Model accurately predicted truck with 99.01458621025085% confidence.\n",
            "Model inaccurately predicted dog with 44.23068165779114% confidence.\n",
            "Model inaccurately predicted truck with 36.14228665828705% confidence.\n",
            "Model inaccurately predicted bird with 87.5844955444336% confidence.\n",
            "Model inaccurately predicted truck with 43.53379011154175% confidence.\n",
            "Model inaccurately predicted frog with 85.67440509796143% confidence.\n",
            "Model accurately predicted horse with 99.63369369506836% confidence.\n",
            "Model inaccurately predicted horse with 31.349048018455505% confidence.\n",
            "Model inaccurately predicted horse with 58.966320753097534% confidence.\n",
            "Model inaccurately predicted dog with 30.799999833106995% confidence.\n",
            "Model accurately predicted cat with 75.67464113235474% confidence.\n",
            "Model inaccurately predicted dog with 19.204963743686676% confidence.\n",
            "Model inaccurately predicted frog with 45.47555446624756% confidence.\n",
            "Model inaccurately predicted ship with 85.34809947013855% confidence.\n",
            "Model inaccurately predicted truck with 56.910240650177% confidence.\n",
            "Model inaccurately predicted bird with 21.432143449783325% confidence.\n",
            "Model accurately predicted deer with 99.79590177536011% confidence.\n",
            "Model inaccurately predicted truck with 72.68723249435425% confidence.\n",
            "Model inaccurately predicted bird with 39.49764668941498% confidence.\n",
            "Model inaccurately predicted bird with 42.350804805755615% confidence.\n",
            "Model inaccurately predicted dog with 73.02132844924927% confidence.\n",
            "Model inaccurately predicted automobile with 22.950580716133118% confidence.\n",
            "Model accurately predicted ship with 97.19703793525696% confidence.\n",
            "Model inaccurately predicted bird with 39.34348225593567% confidence.\n",
            "Model inaccurately predicted bird with 49.42657947540283% confidence.\n",
            "Model inaccurately predicted bird with 53.77304553985596% confidence.\n",
            "Model inaccurately predicted ship with 36.34403049945831% confidence.\n",
            "Model inaccurately predicted bird with 48.320573568344116% confidence.\n",
            "Model inaccurately predicted truck with 40.252313017845154% confidence.\n",
            "Model inaccurately predicted horse with 86.84057593345642% confidence.\n",
            "Model accurately predicted airplane with 50.284093618392944% confidence.\n",
            "Model inaccurately predicted truck with 43.764492869377136% confidence.\n",
            "Model inaccurately predicted truck with 83.13034176826477% confidence.\n",
            "Model inaccurately predicted cat with 54.99357581138611% confidence.\n",
            "Model inaccurately predicted bird with 19.179102778434753% confidence.\n",
            "Model inaccurately predicted bird with 53.40689420700073% confidence.\n",
            "Model accurately predicted frog with 97.81503677368164% confidence.\n",
            "Model inaccurately predicted truck with 85.03873944282532% confidence.\n",
            "Model inaccurately predicted truck with 60.86537837982178% confidence.\n",
            "Model accurately predicted horse with 99.52760934829712% confidence.\n",
            "Model inaccurately predicted dog with 66.95881485939026% confidence.\n",
            "Model inaccurately predicted deer with 63.95801305770874% confidence.\n",
            "Model inaccurately predicted dog with 34.256741404533386% confidence.\n",
            "Model inaccurately predicted bird with 43.43079626560211% confidence.\n",
            "Model accurately predicted airplane with 79.33846116065979% confidence.\n",
            "Model inaccurately predicted truck with 24.457044899463654% confidence.\n",
            "Model inaccurately predicted automobile with 54.046040773391724% confidence.\n",
            "Model inaccurately predicted horse with 37.81338930130005% confidence.\n",
            "Model accurately predicted cat with 91.80709719657898% confidence.\n",
            "Acurracy: 92.28%\n",
            "For airplane: Predicted 368 out of 369 correct. 99.7289972899729% Accuracy\n",
            "For automobile: Predicted 400 out of 421 correct. 95.01187648456056% Accuracy\n",
            "For bird: Predicted 499 out of 589 correct. 84.71986417657045% Accuracy\n",
            "For cat: Predicted 420 out of 443 correct. 94.80812641083521% Accuracy\n",
            "For deer: Predicted 504 out of 536 correct. 94.02985074626866% Accuracy\n",
            "For dog: Predicted 501 out of 561 correct. 89.3048128342246% Accuracy\n",
            "For frog: Predicted 462 out of 464 correct. 99.56896551724138% Accuracy\n",
            "For horse: Predicted 476 out of 516 correct. 92.24806201550388% Accuracy\n",
            "For ship: Predicted 498 out of 518 correct. 96.13899613899613% Accuracy\n",
            "For truck: Predicted 486 out of 583 correct. 83.36192109777015% Accuracy\n",
            "The worst performing group is 'truck' with an accuracy of 83.36192109777015%\n"
          ]
        }
      ]
    }
  ]
}